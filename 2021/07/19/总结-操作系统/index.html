<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ednow.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":400,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="操作系统计算机系统概论计算机操作系统总考纲  【考纲内容】 (一）操作系统的概念、特征、功能和提供的服务 (二）操作系统的发展与分类 (三）操作系统的运行环境 内核态与用户态;中断、异常;系统调用 (四）操作系统体系结构 【知识框架】 概论  特征 并发(最基本) 共享(最基本) 虚拟 同步   目标和功能 计算机系统资源的管理者 用户与计算机系统之间的接口 命令接口 程序接口 GUI   扩充机">
<meta property="og:type" content="article">
<meta property="og:title" content="总结-操作系统">
<meta property="og:url" content="http://ednow.github.io/2021/07/19/%E6%80%BB%E7%BB%93-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.html">
<meta property="og:site_name" content="ednow">
<meta property="og:description" content="操作系统计算机系统概论计算机操作系统总考纲  【考纲内容】 (一）操作系统的概念、特征、功能和提供的服务 (二）操作系统的发展与分类 (三）操作系统的运行环境 内核态与用户态;中断、异常;系统调用 (四）操作系统体系结构 【知识框架】 概论  特征 并发(最基本) 共享(最基本) 虚拟 同步   目标和功能 计算机系统资源的管理者 用户与计算机系统之间的接口 命令接口 程序接口 GUI   扩充机">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210917185554.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210726161521.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210726162307.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210729154445.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210726162621.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808131002.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808131744.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808132052.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808132250.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808155557.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924232351.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924234106.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924234230.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924234833.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000015.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000115.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000242.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000331.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000605.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000736.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000758.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000817.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001048.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001244.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001447.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001545.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925095037.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925095158.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925095407.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925100154.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925100516.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101003.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101118.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101330.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101528.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101624.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101839.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101951.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102039.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102239.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102409.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102637.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925224155.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925225720.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925232929.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925233723.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235124.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235226.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235430.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235734.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926000155.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926001932.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002103.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002456.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002917.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002959.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926003108.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926003302.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926131515.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926131629.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926131714.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926132136.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926132611.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926132635.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144214.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144307.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144352.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144411.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926150756.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926150852.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926151836.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152033.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152417.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152522.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152549.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152649.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152915.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152935.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926153014.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926153350.png">
<meta property="og:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926153519.png">
<meta property="article:published_time" content="2021-07-19T05:02:27.000Z">
<meta property="article:modified_time" content="2021-09-29T14:52:02.997Z">
<meta property="article:author" content="ednow">
<meta property="article:tag" content="操作系统">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/ednow/cloudimg/raw/main/githubio/20210917185554.png">

<link rel="canonical" href="http://ednow.github.io/2021/07/19/%E6%80%BB%E7%BB%93-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>总结-操作系统 | ednow</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XQGJ63ZD9Y"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-XQGJ63ZD9Y');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?83f04257c97e81cca692d7c4c7fbbc9a";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ednow</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://ednow.github.io/2021/07/19/%E6%80%BB%E7%BB%93-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ednow">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ednow">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          总结-操作系统
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-19 13:02:27" itemprop="dateCreated datePublished" datetime="2021-07-19T13:02:27+08:00">2021-07-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-09-29 22:52:02" itemprop="dateModified" datetime="2021-09-29T22:52:02+08:00">2021-09-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><h2 id="计算机系统概论"><a href="#计算机系统概论" class="headerlink" title="计算机系统概论"></a>计算机系统概论</h2><details><summary>计算机操作系统总考纲</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210917185554.jpg" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210917185554.png';" /></details>

<p>【考纲内容】</p>
<p>(一）操作系统的概念、特征、功能和提供的服务</p>
<p>(二）操作系统的发展与分类</p>
<p>(三）操作系统的运行环境</p>
<p>内核态与用户态;中断、异常;系统调用</p>
<p>(四）操作系统体系结构</p>
<p>【知识框架】</p>
<p>概论</p>
<ul>
<li>特征<ul>
<li>并发(最基本)</li>
<li>共享(最基本)</li>
<li>虚拟</li>
<li>同步</li>
</ul>
</li>
<li>目标和功能<ul>
<li>计算机系统资源的管理者</li>
<li>用户与计算机系统之间的接口<ul>
<li>命令接口</li>
<li>程序接口</li>
<li>GUI</li>
</ul>
</li>
<li>扩充机器</li>
</ul>
</li>
<li>发展——批处理操作系统——分时操作系统——实时操作系统——网络和分布式操作系统</li>
<li>运行机制<ul>
<li>中断和异常</li>
<li>系统调用</li>
</ul>
</li>
<li>体系结构<ul>
<li>大内核</li>
<li>微内核</li>
</ul>
</li>
</ul>
<p>【复习提示】</p>
<p>本章内容通常以选择题的形式考查，重点考查操作系统的功能、运行环境和提供的服务。要求读者能在宏观上把握操作系统各个部分的功能，微观上掌握细微的知识点。因此，在复习操作系统时，首先要在形成大体框架后，通过反复做题巩固、完善知识体系，然后把操作系统的所有内容串成一个整体。本章的内容有助于读者整体上初步认识操作系统，为后面展开各章节的知识点奠定基础，进而整体把握课程。不要因为本章内容在历年考题中出现的比例不高而忽视。</p>
<h3 id="操作系统的基本概念"><a href="#操作系统的基本概念" class="headerlink" title="操作系统的基本概念"></a>操作系统的基本概念</h3><h4 id="操作系统的概念"><a href="#操作系统的概念" class="headerlink" title="操作系统的概念"></a>操作系统的概念</h4><p>在信息化时代，软件是计算机系统的灵魂，而作为软件核心的操作系统，已与现代计算机系统密不可分、融为一体。计算机系统自下而上可大致分为4部分:$\color{green}{\text{硬件}}$、$\color{green}{\text{操作系统}}$、$\color{green}{\text{应用程序}}$和$\color{green}{\text{用户}}$(这里的划分与计算机组成原理中的分层不同)。操作系统管理各种计算机硬件，为应用程序提供基础，并充当计算机硬件与用户之间的中介。</p>
<p>硬件如中央处理器、内存、输入/输出设备等，提供基本的计算资源。应用程序如字处理程序、电子制表软件、编译器、网络浏览器等，规定按何种方式使用这些资源来解决用户的计算问题。操作系统控制和协调各用户的应用程序对硬件的分配与使用。</p>
<p>在计算机系统的运行过程中，操作系统提供了正确使用这些资源的方法。</p>
<p>综上所述，操作系统(Operating System，OS）是指控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便接口与环境的程序集合。操作系统是计算机系统中最基本的系统软件。</p>
<h4 id="操作系统的特征"><a href="#操作系统的特征" class="headerlink" title="操作系统的特征"></a>操作系统的特征</h4><p>操作系统是一种系统软件，但与其他系统软件和应用软件有很大的不同，它有自己的特殊性即基本特征。操作系统的基本特征包括并发、共享、虚拟和异步。这些概念对理解和掌握操作系统的核心至关重要，将一直贯穿于各个章节中。</p>
<h5 id="并发-Concurrence"><a href="#并发-Concurrence" class="headerlink" title="并发(Concurrence)"></a>并发(Concurrence)</h5><p>并发是指两个或多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行的程序，因此它具有处理和调度多个程序同时执行的能力。在操作系统中，引入进程的目的是使程序能并发执行。</p>
<p>注意同一时间间隔（$\color{red}{\text{并发}}$）和同一时刻（$\color{red}{\text{并行}}$）的区别。在多道程序环境下，一段时间内，宏观上有多道程序在同时执行，而在每个时刻，单处理机环境下实际仅能有一道程序执行，因此微观上这些程序仍是分时交替执行的。操作系统的并发性是通过分时得以实现的。</p>
<p>注意，并行性是指系统具有同时进行运算或操作的特性，在同一时刻能完成两种或两种以上的工作。并行性需要有相关硬件的支持，如多流水线或多处理机硬件环境。</p>
<p>我们以现实生活中的直观例子来认识并发和并行的区别。例如，如果你在9:00～9:10仅吃面包，在9:10～9:20仅写字，在9:20～9:30仅吃面包，在9:30～10:00仅写字，那么在9:00～10:00吃面包和写字这两种行为就是并发执行的;再如，如果你在9:00～10:00右手写字，左手同时拿着面包吃，那么这两个动作就是并行执行的。</p>
<h5 id="共享-Sharing"><a href="#共享-Sharing" class="headerlink" title="共享(Sharing)"></a>共享(Sharing)</h5><p>资源共享即共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。共享可分为以下两种资源共享方式。</p>
<p>(1）互斥共享方式</p>
<p>系统中的某些资源，如打印机、磁带机，虽然可供多个进程使用，但为使得所打印或记录的结果不致造成混淆，应规定在一段时间内只允许一个进程访问该资源。</p>
<p>为此，当进程A访问某个资源时，必须先提出请求，若此时该资源空闲，则系统便将之分配给进程A使用，此后有其他进程也要访问该资源时（只要A未用完）就必须等待。仅当进程A访问完并释放该资源后，才允许另一个进程对该资源进行访问。我们把这种资源共享方式称为互斥式共享，而把在一段时间内只允许一个进程访问的资源称为临界资源或独占资源。计算机系统中的大多数物理设备及某些软件中所用的栈、变量和表格，都属于临界资源，它们都要求被互斥地共享。</p>
<p>(2）同时访问方式</p>
<p>系统中还有另一类资源，这类资源允许在一段时间内由多个进程“同时”访问。这里所说的“同时”通常是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问即“分时共享”的。可供多个进程“同时”访问的典型资源是磁盘设备，一些用重入码编写的文件也可被“同时”共享，即允许若干个用户同时访问该文件。</p>
<p>注意，互斥共享要求一种资源在一段时间内（哪怕是一段很小的时间）只能满足一个请求，否则就会出现严重的问题，(你能想象打印机第一行打印A文档的内容、第二行打印B文档的内容的效果吗?）而同时访问共享通常要求一个请求分几个时间片段间隔地完成，其效果与连续完成的效果相同。</p>
<p>$\color{green}{\text{并发}}$和$\color{green}{\text{共享}}$是操作系统两个最基本的特征，两者之间互为存在的条件:①资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则自然不存在资源共享问题;②若系统不能对资源共享实施有效的管理，则必将影响到程序的并发执行，甚至根本无法并发执行。</p>
<h5 id="虚拟-Virtual"><a href="#虚拟-Virtual" class="headerlink" title="虚拟(Virtual)"></a>虚拟(Virtual)</h5><p>虚拟是指把一个物理上的$\color{green}{\text{实体}}$变为若干$\color{green}{\text{逻辑}}$上的对应物。物理实体（前者）是实的，即实际存在的;而后者是虚的，是用户感觉上的事物。用于实现虚拟的技术，称为虚拟技术。操作系统中利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等。</p>
<p>虚拟处理器技术是通过多道程序设计技术，采用让多道程序并发执行的方法，来分时使用一个处理器的。此时，虽然只有一个处理器，但它能同时为多个用户服务，使每个终端用户都感觉有一个中央处理器(CPU)在专门为它服务。利用多道程序设计技术把一个物理上的CPU虚拟为多个逻辑上的CPU，称为虚拟处理器。</p>
<p>类似地，可以采用虚拟存储器技术将一台机器的物理存储器变为虚拟存储器，以便从逻辑上扩充存储器的容量。当然，这时用户所感觉到的内存容量是虚的。我们把用户感觉到（但实际不存在)的存储器称为虚拟存储器。</p>
<p>还可采用虚拟设备技术将一台物理IO设备虚拟为多台逻辑上的I/O 设备，并允许每个用户占用一台逻辑上的IO设备，使原来仅允许在一段时间内由一个用户访问的设备（即临界资源)变为在一段时间内允许多个用户同时访问的共享设备。</p>
<p>因此，操作系统的虚拟技术可归纳为:时分复用技术，如处理器的分时共享;空分复用技术，如虚拟存储器。</p>
<h5 id="异步-Asynchronism"><a href="#异步-Asynchronism" class="headerlink" title="异步(Asynchronism)"></a>异步(Asynchronism)</h5><p>多道程序环境允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进，这就是进程的异步性。</p>
<p>异步性使得操作系统运行在一种随机的环境下，可能导致进程产生与时间有关的错误（就像对全局变量的访问顺序不当会导致程序出错一样)。然而，只要运行环境相同，操作系统就须保证多次运行进程后都能获得相同的结果。</p>
<h4 id="操作系统的目标和功能"><a href="#操作系统的目标和功能" class="headerlink" title="操作系统的目标和功能"></a>操作系统的目标和功能</h4><p>为了给多道程序提供良好的运行环境，操作系统应具有以下几方面的功能:处理机管理、存储器管理、设备管理和文件管理。为了方便用户使用操作系统，还必须向用户提供接口。同时，操作系统可用来扩充机器，以提供更方便的服务、更高的资源利用率。</p>
<p>我们用一个直观的例子来理解这种情况。例如，用户是雇主，操作系统是工人（用来操作机器)，计算机是机器（由处理机、存储器、设备、文件几个部件构成)，工人有熟练的技能，能够控制和协调各个部件的工作，这就是操作系统对资源的管理;同时，工人必须接收雇主的命令，这就是“接口”;有了工人，机器就能发挥更大的作用，因此工人就成了“扩充机器”。</p>
<h5 id="操作系统作为计算机系统资源的管理者"><a href="#操作系统作为计算机系统资源的管理者" class="headerlink" title="操作系统作为计算机系统资源的管理者"></a>操作系统作为计算机系统资源的管理者</h5><h6 id="处理机管理"><a href="#处理机管理" class="headerlink" title="处理机管理"></a>处理机管理</h6><p>在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位，因而对处理机的管理可归结为对进程的管理。并发是指在计算机内同时运行多个进程，因此进程何时创建、何时撤销、如何管理、如何避免冲突、合理共享就是进程管理的最主要的任务。进程管理的主要功能包括进程控制、进程同步、进程通信、死锁处理、处理机调度等。</p>
<h6 id="存储器管理"><a href="#存储器管理" class="headerlink" title="存储器管理"></a>存储器管理</h6><p>存储器管理是为了给多道程序的运行提供良好的环境，方便用户使用及提高内存的利用率，主要包括内存分配与回收、地址映射、内存保护与共享和内存扩充等功能。</p>
<h6 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h6><p>计算机中的信息都是以文件的形式存在的，操作系统中负责文件管理的部分称为文件系统。文件管理包括文件存储空间的管理、目录管理及文件读写管理和保护等。</p>
<h6 id="设备管理"><a href="#设备管理" class="headerlink" title="设备管理"></a>设备管理</h6><p>设备管理的主要任务是完成用户的IO请求，方便用户使用各种设备，并提高设备的利用率，主要包括缓冲管理、设备分配、设备处理和虚拟设备等功能。</p>
<p>这些工作都由“工人”负责，“雇主”无须关注。</p>
<h5 id="操作系统作为用户与计算机硬件系统之间的接口"><a href="#操作系统作为用户与计算机硬件系统之间的接口" class="headerlink" title="操作系统作为用户与计算机硬件系统之间的接口"></a>操作系统作为用户与计算机硬件系统之间的接口</h5><p>为了让用户方便、快捷、可靠地操纵计算机硬件并运行自己的程序，操作系统还提供了用户接口。操作系统提供的接口主要分为两类:一类是命令接口，用户利用这些操作命令来组织和控制作业的执行;另一类是程序接口，编程人员可以使用它们来请求操作系统服务。</p>
<h6 id="命令接口"><a href="#命令接口" class="headerlink" title="命令接口"></a>命令接口</h6><p>使用命令接口进行作业控制的主要方式有两种，即联机控制方式和脱机控制方式。按作业控制方式的不同，可将命令接口分为联机命令接口和脱机命令接口。</p>
<p>$\color{green}{\text{联机命令接口}}$又称$\color{green}{\text{交互式命令接口}}$，适用于分时或实时系统的接口。它由一组键盘操作命令组成。用户通过控制台或终端输入操作命令，向系统提出各种服务要求。用户每输入一条命令，控制权就转给操作系统的命令解释程序，然后由命令解释程序解释并执行输入的命令，完成指定的功能。之后，控制权转回控制台或终端，此时用户又可输入下一条命令。联机命令接口可以这样理解:“雇主”说一句话，“工人”做一件事，并做出反馈，这就强调了交互性。</p>
<p>$\color{green}{\text{脱机命令接口}}$又称$\color{green}{\text{批处理命令接口}}$，适用于批处理系统，它由一组作业控制命令组成。脱机用户不能直接干预作业的运行，而应事先用相应的作业控制命令写成一份作业操作说明书，连同作业一起提交给系统。系统调度到该作业时，由系统中的命令解释程序逐条解释执行作业说明书上的命令，从而间接地控制作业的运行。脱机命令接口可以这样理解:“雇主”把要“工人”做的事写在清单上，“工人”按照清单命令逐条完成这些事，这就是批处理。</p>
<blockquote>
<p>$\color{green}{\text{联}}$机和脱机可以理解为「$\color{green}{\text{联}}$接机器」的「$\color{green}{\text{联}}$」不是「$\color{red}{\text{联}}$网」的「$\color{red}{\text{联}}$」;交互的状态不就是连接着机器的吗</p>
</blockquote>
<h6 id="程序接口"><a href="#程序接口" class="headerlink" title="程序接口"></a>程序接口</h6><p>程序接口由一组$\color{green}{\text{系统调用}}$（也称$\color{green}{\text{广义指令}}$）组成。用户通过在程序中使用这些系统调用来请求操作系统为其提供服务，如使用各种外部设备、申请分配和回收内存及其他各种要求。</p>
<p>当前最为流行的是图形用户界面(GUI),即图形接口。GUI最终是通过调用程序接口实现的，用户通过鼠标和键盘在图形界面上单击或使用快捷键，就能很方便地使用操作系统。严格来说，图形接口不是操作系统的一部分，但图形接口所调用的系统调用命令是操作系统的一部分。</p>
<h5 id="操作系统用作扩充机器"><a href="#操作系统用作扩充机器" class="headerlink" title="操作系统用作扩充机器"></a>操作系统用作扩充机器</h5><p>没有任何软件支持的计算机称为裸机，它仅构成计算机系统的物质基础，而实际呈现在用户面前的计算机系统是经过若干层软件改造的计算机。裸机在最里层，其外面是操作系统。操作系统所提供的资源管理功能和方便用户的各种服务功能，将裸机改造成功能更强、使用更方便的机器;因此，我们通常把覆盖了软件的机器称为扩充机器或虚拟机。</p>
<p>“工人”操作机器，机器就有更大的作用，于是“工人”便成了“扩充机器”。</p>
<p>注意，本课程所关注的内容是操作系统如何控制和协调处理机、存储器、设备和文件，而不关注接口和扩充机器，后两者读者只需要有个印象，能理解即可。</p>
<h3 id="操作系统的发展与分类"><a href="#操作系统的发展与分类" class="headerlink" title="操作系统的发展与分类"></a>操作系统的发展与分类</h3><h4 id="手工操作阶段（此阶段无操作系统"><a href="#手工操作阶段（此阶段无操作系统" class="headerlink" title="手工操作阶段（此阶段无操作系统)"></a>手工操作阶段（此阶段无操作系统)</h4><p>用户在计算机上算题的所有工作都要人工干预，如程序的装入、运行、结果的输出等。随着计算机硬件的发展，人机矛盾（速度和资源利用）越来越大，必须寻求新的解决办法。</p>
<p>手工操作阶段有两个突出的缺点:①用户独占全机，虽然不会出现因资源已被其他用户占用而等待的现象，但资源利用率低。②CPU等待手工操作，CPU的利用不充分。</p>
<p>唯一的解决办法就是用高速的机器代替相对较慢的手工操作来对作业进行控制。</p>
<h4 id="批处理阶段-操作系统开始出现）"><a href="#批处理阶段-操作系统开始出现）" class="headerlink" title="批处理阶段(操作系统开始出现）"></a>批处理阶段(操作系统开始出现）</h4><p>为了解决人机矛盾及CPU和IO设备之间速度不匹配的矛盾，出现了批处理系统。按发展历程又分为单道批处理系统、多道批处理系统（多道程序设计技术出现以后)。·</p>
<h5 id="单道批处理系统"><a href="#单道批处理系统" class="headerlink" title="单道批处理系统"></a>单道批处理系统</h5><p>系统对作业的处理是成批进行的，但内存中始终保持一道作业。单道批处理系统是在解决人机矛盾及CPU和IO设备速率不匹配的矛盾中形成的。单道批处理系统的主要特征如下:</p>
<p>1）自动性。在顺利的情况下，磁带上的一批作业能自动地逐个运行，而无须人工干预</p>
<p>2）顺序性。磁带上的各道作业顺序地进入内存，各道作业的完成顺序与它们进入内存的顺序在正常情况下应完全相同，亦即先调入内存的作业先完成。</p>
<p>3）单道性。内存中仅有一道程序运行，即监督程序每次从磁带上只调入一道程序进入内存运行，当该程序完成或发生异常情况时，才换入其后继程序进入内存运行。</p>
<p>此时面临的问题是:每次主机内存中仅存放一道作业，每当它在运行期间（注意这里是“运行时”而不是“完成后”)发出输入/输出请求后，高速的CPU便处于等待低速的IO完成的状态。为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。</p>
<h5 id="多道批处理系统"><a href="#多道批处理系统" class="headerlink" title="多道批处理系统"></a>多道批处理系统</h5><p>多道程序设计技术允许多个程序同时进入内存并允许它们在CPU中交替地运行，这些程序共享系统中的各种硬/软件资源。当一道程序因I/O请求而暂停运行时，CPU便立即转去运行另一道程序。它不采用某些机制来提高某一技术方面的瓶颈问题，而让系统的各个组成部分都尽量去“忙”，因此切换任务所花费的时间很少，可实现系统各部件之间的并行工作，使其整体在单位时间内的效率翻倍。</p>
<p>当然，多道批处理系统的设计和实现要比单道系统复杂很多，因为要充分利用各种资源，就要涉及各种资源的调度问题。</p>
<p>多道程序设计的特点是多道、宏观上并行、微观上串行。</p>
<p>1）多道。计算机内存中同时存放多道相互独立的程序。</p>
<p>2）宏观上并行。同时进入系统的多道程序都处于运行过程中，即它们先后开始各自的运行，但都未运行完毕。</p>
<p>3）微观上串行。内存中的多道程序轮流占有CPU，交替执行。</p>
<p>多道程序设计技术的实现需要解决下列问题:</p>
<p>1）如何分配处理器。</p>
<p>2）多道程序的内存分配问题。</p>
<p>3）IO设备如何分配。</p>
<p>4）如何组织和存放大量的程序和数据，以方便用户使用并保证其安全性与一致性。</p>
<p>在批处理系统中采用多道程序设计技术就形成了多道批处理操作系统。该系统把用户提交的作业成批地送入计算机内存，然后由作业调度程序自动地选择作业运行。</p>
<p>优点:资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用;系统吞吐量大，CPU和其他资源保持“忙碌”状态。缺点:用户响应的时间较长;不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。</p>
<h4 id="分时操作系统"><a href="#分时操作系统" class="headerlink" title="分时操作系统"></a>分时操作系统</h4><p>所谓分时技术，是指把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行，把处理器让给其他作业使用，等待下一轮再继续运行。由于计算机速度很快，作业运行轮转得也很快，因此给每个用户的感觉就像是自己独占一台计算机。</p>
<p>分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时与主机进行交互操作而互不干扰。因此，实现分时系统最关键的问题是如何使用户能与自己的作业进行交互，即当用户在自己的终端上键入命令时，系统应能及时接收并及时处理该命令，再将结果返回用户。分时系统也是支持多道程序设计的系统，但它不同于多道批处理系统多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现人机交互的系统，这使得分时系统具有与批处理系统不同的特征。分时系统的主要特征如下:</p>
<p>1）同时性。同时性也称多路性，指允许多个终端用户同时使用一台计算机，即一台计算机与若干台终端相连接，终端上的这些用户可以同时或基本同时使用计算机。</p>
<p>2）交互性。用户能够方便地与系统进行人机对话，即用户通过终端采用人机对话的方式直接控制程序运行，与同程序进行交互。</p>
<p>3）独立性。系统中多个用户可以彼此独立地进行操作，互不干扰，单个用户感觉不到别人也在使用这台计算机，好像只有自己单独使用这台计算机一样。</p>
<p>4）及时性。用户请求能在很短时间内获得响应。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意。</p>
<p>虽然分时操作系统较好地解决了人机交互问题，但在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统)，因此，实时操作系统应运而生。</p>
<h4 id="实时操作系统"><a href="#实时操作系统" class="headerlink" title="实时操作系统"></a>实时操作系统</h4><p>为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。这里的时间限制可以分为两种情况:若某个动作必须绝对地在规定的时刻（或规定的时间范围）发生，则称为硬实时系统，如飞行器的飞行自动控制系统，这类系统必须提供绝对保证，让某个特定的动作在规定的时间内完成。若能够接受偶尔违反时间规定且不会引起任何永久性的损害，则称为软实时系统，如飞机订票系统、银行管理系统。</p>
<p>在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并在严格的时限内处理完接收的事件。实时操作系统的主要特点是及时性和可靠性。</p>
<h4 id="网络操作系统和分布式计算机系统"><a href="#网络操作系统和分布式计算机系统" class="headerlink" title="网络操作系统和分布式计算机系统"></a>网络操作系统和分布式计算机系统</h4><p>网络操作系统把计算机网络中的各台计算机有机地结合起来，提供一种统一、经济而有效的使用各台计算机的方法，实现各台计算机之间数据的互相传送。网络操作系统最主要的特点是网络中各种资源的共享及各台计算机之间的通信。</p>
<p>分布式计算机系统是由多台计算机组成并满足下列条件的系统:系统中任意两台计算机通过通信方式交换信息;系统中的每台计算机都具有同等的地位，即没有主机也没有从机;每台计算机上的资源为所有用户共享;系统中的任意台计算机都可以构成一个子系统，并且还能重构;任何工作都可以分布在几台计算机上，由它们并行工作、协同完成。用于管理分布式计算机系统的操作系统称为分布式计算机系统。该系统的主要特点是:分布性和并行性。分布式操作系统与网络操作系统的本质不同是，分布式操作系统中的若干计算机相互协同完成同一任务。</p>
<h4 id="个人计算机操作系统"><a href="#个人计算机操作系统" class="headerlink" title="个人计算机操作系统"></a>个人计算机操作系统</h4><p>个人计算机操作系统是目前使用最广泛的操作系统，它广泛应用于文字处理、电子表格、游戏中，常见的有 Windows、Linux和 Macintosh等。操作系统的发展历程如图1.1所示。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210726161521.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210726161521.png';" /></details>

<p>此外，还有嵌入式操作系统、服务器操作系统、智能手机操作系统等。</p>
<h3 id="操作系统的运行环境"><a href="#操作系统的运行环境" class="headerlink" title="操作系统的运行环境"></a>操作系统的运行环境</h3><h4 id="操作系统的运行机制"><a href="#操作系统的运行机制" class="headerlink" title="操作系统的运行机制"></a>操作系统的运行机制</h4><blockquote>
<p>初学者需要弄清楚一个问题，即计算机“指令”和高级语言的“代码”是不同的。我们一般所说的“编写代码”指的是用高级语言〈如C、Java等）来编写程序。但CPU看不懂这些高级语言程序的含义，为了让这些程序能够顺利执行，就需要把它们“翻译”成CPU能懂的机器语言，即一条条“指令”(这个“翻译”的过程称为“编译”)。所谓执行程序，其实就是CPU根据一条条指令的指示来执行一个个具体的操作。</p>
</blockquote>
<p>计算机系统中，通常CPU执行两种不同性质的程序:一种是操作系统内核程序;另一种是用户自编程序（即系统外层的应用程序，或简称“应用程序”)。对操作系统而言，这两种程序的作用不同，前者是后者的管理者，因此“管理程序”(即内核程序）要执行一些特权指令，而“被管理程序”(即用户自编程序）出于安全考虑不能执行这些指令。所谓特权指令，是指计算机中不允许用户直接使用的指令，如IO指令、置中断指令，存取用于内存保护的寄存器、送程序状态字到程序状态字寄存器等的指令。在具体实现上，将CPU的状态划分为用户态(目态）和核心态（又称管态、内核态)。可以理解为CPU内部有一个小开关，当小开关为1时，CPU处于核心态，此时CPU可以执行特权指令;当小开关为0时，CPU处于用户态，此时CPU只能执行非特权指令。用户自编程序运行在用户态，操作系统内核程序运行在核心态。</p>
<p>在软件工程思想和结构化程序设计方法影响下诞生的现代操作系统，几乎都是层次式的结构。操作系统的各项功能分别被设置在不同的层次上。一些与硬件关联较紧密的模块，如时钟管理、中断处理、设备驱动等处于最低层。其次是运行频率较高的程序，如进程管理、存储器管理和设备管理等。这两部分内容构成了操作系统的内核。这部分内容的指令操作工作在核心态。</p>
<p>内核是计算机上配置的底层软件，是计算机功能的延伸。不同系统对内核的定义稍有区别，大多数操作系统的内核包括4方面的内容。</p>
<h5 id="时钟管理"><a href="#时钟管理" class="headerlink" title="时钟管理"></a>时钟管理</h5><p>在计算机的各种部件中，时钟是最关键的设备。时钟的第一功能是计时，操作系统需要通过时钟管理，向用户提供标准的系统时间。另外，通过时钟中断的管理，可以实现进程的切换。例如，在分时操作系统中采用时间片轮转调度，在实时系统中按截止时间控制运行，在批处理系统中通过时钟管理来衡量一个作业的运行程度等。因此，系统管理的方方面面无不依赖于时钟。</p>
<h5 id="中断机制"><a href="#中断机制" class="headerlink" title="中断机制"></a>中断机制</h5><p>引入中断技术的初衷是提高多道程序运行环境中CPU 的利用率，而且主要是针对外部设备的。后来逐步得到发展，形成了多种类型，成为操作系统各项操作的基础。例如，键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等，无不依赖于中断机制。可以说，现代操作系统是靠中断驱动的软件。</p>
<p>中断机制中，只有一小部分功能属于内核，它们负责保护和恢复中断现场的信息，转移控制权到相关的处理程序。这样可以减少中断的处理时间，提高系统的并行处理能力。</p>
<h5 id="原语"><a href="#原语" class="headerlink" title="原语"></a>原语</h5><p>按层次结构设计的操作系统，底层必然是一些可被调用的公用小程序，它们各自完成一个规定的操作。它们的特点如下:</p>
<p>1）处于操作系统的最低层，是最接近硬件的部分。</p>
<p>2)这些程序的运行具有原子性，其操作只能一气呵成(主要从系统安全性和便于管理考虑)。</p>
<p>3）这些程序的运行时间都较短，而且调用频繁。</p>
<p>通常把具有这些特点的程序称为原语(Atomic Operation)。定义原语的直接方法是关闭中断，让其所有动作不可分割地完成后再打开中断。</p>
<p>系统中的设备驱动、CPU切换、进程通信等功能中的部分操作都可定义为原语，使它们成为内核的组成部分。</p>
<h5 id="系统控制的数据结构及处理"><a href="#系统控制的数据结构及处理" class="headerlink" title="系统控制的数据结构及处理"></a>系统控制的数据结构及处理</h5><p>系统中用来登记状态信息的数据结构很多，如作业控制块、进程控制块(PCB)、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表等。为了实现有效的管理,系统需要一些基本的操作，常见的操作有以下3种:</p>
<p>1)进程管理。进程状态管理、进程调度和分派、创建与撤销进程控制块等。</p>
<p>2）存储器管理。存储器的空间分配和回收、内存信息保护程序、代码对换程序等。</p>
<p>3）设备管理。缓冲区管理、设备分配和回收等。</p>
<p>从上述内容可以了解，核心态指令实际上包括系统调用类指令和一些针对时钟、中断和原语的操作指令。</p>
<h4 id="中断和异常的概念"><a href="#中断和异常的概念" class="headerlink" title="中断和异常的概念"></a>中断和异常的概念</h4><blockquote>
<p>建议结合《计算机组成原理考研复习指导》第7章学习，那里的讲解更详细。</p>
</blockquote>
<p>在操作系统中引入核心态和用户态这两种工作状态后，就需要考虑这两种状态之间如何切换。操作系统内核工作在核心态，而用户程序工作在用户态。系统不允许用户程序实现核心态的功能，而它们又必须使用这些功能。因此，需要在核心态建立一些“门”，以便实现从用户态进入核心态。在实际操作系统中，CPU运行上层程序时唯一能进入这些“门”的途径就是通过中断或异常。发生中断或异常时，运行用户态的CPU会立即进入核心态，这是通过硬件实现的(例如,用一个特殊寄存器的一位来表示CPU所处的工作状态，0表示核心态，1表示用户态。若要进入核心态，则只需将该位置0即可)。中断是操作系统中非常重要的一个概念，对一个运行在计算机上的实用操作系统而言，缺少了中断机制，将是不可想象的。原因是，操作系统的发展过程大体上就是一个想方设法不断提高资源利用率的过程，而提高资源利用率就需要在程序并未使用某种资源时，把它对那种资源的占有权释放，而这一行为就需要通过中断实现。</p>
<h5 id="中断和异常的定义"><a href="#中断和异常的定义" class="headerlink" title="中断和异常的定义"></a>中断和异常的定义</h5><p>中断(Interruption)也称外中断，指来自CPU执行指令以外的事件的发生，如设备发出的IO结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入/输出请求，同时让完成输入/输出后的程序继续运行。时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与当前指令执行无关的事件，即它们与当前处理机运行的程序无关。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210726162307.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210726162307.png';" /></details>

<p>异常（Exception）也称内中断、例外或陷入(trap)，指源自CPU执行指令内部的事件,如程序的非法操作码、地址越界、算术溢出、虚存系统的缺页及专门的陷入指令等引起的事件。对异常的处理一般要依赖于当前程序的运行现场，而且异常不能被屏蔽，一旦出现应立即处理。关于内中断和外中断的联系与区别如图1.2所示。</p>
<blockquote>
<p>异常不能被屏蔽，一旦出现应立即处理???</p>
</blockquote>
<h5 id="中断处理的过程"><a href="#中断处理的过程" class="headerlink" title="中断处理的过程"></a>中断处理的过程</h5><p>不同计算机的中断(指外中断)处理过程各具特色，就其多数而论，中断处理流程如图1.3所示。各阶段处理流程的描述如下:</p>
<details><summary>图1.3 中断处理流程</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210729154445.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210729154445.png';" /></details>

<p>1）关中断。CPU响应中断后，首先要保护程序的现场状态，在保护现场的过程中，CPU不应响应更高级中断源的中断请求。否则，若现场保存不完整，在中断服务程序结束后，也就不能正确地恢复并继续执行现行程序。</p>
<p>2）保存断点。为保证中断服务程序执行完毕后能正确地返回到原来的程序，必须将原来的程序的断点（即程序计数器PC）保存起来。</p>
<p>3）中断服务程序寻址。其实质是取出中断服务程序的入口地址送入程序计数器PC。</p>
<p>4)保存现场和屏蔽字。进入中断服务程序后，首先要保存现场，现场信息一般是指程序状态字寄存器PSWR和某些通用寄存器的内容。</p>
<p>5）开中断。允许更高级中断请求得到响应。</p>
<p>6）执行中断服务程序。这是中断请求的目的。</p>
<p>7）关中断。保证在恢复现场和屏蔽字时不被中断。</p>
<p>8）恢复现场和屏蔽字。将现场和屏蔽字恢复到原来的状态。</p>
<p>9)开中断、中断返回。中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。</p>
<p>其中，1 ~ 3步是在CPU进入中断周期后，由硬件自动（中断隐指令）完成的;4 ~ 9步由中断服务程序完成。恢复现场是指在中断返回前，必须将寄存器的内容恢复到中断处理前的状态，这部分工作由中断服务程序完成。中断返回由中断服务程序的最后一条中断返回指令完成。</p>
<h4 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h4><p>所谓系统调用，是指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的公共子程序。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、进行IO传输及管理文件等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。通常，一个操作系统提供的系统调用命令有几十条乃至上百条之多。这些系统调用按功能大致可分为如下几类。</p>
<ul>
<li>设备管理。完成设备的请求或释放，以及设备启动等功能。文件管理。完成文件的读、写、创建及删除等功能。</li>
<li>进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。</li>
<li>进程通信。完成进程之间的消息传递或信号传递等功能。</li>
<li>内存管理。完成内存的分配、回收以及获取作业占用内存区大小及始址等功能。</li>
</ul>
<p>显然，系统调用相关功能涉及系统资源管理、进程管理之类的操作，对整个系统的影响非常大，因此必定需要使用某些特权指令才能完成，所以系统调用的处理需要由操作系统内核程序负责完成，要运行在核心态。用户程序可以执行陷入指令(又称$\color{green}{\text{访管指令}}$或$\color{green}{\text{trap指令}}$）来发起系统调用，请求操作系统提供服务。可以这么理解，用户程序执行“陷入指令”，相当于把CPU成低用权主动交给操作系统内核程序（CPU 状态会从用户态进入核心态)，之后操作系统内核程序再对系统调用请求做出相应处理。处理完成后，操作系统内核程序又会把CPU的使用权还给用户程序(即CPU状态会从核心态回到用户态)。这么设计的目的是:用户程序不能直接执行对系统影响非常大的操作，必须通过系统调用的方式请求操作系统代为执行，以便保证系统的稳定性和安全性，防止用户程序随意更改或访问重要的系统资源，影响其他进程的运行。</p>
<p>这样，操作系统的运行环境就可以理解为:用户通过操作系统运行上层程序（如系统提供的命令解释程序或用户自编程序)，而这个上层程序的运行依赖于操作系统的底层管理程序提供服务支持，当需要管理程序服务时，系统则通过硬件中断机制进入核心态，运行管理程序;也可能是程序运行出现异常情况，被动地需要管理程序的服务，这时就通过异常处理来进入核心态。管理程序运行结束时，用户程序需要继续运行，此时通过相应的保存的程序现场退出中断处理程序或异常处理程序，返回断点处继续执行，如图1.4所示。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210726162621.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210726162621.png';" /></details>


<p>在操作系统这一层面上，我们关心的是系统核心态和用户态的软件实现与切换，对于硬件层面的具体理解，可以结合“计算机组成原理”课程中有关中断的内容进行学习。</p>
<p>下面列举一些由用户态转向核心态的例子:</p>
<p>1）用户程序要求操作系统的服务，即系统调用。</p>
<p>2）发生一次中断。</p>
<p>3）用户程序中产生了一个错误状态。</p>
<p>4）用户程序中企图执行一条特权指令。</p>
<p>5）从核心态转向用户态由一条指令实现，这条指令也是特权命令，一般是中断返回指令。</p>
<blockquote>
<p>注意:由用户态进入核心态，不仅状态需要切换，而且所用的堆栈也可能需要由用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的。</p>
</blockquote>
<p>若程序的运行由用户态转到核心态，则会用到访管指令，访管指令是在用户态使用的，所以它不可能是特权指令。</p>
<h3 id="操作系统的体系结构"><a href="#操作系统的体系结构" class="headerlink" title="操作系统的体系结构"></a>操作系统的体系结构</h3><h4 id="大内核和微内核"><a href="#大内核和微内核" class="headerlink" title="大内核和微内核"></a>大内核和微内核</h4><p>操作系统的体系结构是一个开放的问题。如上文所述，操作系统在核心态为应用程序提供公共的服务，那么操作系统在核心态应该提供什么服务、怎样提供服务﹖有关这一问题的回答形成了两种主要的体系结构:大内核和微内核。</p>
<p>大内核系统将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为应用提供高性能的系统服务。因为各管理模块之间共享信息，能有效利用相互之间的有效特性.所以具有无可比拟的性能优势。</p>
<p>但随着体系结构和应用需求的不断发展，需要操作系统提供的服务越来越多，而且接口形式越来越复杂，操作系统的设计规模急剧增长，操作系统也面临着“软件危机”困境。为此，操作系统设计人员试图按照复杂性、时间常数、抽象级别等因素，将操作系统内核分成基本进程管理、虚存、IO与设备管理、IPC、文件系统等几个层次，继而定义层次之间的服务结构，提高操作系统内核设计上的模块化。但是，由于层次之间的交互关系错综复杂，定义清晰的层次间接口非常困难，复杂的交互关系也使得层次之间的界限极其模糊。</p>
<p>为解决操作系统的内核代码难以维护的问题，提出了微内核的体系结构。它将内核中最基本的功能（如进程管理等）保留在内核，而将那些不需要在核心态执行的功能移到用户态执行,从而降低了内核的设计复杂性。那些移出内核的操作系统代码根据分层的原则被划分成若干服务程序，它们的执行相互独立，交互则都借助于微内核进行通信。</p>
<p>微内核结构有效地分离了内核与服务、服务与服务，使得它们之间的接口更加清晰，维护的代价大大降低，各部分可以独立地优化和演进，从而保证了操作系统的可靠性。</p>
<p>微内核结构的最大问题是性能问题，因为需要频繁地在核心态和用户态之间进行切换，操作系统的执行开销偏大。因此有的操作系统将那些频繁使用的系统服务又移回内核，从而保证系统性能。但相当多的实验数据表明，体系结构不是引起性能下降的主要因素，体系结构带来的性能提升足以弥补切换开销带来的缺陷。为减少切换开销，也有人提出将系统服务作为运行库链接到用户程序的一种解决方案，这样的体系结构称为$\color{green}{\text{库操作系统}}$。</p>
<blockquote>
<p><code>体系结构带来的性能提升足以弥补切换开销带来的缺陷</code>在说啥?</p>
</blockquote>
<h3 id="本章疑难点"><a href="#本章疑难点" class="headerlink" title="本章疑难点"></a>本章疑难点</h3><h4 id="并行性与并发性的区别和联系"><a href="#并行性与并发性的区别和联系" class="headerlink" title="并行性与并发性的区别和联系"></a>并行性与并发性的区别和联系</h4><p>并行性和并发性是既相似又有区别的两个概念。并行性是指两个或多个事件在同一时刻发生，并发性是指两个或多个事件在同一时间间隔内发生。</p>
<p>在多道程序环境下，并发性是指在一段时间内，宏观上有多个程序同时运行，但在单处理器系统中每个时刻却仅能有一道程序执行，因此微观上这些程序只能分时地交替执行。若在计算机系统中有多个处理器，则这些可以并发执行的程序便被分配到多个处理器上，实现并行执行，即利用每个处理器来处理一个可并发执行的程序。</p>
<blockquote>
<p>咬文嚼字一下，并行依靠多处理器支持，如果两个任务挂在到两个不同的处理器那么就能并行执行<br>考虑java的线程机制，一个继承了thread的线程，在调用start的时候$\color{green}{\text{启动}}$一个线程，那么就实现了并$\color{green}{\text{发}}$(发车，启动)<br>java <a target="_blank" rel="noopener" href="https://www.cnblogs.com/agilestyle/p/11421515.html">run和start的区别</a></p>
</blockquote>
<h4 id="特权指令与非特权指令"><a href="#特权指令与非特权指令" class="headerlink" title="特权指令与非特权指令"></a>特权指令与非特权指令</h4><p>所谓特权指令，是指有特殊权限的指令，由于这类指令的权限最大，使用不当将导致整个系统崩溃，如清内存、置时钟、分配系统资源、修改虚存的段表或页表、修改用户的访问权限等。若所有程序都能使用这些指令，则系统一天死机n次就不足为奇。为保证系统安全，这类指令只能用于操作系统或其他系统软件，不直接提供给用户使用。因此，特权指令必须在核心态执行。实际上，CPU在核心态下可以执行指令系统的全集。形象地说，特权指令是那些儿童不宜的东西，而非特权指令是老少皆宜的东西。</p>
<p>为了防止用户程序中使用特权指令，用户态下只能使用非特权指令，核心态下可以使用全部指令。在用户态下使用特权指令时，将产生中断以阻止用户使用特权指令。所以把用户程序放在用户态下运行，而操作系统中必须使用特权指令的那部分程序在核心态下运行，保证了计算机系<br>统的安全可靠。从用户态转换为核心态的唯一途径是中断或异常。</p>
<h4 id="访管指令与访管中断"><a href="#访管指令与访管中断" class="headerlink" title="访管指令与访管中断"></a>访管指令与访管中断</h4><p>访管指令是一条可以在用户态下执行的指令。在用户程序中，因要求操作系统提供服务而有意识地使用访管指令，从而产生一个中断事件（自愿中断)，将操作系统转换为核心态，称为访管中断。访管中断由访管指令产生，程序员使用访管指令向操作系统请求服务。</p>
<p>为什么要在程序中引入访管指令呢?这是因为用户程序只能在用户态下运行。若用户程序想要完成在用户态下无法完成的工作，该怎么办﹖解决这个问题要靠访管指令。访管指令本身不是特权指令，其基本功能是让程序拥有“自愿进管”的手段，从而引起访管中断。</p>
<p>处于用户态的用户程序使用访管指令时，系统根据访管指令的操作数执行访管中断处理程序，访管中断处理程序将按系统调用的操作数和参数转到相应的例行子程序。完成服务功能后，退出中断，返回到用户程序断点继续执行。</p>
<h2 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h2><p>【考纲内容】</p>
<p>(一）进程与线程</p>
<p>进程的概念;进程的状态与转换</p>
<p>进程控制;进程组织</p>
<p>进程通信;线程概念与多线程模型</p>
<p>(二）处理机调度</p>
<p>调度的基本概念;调度时机、切换与过程</p>
<p>调度的基本准则;调度方式;典型调度算法</p>
<p>(三）进程同步</p>
<p>进程同步的基本概念</p>
<p>实现临界区互斥的基本方法</p>
<p>信号量;管程;经典同步问题</p>
<p>(四）死锁</p>
<p>死锁的概念;死锁处理策略</p>
<p>死锁预防;死锁避免;死锁的检测和解除</p>
<p>【知识框架】</p>
<ul>
<li>进程<ul>
<li>概念:与程序的区别</li>
<li>特征:动态性、并发性、独立性、异步性、结构性</li>
<li>状态:运行、就绪、阻塞、创建、结束</li>
<li>控制:创建、终止、阻塞和唤醒、切换</li>
<li>组织:进程控制块PCB、程序段、数据段</li>
<li>通信:共享存储、消息传递、管道通信</li>
</ul>
</li>
<li>线程<ul>
<li>概念、与进程的比较、属性</li>
<li>线程的实现方式</li>
</ul>
</li>
<li>处理机调度<ul>
<li>概念、三级调度:作业调度、中级调度、进程调度调度方式:剥夺式、非剥夺式</li>
<li>调度准则:CPU利用率、吞吐量、周转时间、等待时间、响应时间</li>
<li>算法:先来先服务、短作业(SJF）优先、优先级、高响应比优先、时间片轮转、多级反馈队列</li>
</ul>
</li>
<li>进程同步<ul>
<li>概念:临界资源、同步、互斥</li>
<li>实现方法:软件实现的几种算法、硬件实现</li>
<li>信号量:整型、记录型</li>
<li>经典问题:生产者-消费者问题、读者-写者问题、哲学家进餐问题、吸烟者问题</li>
</ul>
</li>
<li>死锁<ul>
<li>定义</li>
<li>原因:系统资源竞争、进程推进顺序非法</li>
<li>条件:互斥、不剥夺、请求和保持、循环等待</li>
<li>策略:预防死锁、避免死锁、死锁的检测与解除</li>
</ul>
</li>
</ul>
<p>【复习提示】</p>
<p>进程管理是操作系统的核心，也是每年必考的重点。其中，进程的概念、进程调度、信号量机制实现同步和互斥、进程死锁等更是重中之重，必须深入掌握。需要注意的是，除选择题外，本章还容易出综合题，其中信号量机制实现同步和互斥、进程调度算法和银行家算法都是可能出现的综合题考点，如利用信号量进行进程同步就在往年的统考中频繁出现。</p>
<p>进程:process</p>
<h3 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h3><p>在学习本节时，请读者思考以下问题:</p>
<p>1）为什么要引入进程?</p>
<p>2）什么是进程?进程由什么组成?</p>
<p>3）进程是如何解决问题的?</p>
<p>希望读者带着上述问题去学习本节内容，并在学习的过程中多思考，从而更深入地理解本节内容。进程本身是一个比较抽象的概念，它不是实物，看不见、摸不着，初学者在理解进程概念时存在一定困难，在介绍完进程的相关知识后，我们会用比较直观的例子帮助大家理解。</p>
<h4 id="进程的概念和特征"><a href="#进程的概念和特征" class="headerlink" title="进程的概念和特征"></a>进程的概念和特征</h4><h5 id="进程的概念"><a href="#进程的概念" class="headerlink" title="进程的概念"></a>进程的概念</h5><p>在多道程序环境下，允许多个程序并发执行，此时它们将失去封闭性，并具有间断性及不可再现性的特征。为此引入了进程（Process）的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性（最基本的两个特性)。</p>
<p>为了使参与并发执行的程序（含数据）能独立地运行，必须为之配置一个专门的数据结构，称为进程控制块（Process Control Block，PCB)。系统利用PCB来描述进程的基本情况和运行状态，进而控制和管理进程。相应地，由程序段、相关数据段和PCB三部分构成了进程映像（进程实体)。所谓创建进程，实质上是创建进程映像中的PCB;而撤销进程,实质上是撤销进程的PCB。值得注意的是，进程映像是静态的，进程则是动态的。</p>
<p>注意:PCB是进程存在的唯一标志!</p>
<p>从不同的角度，进程可以有不同的定义，比较典型的定义有:</p>
<p>1）进程是程序的一次执行过程。</p>
<p>2）进程是一个程序及其数据在处理机上顺序执行时所发生的活动。</p>
<p>3）进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。</p>
<p>引入进程实体的概念后，我们可以把传统操作系统中的进程定义为:“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。”</p>
<p>读者要准确理解这里说的系统资源。它指处理机、存储器和其他设备服务于某个进程的“时间”，例如把处理机资源理解为处理机的时间片才是准确的。因为进程是这些资源分配和调度的独立单位，即“时间片”分配的独立单位，这就决定了进程一定是一个动态的、过程性的概念。</p>
<h5 id="进程的特征"><a href="#进程的特征" class="headerlink" title="进程的特征"></a>进程的特征</h5><p>进程是由多道程序的并发执行而引出的，它和程序是两个截然不同的概念。进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求。</p>
<p>1）动态性。进程是程序的一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。动态性是进程最基本的特征。</p>
<p>2）并发性。指多个进程实体同时存于内存中，能在一段时间内同时运行。并发性是进程的重要特征，同时也是操作系统的重要特征。引入进程的目的就是使程序能与其他进程的程序并发执行，以提高资源利用率。</p>
<p>3）独立性。指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序，都不能作为一个独立的单位参与运行。</p>
<p>4）异步性。由于进程的相互制约，使得进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应的进程同步机制。</p>
<p>5）结构性。每个进程都配置一个PCB对其进行描述。从结构上看，进程实体是由程序段、数据段和进程控制块三部分组成的。</p>
<p>通常不会直接考查进程有什么特性，所以读者对上面的5个特性不求记忆，只求理解。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/67644873/answer/829627104">并发和异步的区别</a></p>
</blockquote>
<h4 id="进程的状态与转换"><a href="#进程的状态与转换" class="headerlink" title="进程的状态与转换"></a>进程的状态与转换</h4><p>进程在其生命周期内，由于系统中各进程之间的相互制约关系及系统的运行环境的变化，使得进程的状态也在不断地发生变化(一个进程会经历若干不同状态)。通常进程有以下5种状态，前3种是进程的基本状态。</p>
<p>1）运行态。进程正在处理机上运行。在单处理机环境下，每个时刻最多只有一个进程处于运行态。</p>
<p>2）就绪态。进程获得了除处理机外的一切所需资源，一旦得到处理机，便可立即运行。系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。</p>
<p>3）阻塞态，又称等待态。进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理机）或等待输入/输出完成。即使处理机空闲，该进程也不能运行。</p>
<p>4）创建态。进程正在被创建，尚未转到就绪态。创建进程通常需要多个步骤:首先申请一个空白的 PCB，并向PCB中填写一些控制和管理进程的信息;然后由系统为该进程分配运行时所必需的资源;最后把该进程转入就绪态。</p>
<p>5）结束态。进程正从系统中消失，可能是进程正常结束或其他原因中断退出运行。进程需要结束运行时，系统首先必须将该进程置为结束态，然后进一步处理资源释放和回收等工作。</p>
<p>注意区别就绪态和等待态:就绪态是指进程仅缺少处理机，只要获得处理机资源就立即运行;而等待态是指进程需要其他资源（除了处理机）或等待某一事件。之所以把处理机和其他资源划分开，是因为在分时系统的时间片轮转机制中，每个进程分到的时间片是若干毫秒。也就是说，进程得到处理机的时间很短且非常频繁，进程在运行过程中实际上是频繁地转换到就绪态的;而其他资源（如外设）的使用和分配或某一事件的发生（如IO操作的完成）对应的时间相对来说很长，进程转换到等待态的次数也相对较少。这样来看，就绪态和等待态是进程生命周期中两个完全不同的状态，显然需要加以区分。</p>
<p>图2.1说明了5种进程状态的转换，而3种基本状态之间的转换如下:</p>
<ul>
<li>就绪态→运行态:处于就绪态的进程被调度后，获得处理机资源（分派处理机时间片)，于是进程由就绪态转换为运行态。 </li>
<li>运行态→就绪态:处于运行态的进程在时间片用完后，不得不让出处理机，从而进程由运行态转换为就绪态。此外，在可剥夺的操作系统中，当有更高优先级的进程就绪时，调度程序将正在执行的进程转换为就绪态，让更高优先级的进程执行。</li>
<li>运行态→阻塞态:进程请求某一资源（如外设）的使用和分配或等待某一事件的发生(如I/O操作的完成）时，它就从运行态转换为阻塞态。进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。</li>
<li>阻塞态→就绪态:进程等待的事件到来时，如IO操作结束或中断结束时，中断处理程序必须把相应进程的状态由阻塞态转换为就绪态。</li>
</ul>
<details><summary>图2.1 5种进程状态的转换</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210808131002.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808131002.png';" /></details>

<p>需要注意的是，一个进程从运行态变成阻塞态是主动的行为，而从阻塞态变成就绪态是被动的行为，需要其他相关进程的协助。</p>
<h4 id="进程控制"><a href="#进程控制" class="headerlink" title="进程控制"></a>进程控制</h4><p>进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。</p>
<h5 id="进程的创建"><a href="#进程的创建" class="headerlink" title="进程的创建"></a>进程的创建</h5><p>允许一个进程创建另一个进程。此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给程。此外，在撤销父进程时，必须同时撤销其所有的子进程。</p>
<p>在操作系统中，终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等都会引起进程的创建。操作系统创建一个新进程的过程如下（创建原语):<br>1）为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB (PCB是有限的)。若申请失败，则创建失败。</p>
<p>2）为进程分配资源，为新进程的程序和数据及用户栈分配必要的内存空间（在PCB中体现)。注意，若资源不足（如内存空间)，则并不是创建失败，而是处于阻塞态，等待内存资源。</p>
<p>3）初始化 PCB，主要包括初始化标志信息、初始化处理机状态信息和初始化处理机控制信息，以及设置进程的优先级等。</p>
<p>4）若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行。</p>
<h5 id="进程的终止"><a href="#进程的终止" class="headerlink" title="进程的终止"></a>进程的终止</h5><p>引起进程终止的事件主要有:①正常结束，表示进程的任务已完成并准备退出运行。②异常结束，表示进程在运行时，发生了某种异常事件，使程序无法继续运行，如存储区越界、保护错、非法指令、特权指令错、运行超时、算术运算错、I/O故障等。③外界干预，指进程应外界的请求而终止运行，如操作员或操作系统干预、父进程请求和父进程终止。</p>
<p>操作系统终止进程的过程如下（撤销原语):</p>
<p>1）根据被终止进程的标识符，检索PCB，从中读出该进程的状态。</p>
<p>2）若被终止进程处于执行状态，立即终止该进程的执行，将处理机资源分配给其他进程。</p>
<p>3）若该进程还有子孙进程，则应将其所有子孙进程终止。</p>
<p>4）将该进程所拥有的全部资源，或归还给其父进程，或归还给操作系统。</p>
<p>5）将该PCB从所在队列（链表）中删除。</p>
<h5 id="进程的阻塞和唤醒"><a href="#进程的阻塞和唤醒" class="headerlink" title="进程的阻塞和唤醒"></a>进程的阻塞和唤醒</h5><p>正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作可做等，由系统自动执行阻塞原语（Block)，使自己由运行态变为阻塞态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程(获得CPU才可能将其转为阻塞态。阻塞原语的执行过程如下:</p>
<p>1）找到将要被阻塞进程的标识号对应的PCB。</p>
<p>2）若该进程为运行态，则保护其现场，将其状态转为阻塞态，停止运行。3）把该PCB插入相应事件的等待队列，将处理机资源调度给其他就绪进程。</p>
<p>当被阻塞进程所期待的事件出现时,如它所启动的IO操作已完成或其所期待的数据已到达，由有关进程（比如，释放该IO 设备的进程，或提供数据的进程）调用唤醒原语（Wakeup)，将等待该事件的进程唤醒。唤醒原语的执行过程如下:</p>
<p>1）在该事件的等待队列中找到相应进程的PCB。</p>
<p>2）将其从等待队列中移出，并置其状态为就绪态。</p>
<p>3）把该PCB插入就绪队列，等待调度程序调度。</p>
<p>需要注意的是，Block原语和 Wakeup原语是一对作用刚好相反的原语，必须成对使用。Block原语是由被阻塞进程自我调用实现的，而 Wakeup原语则是由一个与被唤醒进程合作或被其他相关的进程调用实现的。</p>
<h5 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h5><p>对于通常的进程而言，其创建、撤销及要求由系统设备完成的I/O操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p>
<p>进程切换是指处理机从一个进程的运行转到另一个进程上运行，在这个过程中，进程的运行环境产生了实质性的变化。进程切换的过程如下:</p>
<p>1)）保存处理机上下文，包括程序计数器和其他寄存器。</p>
<p>2）更新PCB信息。</p>
<p>3）把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。</p>
<p>4）选择另一个进程执行，并更新其PCB。</p>
<p>5）更新内存管理的数据结构。</p>
<p>6）恢复处理机上下文。</p>
<blockquote>
<p>注意，进程切换与处理机模式切换是不同的，模式切换时，处理机逻辑上可能还在同一进程中运行。若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的程序运行，则操作系统只需恢复进程进入内核时所保存的CPU现场，而无须改变当前进程的环境信息。但若要切换进程，当前运行进程改变了，则当前进程的环境信息也需要改变。</p>
</blockquote>
<h4 id="进程的组织"><a href="#进程的组织" class="headerlink" title="进程的组织"></a>进程的组织</h4><p>进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。它由以下三部分组成，其中最核心的是进程控制块（PCB)。</p>
<h5 id="进程控制块"><a href="#进程控制块" class="headerlink" title="进程控制块"></a>进程控制块</h5><p>进程创建时，操作系统为它新建一个PCB，该结构之后常驻内存，任意时刻都可以存取，并在进程结束时删除。PCB是进程实体的一部分，是进程存在的唯一标志。</p>
<p>进程执行时，系统通过其 PCB 了解进程的现行状态信息，以便对其进行控制和管理;进程结束时，系统收回其PCB，该进程随之消亡。操作系统通过PCB表来管理和控制进程。</p>
<p>当操作系统欲调度某进程运行时，要从该进程的PCB中查出其现行状态及优先级;在调度到某进程后，要根据其PCB中所保存的处理机状态信息，设置该进程恢复运行的现场，并根据其PCB中的程序和数据的内存始址，找到其程序和数据;进程在运行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也需要访问PCB;当进程由于某种原因而暂停运行时，又需将其断点的处理机环境保存在PCB中。可见，在进程的整个生命期中，系统总是通过PCB对进程进行控制的，亦即系统唯有通过进程的PCB才能感知到该进程的存在。</p>
<p>表2.1是一个PCB 的实例。PCB主要包括进程描述信息、进程控制和管理信息、资源分配清单和处理机相关信息等。各部分的主要说明如下:</p>
<details><summary>表2.1 PCB通常包含的内容</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210808131744.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808131744.png';" /></details>

<p>1）进程描述信息。进程标识符:标志各个进程，每个进程都有一个唯一的标识号。用户标识符:进程归属的用户，用户标识符主要为共享和保护服务。</p>
<p>2）进程控制和管理信息。进程当前状态:描述进程的状态信息，作为处理机分配调度的依据。进程优先级:描述进程抢占处理机的优先级，优先级高的进程可优先获得处理机。</p>
<p>3）资源分配清单，用于说明有关内存地址空间或虚拟地址空间的状况，所打开文件的列表和所使用的输入/输出设备信息。</p>
<p>4）处理机相关信息，主要指处理机中各寄存器的值，当进程被切换时，处理机状态信息都必须保存在相应的PCB中，以便在该进程重新执行时，能从断点继续执行。</p>
<p>在一个系统中，通常存在着许多进程的PCB，有的处于就绪态，有的处于阻塞态，而且阻塞的原因各不相同。为了方便进程的调度和管理，需要将各进程的PCB用适当的方法组织起来。目前，常用的组织方式有链接方式和索引方式两种。链接方式将同一状态的PCB链接成一个队列,不同状态对应不同的队列，也可把处于阻塞态的进程的PCB，根据其阻塞原因的不同，排成多个阻塞队列。索引方式将同一状态的进程组织在一个索引表中，索引表的表项指向相应的PCB，不同状态对应不同的索引表，如就绪索引表和阻塞索引表等。</p>
<h5 id="程序段"><a href="#程序段" class="headerlink" title="程序段"></a>程序段</h5><p>程序段就是能被进程调度程序调度到CPU执行的程序代码段。注意，程序可被多个进程共享，即多个进程可以运行同一个程序。</p>
<h5 id="数据段"><a href="#数据段" class="headerlink" title="数据段"></a>数据段</h5><p>一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。</p>
<h4 id="进程的通信"><a href="#进程的通信" class="headerlink" title="进程的通信"></a>进程的通信</h4><p>进程通信是指进程之间的信息交换。PV操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类。</p>
<h5 id="共享存储"><a href="#共享存储" class="headerlink" title="共享存储"></a>共享存储</h5><p>在通信的进程之间存在一块可直接访问的共享空间,通过对这片共享空间进行写/读操作实现进程之间的信息交换，如图2.2所示。在对共享空间进行写/读操作时，需要使用同步互斥工具(如Р操作、V操作)，对共享空间的写/读进行控制。共享存储又分为两种:低级方式的共享是基于数据结构的共享;高级方式的共享则是基于存储区的共享。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。</p>
<p>注意，用户进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，要想让两个用户进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。</p>
<p>简单理解就是，甲和乙中间有一个大布袋，甲和乙交换物品是通过大布袋进行的，甲把物品放在大布袋里，乙拿走。但乙不能直接到甲的手中拿东西，甲也不能直接到乙的手中拿东西。</p>
<h5 id="消息传递"><a href="#消息传递" class="headerlink" title="消息传递"></a>消息传递</h5><p>在消息传递系统中，进程间的数据交换是以格式化的消息（Message）为单位的。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。进程通过系统提供的发送消息和接收消息两个原语进行数据交换。</p>
<p>1）直接通信方式。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息，如图2.3所示。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210808132052.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808132052.png';" /></details>

<p>2）间接通信方式。发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。</p>
<p>这种中间实体一般称为信箱，这种通信方式又称信箱通信方式。该通信方式广泛应用于计算机网络中，相应的通信系统称为电子邮件系统。<br>简单理解就是，甲要告诉乙某些事情，就要写信，然后通过邮差送给乙。直接通信就是邮差把信直接送到乙的手上;间接通信就是乙家门口有一个邮箱，邮差把信放到邮箱里。</p>
<h5 id="管道通信"><a href="#管道通信" class="headerlink" title="管道通信"></a>管道通信</h5><p>管道通信是消息传递的一种特殊方式（见图2.4)。所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间的通信的一个共享文件，又名pipe文件。向管道(共享文件)提供输入的发送进程（即写进程)，以字符流形式将大量的数据送入(写）管道;而接收管道输出的接收进程（即读进程）则从管道中接收（读）数据。为了协调双方的通信，管道机制必须提供以下三方面的协调能力:互斥、同步和确定对方的存在。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210808132250.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808132250.png';" /></details>

<p>下面以Linux中的管道为例进行说明。在Linux 中，管道是一种使用非常频繁的通信机制。从本质上说，管道也是一种文件，但它又和一般的文件有所不同，管道可以克服使用文件进行通信的两个问题，具体表现如下:</p>
<p>1）限制管道的大小。实际上，管道是一个固定大小的缓冲区。在 Linux中，该缓冲区的大小为4KB，这使得它的大小不像文件那样不加检验地增长。使用单个固定缓冲区也会带来问题，比如在写管道时可能变满，这种情况发生时，随后对管道的 write()调用将默认地被阻塞，等待某些数据被读取，以便腾出足够的空间供 write()调用写。</p>
<p>2）读进程也可能工作得比写进程快。当所有当前进程数据已被读取时，管道变空。当这种情况发生时，一个随后的read()调用将默认地被阻塞,等待某些数据被写入,这解决了read()调用返回文件结束的问题。</p>
<blockquote>
<p>注意:从管道读数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据。管道只能采用半双工通信，即某一时刻只能单向传输。要实现父子进程双方互动通信，需要定义两个管道。</p>
</blockquote>
<p>管道可以理解为共享存储的优化和发展,因为在共享存储中，若某进程要访问共享存储空间则必须没有其他进程在该共享存储空间中进行写操作，否则访问行为就会被阻塞。而管道通信中存储空间进化成了缓冲区，缓冲区只允许一边写入、另一边读出，因此只要缓冲区中有数据，进程就能从缓冲区中读出，而不必担心会因为其他进程在其中进行写操作而遭到阻塞，因为写进程会先把缓冲区写满，然后才让读进程读，当缓冲区中还有数据时，写进程不会往缓冲区写数据。当然，这也决定了管道通信必然是半双工通信。</p>
<h4 id="线程概念和多线程模型"><a href="#线程概念和多线程模型" class="headerlink" title="线程概念和多线程模型"></a>线程概念和多线程模型</h4><h5 id="线程的基本概念"><a href="#线程的基本概念" class="headerlink" title="线程的基本概念"></a>线程的基本概念</h5><p>引入进程的目的是更好地使多道程序并发执行，提高资源利用率和系统吞吐量;而引入线程的目的则是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。</p>
<p>线程最直接的理解就是“轻量级进程”，它是一个基本的CPU执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。</p>
<p>引入线程后，进程的内涵发生了改变，进程只作为除CPU外的系统资源的分配单元，而线程则作为处理机的分配单元。由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。</p>
<h5 id="线程与进程的比较"><a href="#线程与进程的比较" class="headerlink" title="线程与进程的比较"></a>线程与进程的比较</h5><p>1）调度。在传统的操作系统中，拥有资源和独立调度的基本单位都是进程。在引入线程的操作系统中，线程是独立调度的基本单位，进程是拥有资源的基本单位。在同一进程中,线程的切换不会引起进程切换。在不同进程中进行线程切换，如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。</p>
<p>2）拥有资源。不论是传统操作系统还是设有线程的操作系统，进程都是拥有资源的基本单位，而线程不拥有系统资源（也有一点儿必不可少的资源)，但线程可以访问其隶属进程的系统资源。要知道，若线程也是拥有资源的单位，则切换线程就需要较大的时空开销，线程这个概念的提出就没有意义。</p>
<p>3）并发性。在引入线程的操作系统中，不仅进程之间可以并发执行，而且多个线程之间也可以并发执行，从而使操作系统具有更好的并发性，提高了系统的吞吐量。</p>
<p>4）系统开销。由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、IO设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程CPU 环境的保存及新调度到进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现，甚至无须操作系统的干预。</p>
<p>5）地址空间和其他资源（如打开的文件)。进程的地址空间之间互相独立，同一进程的各线程间共享进程的资源，某进程内的线程对于其他进程不可见。</p>
<p>6）通信方面。进程间通信（IPC）需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以直接读/写进程数据段（如全局变量）来进行通信。</p>
<h5 id="线程的属性"><a href="#线程的属性" class="headerlink" title="线程的属性"></a>线程的属性</h5><p>多线程操作系统把线程作为独立运行（或调度）的基本单位，此时的进程已不再是一个基本的可执行实体，但它仍具有与执行相关的状态。所谓进程处于“执行”状态，实际上是指该进程中的某线程正在执行。线程的主要属性如下:</p>
<p>1）线程是一个轻型实体，它不拥有系统资源，但每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。</p>
<p>2）不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。</p>
<p>3)同一进程中的各个线程共享该进程所拥有的资源。</p>
<p>4)线程是处理机的独立调度单位，多个线程是可以并发执行的。在单CPU的计算机系统中，各线程可交替地占用CPU;在多CPU的计算机系统中，各线程可同时占用不同的CPU,若各个CPU同时为一个进程内的各线程服务，则可缩短进程的处理时间。</p>
<p>5）一个线程被创建后，便开始了它的生命周期，直至终止。线程在生命周期内会经历阻塞态、就绪态和运行态等各种状态变化。</p>
<p>为什么线程的提出有利于提高系统并发性?可以这样来理解:由于有了线程，线程切换时，有可能会发生进程切换，也有可能不发生进程切换，平均而言每次切换所需的开销就变小了，因此能够让更多的线程参与并发，而不会影响到响应时间等问题。</p>
<h5 id="线程的实现方式"><a href="#线程的实现方式" class="headerlink" title="线程的实现方式"></a>线程的实现方式</h5><p>线程的实现可以分为两类:用户级线程(User-Level Thread，ULT)和内核级线程(Kernel-LevelThread，KLT)。内核级线程又称内核支持的线程。</p>
<p>在用户级线程中，有关线程管理（线程的创建、撤销和切换等）的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。图2.5(a)说明了用户级线程的实现方式。</p>
<p>在内核级线程中，线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息，调度也在内核基于线程架构的基础上完成。图2.5(b)说明了内核级线程的实现方式。</p>
<p>有些系统中使用组合方式的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些(小于等于用户级线程的数目）内核级线程上。图2.5(c)说明了用户级与内核级的组合实现方式。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210808155557.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210808155557.png';" /></details>


<h5 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h5><p>有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式。</p>
<p>1）多对一模型。将多个用户级线程映射到一个内核级线程，线程管理在用户空间完成。此模式中，用户级线程对操作系统不可见（即透明)。</p>
<p>优点:线程管理是在用户空间进行的，因而效率比较高。</p>
<p>缺点:一个线程在使用内核服务时被阻塞，整个进程都会被阻塞;多个线程不能并行地运行在多处理机上。</p>
<p>2）一对一模型。将每个用户级线程映射到一个内核级线程。</p>
<p>优点:当一个线程被阻塞后，允许另一个线程继续执行，所以并发能力较强。</p>
<p>缺点:每创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。</p>
<p>3）多对多模型。将n个用户级线程映射到m个内核级线程上，要求m≤n。</p>
<p>特点:多对多模型是多对一模型和一对一模型的折中，既克服了多对一模型并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。</p>
<p>此外，还拥有多对一模型和一对一模型各自的优点，可谓集两者之所长。</p>
<h4 id="本节小结"><a href="#本节小结" class="headerlink" title="本节小结"></a>本节小结</h4><h5 id="为什么要引入进程"><a href="#为什么要引入进程" class="headerlink" title="为什么要引入进程?"></a>为什么要引入进程?</h5><p>在多道程序同时运行的背景下，进程之间需要共享系统资源，因此会导致各程序在执行过程中出现相互制约的关系，程序的执行会表现出间断性的特征。这些特征都是在程序的执行过程中发生的，是动态的过程，而传统的程序本身是一组指令的集合，是一个静态的概念，无法描述程序在内存中的执行情况，即我们无法从程序的字面上看出它何时执行、何时停顿，也无法看出它与其他执行程序的关系，因此，程序这个静态概念已不能如实反映程序并发执行过程的特征。为了深刻描述程序动态执行过程的性质乃至更好地支持和管理多道程序的并发执行，人们引入了进程的概念。</p>
<h5 id="什么是进程-进程由什么组成"><a href="#什么是进程-进程由什么组成" class="headerlink" title="什么是进程?进程由什么组成?"></a>什么是进程?进程由什么组成?</h5><p>进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码本身，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。</p>
<p>一个进程实体由程序段、相关数据段和 PCB三部分构成，其中 PCB是标志一个进程存在的唯一标识，程序段是进程运行的程序的代码，数据段则存储程序运行过程中相关的一些数据。</p>
<h5 id="进程是如何解决问题的"><a href="#进程是如何解决问题的" class="headerlink" title="进程是如何解决问题的?"></a>进程是如何解决问题的?</h5><p>进程把能够识别程序运行态的一些变量存放在 PCB中，通过这些变量系统能够更好地了解进程的状况，并在适当时进行进程的切换，以避免一些资源的浪费，甚至划分为更小的调度单位一线程来提高系统的并发度。</p>
<p>本节主要介绍什么是进程，并围绕这个问题进行一些阐述和讨论，为下一节讨论的内容做铺垫，但之前未学过相关课程的读者可能会比较费解，到现在为止对进程这个概念还未形成比较清晰的认识。接下来，我们再用一个比较熟悉的概念来类比进程，以便大家能彻底理解本节的内容到底在讲什么，到底解决了什么问题。</p>
<p>我们用“人的生命历程”来类比进程。首先，人的生命历程一定是一个动态的、过程性的概念，要研究人的生命历程，先要介绍经历这个历程的主体是什么。主体当然是人，相当于经历进程的主体是进程映像，人有自己的身份，相当于进程映像里有PCB;人生历程会经历好几种状态:出生的时候、弥留的时候、充满斗志的时候、发奋图强的时候及失落的时候，相当于进程有创建、撤销、就绪、运行、阻塞等状态，这几种状态会发生改变，人会充满斗志而转向发奋图强，发奋图强获得进步之后又会充满斗志预备下一次发奋图强，或者发奋图强后遇到阻碍会进入失落状态，然后在别人的开导之下又重新充满斗志。类比进程，会由就绪态转向运行态，运行态转向就绪态，或者运行态转向阻塞态，然后在别的进程帮助下返回就绪态。</p>
<p>若我们用“人生历程”这个过程的概念去类比进程，则对进程的理解就会更深一层。前面生活化的例子可以帮我们理解进程的实质，但它毕竟有不严谨的地方。一种较好的方式是，在类比进程和“人生历程”后，再看一遍前面较为严谨的书面阐述和讨论，这样对知识的掌握会更加准确而全面。</p>
<p>这里再给出一些学习计算机科学知识的建议。学习科学知识时，很多同学会陷入一个误区，即只注重对定理、公式的应用，而忽视对基础概念的理解。这是我们从小到大为了应付考试而培养出的一个毛病，因为熟练应用公式和定理对考试有立竿见影的效果。公式、定理的应用固然重要，但基础概念的理解能让我们透彻地理解一门学科，更利于我们产生兴趣，培养创造性思维。</p>
<h3 id="处理机调度"><a href="#处理机调度" class="headerlink" title="处理机调度"></a>处理机调度</h3><p>在学习本节时，请读者思考以下问题:</p>
<p>1)为什么要进行处理机调度?</p>
<p>2）调度算法有哪几种?结合第1章学习的分时操作系统和实时操作系统，思考哪种调度算法比较适合这两种操作系统。</p>
<p>希望读者能够在学习调度算法前，先自己思考一些调度算法，在学习的过程中注意把自己的想法与这些经典的算法进行比对，并学会计算一些调度算法的周转时间。</p>
<h4 id="调度的概念"><a href="#调度的概念" class="headerlink" title="调度的概念"></a>调度的概念</h4><h5 id="调度的基本概念"><a href="#调度的基本概念" class="headerlink" title="调度的基本概念"></a>调度的基本概念</h5><p>在多道程序系统中，进程的数量往往多于处理机的个数，因此进程争用处理机的情况在所难免。处理机调度是对处理机进行分配，即从就绪队列中按照一定的算法（公平、高效）选择一个进程并将处理机分配给它运行，以实现进程并发地执行。</p>
<p>处理机调度是多道程序操作系统的基础，是操作系统设计的核心问题。</p>
<h5 id="调度的层次"><a href="#调度的层次" class="headerlink" title="调度的层次"></a>调度的层次</h5><p>一个作业从提交开始直到完成，往往要经历以下三级调度，如图2.6所示。</p>
<p>1）作业调度。又称高级调度，其主要任务是按一定的原则从外存上处于后备状态的作业中挑选一个(或多个）作业，给它（们）分配内存、输入/输出设备等必要的资源，并建立相应的进程，以使它（们）获得竞争处理机的权利。简言之，作业调度就是内存与辅存之间的调度。对于每个作业只调入一次、调出一次。<br>多道批处理系统中大多配有作业调度，而其他系统中通常不需要配置作业调度。作业调度的执行频率较低，通常为几分钟一次。</p>
<p>2）中级调度。又称内存调度，其作用是提高内存利用率和系统吞吐量。为此，应将那些暂时不能运行的进程调至外存等待，把此时的进程状态称为挂起态。当它们已具备运行条件且内存又稍有空闲时，由中级调度来决定把外存上的那些已具备运行条件的就绪进程再重新调入内存，并修改其状态为就绪态，挂在就绪队列上等待。</p>
<p>3）进程调度。又称低级调度，其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给它。进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度。进程调度的频率很高，一般几十毫秒一次。</p>
<details><summary>图2.6处理机的三级调度</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210924232351.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924232351.png';" /></details>

<h5 id="三级调度的联系"><a href="#三级调度的联系" class="headerlink" title="三级调度的联系"></a>三级调度的联系</h5><p>作业调度从外存的后备队列中选择一批作业进入内存，为它们建立进程，这些进程被送入就绪队列，进程调度从就绪队列中选出一个进程，并把其状态改为运行态，把CPU分配给它。中级调度是为了提高内存的利用率，系统将那些暂时不能运行的进程挂起来。当内存空间宽松时，通过中级调度选择具备运行条件的进程，将其唤醒。</p>
<p>1）作业调度为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。</p>
<p>2）作业调度次数少，中级调度次数略多，进程调度频率最高。</p>
<p>3）进程调度是最基本的，不可或缺。</p>
<h4 id="调度的时机、切换与过程"><a href="#调度的时机、切换与过程" class="headerlink" title="调度的时机、切换与过程"></a>调度的时机、切换与过程</h4><p>进程调度和切换程序是操作系统内核程序。请求调度的事件发生后，才可能运行进程调度程序，调度了新的就绪进程后，才会进行进程间的切换。理论上这三件事情应该顺序执行，但在实际设计中，操作系统内核程序运行时，若某时发生了引起进程调度的因素，则不一定能够马上进行调度与切换。</p>
<p>现代操作系统中，不能进行进程的调度与切换的情况有以下几种:</p>
<p>1)在处理中断的过程中。中断处理过程复杂，在实现上很难做到进程切换，而且中断处理是系统工作的一部分，逻辑上不属于某一进程，不应被剥夺处理机资源。</p>
<p>2）进程在操作系统内核程序临界区中。进入临界区后，需要独占式地访问共享数据，理论上必须加锁，以防止其他并行程序进入，在解锁前不应切换到其他进程运行，以加快该共享数据的释放。</p>
<p>3）其他需要完全屏蔽中断的原子操作过程中。如加锁、解锁、中断现场保护、恢复等原子操作。在原子过程中，连中断都要屏蔽，更不应该进行进程调度与切换。</p>
<p>若在上述过程中发生了引起调度的条件，则不能马上进行调度和切换，应置系统的请求调度标志，直到上述过程结束后才进行相应的调度与切换。</p>
<p>应该进行进程调度与切换的情况如下:</p>
<p>1）发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度与切换。若操作系统只在这种情况下进行进程调度，则是非剥夺调度。</p>
<p>2）中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。若操作系统支持这种情况下的运行调度程序，则实现了剥夺方式的调度。</p>
<p>进程切换往往在调度完成后立刻发生，它要求保存原进程当前切换点的现场信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将原进程的现场信息推入当前进程的内核堆栈来保存它们，并更新堆栈指针。内核完成从新进程的内核栈中装入新进程的现场信息、更新当前运行进程空间指针、重设PC寄存器等相关工作之后，开始运行新的进程。</p>
<h4 id="进程调度方式"><a href="#进程调度方式" class="headerlink" title="进程调度方式"></a>进程调度方式</h4><p>所谓进程调度方式，是指当某个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要处理，即有优先权更高的进程进入就绪队列，此时应如何分配处理机。</p>
<p>通常有以下两种进程调度方式:</p>
<p>1）非剥夺调度方式，又称非抢占方式。非剥夺调度方式是指当一个进程正在处理机上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行直到该进程完成或发生某种事件而进入阻塞态时，才把处理机分配给更为重要或紧迫的进程。</p>
<p>在非剥夺调度方式下，一旦把CPU分配给一个进程，该进程就会保持CPU直到终止或转换到等待态。这种方式的优点是实现简单、系统开销小，适用于大多数的批处理系统但它不能用于分时系统和大多数的实时系统。</p>
<p>2）剥夺调度方式，又称抢占方式。剥夺调度方式是指当一个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给这个更为重要或紧迫的进程。</p>
<p>采用剥夺式的调度，对提高系统吞吐率和响应效率都有明显的好处。但“剥夺”不是一种任意性行为，必须遵循一定的原则，主要有优先权、短进程优先和时间片原则等。</p>
<h4 id="调度的基本准则"><a href="#调度的基本准则" class="headerlink" title="调度的基本准则"></a>调度的基本准则</h4><p>不同的调度算法具有不同的特性，在选择调度算法时，必须考虑算法的特性。为了比较处理机调度算法的性能，人们提出了很多评价准则，下面介绍其中主要的几种:</p>
<p>1)CPU利用率。CPU是计算机系统中最重要和昂贵的资源之一，所以应尽可能使CPU保持“忙”状态，使这一资源利用率最高。</p>
<p>2)系统吞吐量。表示单位时间内CPU完成作业的数量。长作业需要消耗较长的处理机时间,因此会降低系统的吞吐量。而对于短作业，它们所需要消耗的处理机时间较短，因此能提高系统的吞吐量。调度算法和方式的不同，也会对系统的吞吐量产生较大的影响。3）周转时间。周转时间是指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行及进行输入/输出操作所花费时间的总和。</p>
<p>作业的周转时间可用公式表示如下:</p>
<p style='text-align:center'>周转时间=作业完成时间-作业提交时间</p>

<p>平均周转时间是指多个作业周转时间的平均值:</p>
<p style='text-align:center'>平均周转时间=（作业1的周转时间+…+作业 $n$ 的周转时间）/ $n$ </p>

<p>带权周转时间是指作业周转时间与作业实际运行时间的比值:</p>
<p style='text-align:center'> $\text{带权周转时间}=\dfrac{\text{作业周转时间}}{作业实际运行时间}$ </p>

<p>平均带权周转时间是指多个作业带权周转时间的平均值:</p>
<p style='text-align:center'>平均带权周转时间=（作业1的带权周转时间+..+作业 $n$ 的带权周转时间）/ $n$ </p>

<p>4）等待时间。等待时间指进程处于等处理机状态的时间之和，等待时间越长，用户满意度越低。处理机调度算法实际上并不影响作业执行或输入/输出操作的时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法的优劣，常常只需简单地考察等待时间。</p>
<p>5）响应时间。响应时间指从用户提交请求到系统首次产生响应所用的时间。在交互式系统中，周转时间不可能是最好的评价准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能接受的范围之内。</p>
<p>要想得到一个满足所有用户和系统要求的算法几乎是不可能的。设计调度程序，一方面要满足特定系统用户的要求（如某些实时和交互进程的快速响应要求)，另一方面要考虑系统整体效率（如减少整个系统的进程平均周转时间)，同时还要考虑调度算法的开销。</p>
<h4 id="典型的调度算法"><a href="#典型的调度算法" class="headerlink" title="典型的调度算法"></a>典型的调度算法</h4><h5 id="先来先服务-FCFS-调度算法"><a href="#先来先服务-FCFS-调度算法" class="headerlink" title="先来先服务(FCFS)调度算法"></a>先来先服务(FCFS)调度算法</h5><p>FCFS 调度算法是一种最简单的调度算法，它既可用于作业调度，又可用于进程调度。在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。</p>
<p>在进程调度中，FCFS 调度算法每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，使之投入运行，直到完成或因某种原因而阻塞时才释放处理机。</p>
<p>下面通过一个实例来说明FCFS调度算法的性能。假设系统中有4个作业，它们的提交时间分别是8,8.4,8.8,9，运行时间依次是2,1,0.5,0.2，系统采用FCFS调度算法，这组作业的平均等待时间、平均周转时间和平均带权周转时间见表2.2。</p>
<details><summary>表2.2 FCFS调度算法的性能</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210924234106.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924234106.png';" /></details>

<p>FCFS 调度算法属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业先到达系统，就会使后面的许多短作业等待很长时间，因此它不能作为分时系统和实时系统的主要调度策略。但它常被结合在其他调度策略中使用。例如，在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按FCFS原则处理。</p>
<p>FCFS 调度算法的特点是算法简单，但效率低;对长作业比较有利，但对短作业不利（相对SJF和高响应比);有利于CPU繁忙型作业，而不利于I/O繁忙型作业。</p>
<h5 id="短作业优先-SJF-调度算法"><a href="#短作业优先-SJF-调度算法" class="headerlink" title="短作业优先(SJF)调度算法"></a>短作业优先(SJF)调度算法</h5><p>短作业（进程）优先调度算法是指对短作业（进程）优先调度的算法。短作业优先（SJF)调度算法从后备队列中选择一个或若干估计运行时间最短的作业，将它们调入内存运行;短进程优先(SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或发生某事件而阻塞时，才释放处理机。</p>
<p>例如，考虑表2.2中给出的一组作业，若系统采用短作业优先调度算法，其平均等待时间、平均周转时间和平均带权周转时间见表2.3。</p>
<details><summary>表2.3SJF调度算法的性能</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210924234230.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924234230.png';" /></details>

<p>SJF调度算法也存在不容忽视的缺点:</p>
<p>1）该算法对长作业不利，由表2.2和表2.3可知，SJF调度算法中长作业的周转时间会增加更严重的是，若有一长作业进入系统的后备队列，由于调度程序总是优先调度那些（E使是后进来的）短作业，将导致长作业长期不被调度（“饥饿”现象，注意区分“死锁”后者是系统环形等待，前者是调度策略问题)。</p>
<p>2）该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业会被及时处理。</p>
<p>3）由于作业的长短只是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。</p>
<blockquote>
<p>注意，SJF调度算法的平均等待时间、平均周转时间最少。</p>
</blockquote>
<h5 id="优先级调度算法"><a href="#优先级调度算法" class="headerlink" title="优先级调度算法"></a>优先级调度算法</h5><p>优先级调度算法又称优先权调度算法，它既可用于作业调度，又可用于进程调度。该算法中的优先级用于描述作业运行的紧迫程度。</p>
<p>在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最高的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。</p>
<p>根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为如下两种:</p>
<p>1）非剥夺式优先级调度算法。当一个进程正在处理机上运行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件)，才把处理机分配给更为重要或紧迫的进程。</p>
<p>2）剥夺式优先级调度算法。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。</p>
<p>而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种:</p>
<p>1）静态优先级。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。</p>
<p>2）动态优先级。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据有进程占有CPU时间的长短、就绪进程等待CPU时间的长短。</p>
<p>一般来说，进程优先级的设置可以参照以下原则:</p>
<p>1）系统进程&gt;用户进程。系统进程作为系统的管理者，理应拥有更高的优先级。</p>
<p>2）交互型进程&gt;非交互型进程（或前台进程&gt;后台进程)。大家平时在使用手机时，在前台运行的正在和你交互的进程应该更快速地响应你，因此自然需要被优先处理，即要有更高的优先级。</p>
<p>3)I/O型进程&gt;计算型进程。所谓IO型进程，是指那些会频繁使用IO设备的进程，而计算型进程是那些频繁使用CPU的进程（很少使用I/O设备)。我们知道，IO设备（如打印机）的处理速度要比CPU慢得多，因此若将IO型进程的优先级设置得更高，就更有可能让IO设备尽早开始工作，进而提升系统的整体效率。</p>
<h5 id="高响应比优先调度算法"><a href="#高响应比优先调度算法" class="headerlink" title="高响应比优先调度算法"></a>高响应比优先调度算法</h5><p>高响应比优先调度算法主要用于作业调度，是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑了每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。</p>
<p>响应比的变化规律可描述为</p>
<p style='text-align:center'> $\text{响应比}R_p=\dfrac{\text{等待时间}+\text{要求服务时间}}{\text{要求服务时间}}$ </p>

<p>根据公式可知：<br>1）作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业。</p>
<p>2）要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高,因而它实现的是先来先服务。</p>
<p>3）对于长作业，作业的响应比可以随等待时间的增加而提高，等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。因此，克服了饥饿状态，兼顾了长作业。</p>
<h5 id="时间片轮转调度算法"><a href="#时间片轮转调度算法" class="headerlink" title="时间片轮转调度算法"></a>时间片轮转调度算法</h5><p>时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中的第一个进程执行，即先来先服务的原则，但仅能运行一个时间片，如100ms。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等候再次运行。</p>
<p>在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。若时间片很小，则处理机将在进程间过于频繁地切换，使处理机的开销增大，而真正用于运行用户进程的时间将减少。因此，时间片的大小应选择适当。</p>
<p>时间片的长短通常由以下因素确定:系统的响应时间、就绪队列中的进程数目和系统的处理能力。</p>
<h5 id="多级反馈队列调度算法（融合了前几种算法的优点）"><a href="#多级反馈队列调度算法（融合了前几种算法的优点）" class="headerlink" title="多级反馈队列调度算法（融合了前几种算法的优点）"></a>多级反馈队列调度算法（融合了前几种算法的优点）</h5><p>多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合与发展，如图2.7所示。通过动态调整进程优先级和时间片大小,多级反馈队列调度算法可以兼顾多方面的系统目标。例如，为提高系统吞吐量和缩短平均周转时间而照顾短进程;为获得较好的IO设备利用率和缩短响应时间而照顾IO型进程;同时，也不必事先估计进程的执行时间。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210924234833.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210924234833.png';" /></details>

<p>多级反馈队列调度算法的实现思想如下:</p>
<p>1）设置多个就绪队列，并为各个队列赋予不同的优先级，第1级队列的优先级最高，第2级队列次之，其余队列的优先级逐次降低。</p>
<p>2）赋予各个队列中进程执行时间片的大小各不相同。在优先级越高的队列中，每个进程的运行时间片越小。例如，第2级队列的时间片要比第1级队列的时间片长1倍……第 $i$ +1级队列的时间片要比第 $i$ 级队列的时间片长1倍。</p>
<p>3）一个新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则排队等待调度当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统;若它在一个时间片结束时尚未完成，调度程序便将该进程转入第2级队列的末尾，再同样按FCFS原则等待调度执行;若它在第2级队列中运行一个时间片后仍未完成，再以同样的方法放入第3级队列……如此下去，当一个长进程从第1级队列依次降到第 $n$ 级队列后，在第 $n$ 级队列中便采用时间片轮转的方式运行。</p>
<p>4)仅当第1级队列为空时，调度程序才调度2级队列中的进程运行;仅当第1~( $i$ -1)级队列均为空时，才会调度第 $i$ 级队列中的进程运行。若处理机正在执行第 $i$ 级队列中的某进程，这时又有新进程进入优先级较高的队列〔第1～( $i$ -1)中的任何一个队列]，则此时新进程将抢占正在运行进程的处理机,即由调度程序把正在运行的进程放回第i级队列的末尾，把处理机分配给新到的更高优先级的进程。</p>
<p>多级反馈队列的优势有以下几点:</p>
<p>1)终端型作业用户:短作业优先。</p>
<p>2）短批处理作业用户:周转时间较短。</p>
<p>3）长批处理作业用户:经过前面几个队列得到部分执行，不会长期得不到处理。</p>
<h4 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h4><p>本节开头提出的问题的参考答案如下。</p>
<p>1）为什么要进行处理机调度?</p>
<p>若没有处理机调度，同意味着要等到当前运行的进程执行完毕后，下一个进程才能执行，而实际情况中，进程时常需要等待一些外部设备的输入，而外部设备的速度与处理机相比是非常缓慢的，若让处理机总是等待外部设备，则对处理机的资源是极大的浪费。而引进处理机调度后，可在运行进程等待外部设备时，把处理机调度给其他进程，从而提高处理机的利用率。用一句简单的话说，就是为了合理地处理计算机的软/硬件资源。</p>
<p>2）调度算法有哪几种?结合第1章学习的分时操作系统和实时操作系统，思考有没有哪种调度算法比较适合这两种操作系统。</p>
<p>本节介绍的调度算法有先来先服务调度算法、短作业优先调度算法、优先级调度算法、高响应比优先调度算法、时间片轮转调度算法、多级反馈队列调度算法6种。</p>
<p>先来先服务算法和短作业优先算法无法保证及时地接收和处理问题，因此尤法休证仕规疋时时间间隔内响应每个用户的需求，也同样无法达到实时操作系统的及的性而水。优兀级A度开仫按照任务的优先级进行调度，对于更紧急的任务给予更高的优先级，适合实时操作系统。</p>
<p>高响应比优先调度算法、时间片轮转调度算法、多级反馈队列调度算法都能保证每个任务在一定时间内分配到时间片，并轮流占用CPU，适合分时操作系统。</p>
<p>本节主要介绍了处理机调度的概念。操作系统主要管理处理机、内存、文件、设备几种资源，只要对资源的请求大于资源本身的数量，就会涉及调度。例如，在单处理机系统中，处理机只有一个，而请求服务的进程却有多个，所以就有处理机调度的概念出现。而出现调度的概念后，又有了一个问题，即如何调度、应该满足谁、应该让谁等待，这是调度算法所回答的问题;而应该满足谁、应该让谁等待，要遵循一定的准则，即调度的准则。调度这一概念贯穿于操作系统的始终，读者在接下来的学习中，将接触到几种资源的调度问题和相应的调度算法。将它们与处理机调度的内容相对比，将会发现它们有异曲同工之妙。</p>
<h3 id="进程同步"><a href="#进程同步" class="headerlink" title="进程同步"></a>进程同步</h3><p>在学习本节时，请读者思考以下问题:</p>
<p>1）为什么要引入进程同步的概念?</p>
<p>2）不同的进程之间会存在什么关系?</p>
<p>3）当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗?</p>
<p>用PV操作解决进程之间的同步互斥问题是这一节的重点，考试已经多次考查过这一内容，读者务必多加练习，掌握好求解问题的方法。</p>
<h4 id="进程同步的基本概念"><a href="#进程同步的基本概念" class="headerlink" title="进程同步的基本概念"></a>进程同步的基本概念</h4><p>在多道程序环境下，进程是并发执行的，不同进程之间存在着不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。下面举一个简单的例于米帮大豕理解赵个概念。例如，让系统计算1+2x3，假设系统产生两个进程:一个是加法进程，一个是乘法进程。要让计算结果是正确的，一定要让加法进程发生在乘法进程之后，但实际上操作系统具有异步性，若不加以制约，加法进程发生在乘法进程之前是绝对有可能的，因此要制定一定的机制去约束加法进程，让它在乘法进程完成之后才发生，而这种机制就是本节要讨论的内容。</p>
<h5 id="临界资源"><a href="#临界资源" class="headerlink" title="临界资源"></a>临界资源</h5><p>虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，我们将一次仅允许一个进程使用的资源称为临界资源。许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。</p>
<p>对临界资源的访问，必须互斥地进行，在每个进程中，访问临界资源的那段代码称为临界区。为了保证临界资源的正确使用，可把临界资源的访问过程分成4个部分:</p>
<p>1）进入区。为了进入临界区使用临界资源，在进入区要检查可否进入临界区，若能进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。</p>
<p>2)临界区。进程中访问临界资源的那段代码，又称临界段。</p>
<p>3）退出区。将正在访问临界区的标志清除。</p>
<p>4）剩余区。代码中的其余部分。</p>
<details><summary>代码详情</summary>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">do&#123;</span><br><span class="line">  entry section; &#x2F;&#x2F;进入区</span><br><span class="line">  critical section; &#x2F;&#x2F;临界区</span><br><span class="line">  exit section;&#x2F;&#x2F;退出区</span><br><span class="line">  remainder section;&#x2F;&#x2F;剩余区</span><br><span class="line">&#125; while (true)</span><br></pre></td></tr></table></figure>
</details>

<h5 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h5><p>同步亦称直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系源于它们之间的相互合作。</p>
<p>例如，输入进程A通过单缓冲向进程B提供数据。当该缓冲区空时，进程B不能获得所需数据而阻塞，一旦进程A将数据送入缓冲区，进程B就被唤醒。反之，当缓冲区满时，进程A被阻塞，仅当进程B取走缓冲数据时，才唤醒进程A。</p>
<h5 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h5><p>互斥也称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。</p>
<p>例如，在仅有一台打印机的系统中，有两个进程A和进程B，若进程A需要打印时，系统已将打印机分配给进程B，则进程A必须阻塞。一旦进程B将打印机释放，系统便将进程唤醒，并将其由阻塞态变为就绪态。</p>
<p>为禁止两个进程同时进入临界区，同步机制应遵循以下准则:</p>
<p>1)）空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。</p>
<p>2）忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。</p>
<p>3）有限等待。对请求访问的进程，应保证能在有限时间内进入临界区。</p>
<p>4）让权等待。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。</p>
<h4 id="实现临界区互斥的基本方法"><a href="#实现临界区互斥的基本方法" class="headerlink" title="实现临界区互斥的基本方法"></a>实现临界区互斥的基本方法</h4><h5 id="软件实现方法"><a href="#软件实现方法" class="headerlink" title="软件实现方法"></a>软件实现方法</h5><p>在进入区设置并检查一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。</p>
<p>1）算法一:单标志法。该算法设置一个公用整型变量turn，用于指示被允许进入临界区的进程编号，即若turn=0，则允许P进程进入临界区。该算法可确保每次只允许一个进程进入临界区。但两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也将无法进入临界区（违背“空闲让进”)。这样很容易造成资源利用不充分。若P顺利进入临界区并从临界区离开，则此时临界区是空闲的，但P并没有进入临界区的打算，turn=1一直成立，P。就无法再次进入临界区（一直被while死循环困住)。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000015.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000015.png';" /></details>

<p>2）算法二:双标志法先检查。该算法的基本思想是在每个进程访问临界区资源之前，先查看临界资源是否正被访问，若正被访问，该进程需等待;否则，进程才进入自己的临界区。为此，设置一个数据flag[ $i$ ]，如第i个元素值为FALSE，表示 $P_i$ 进程未进入临界区，值为TRUE，表示P进程进入临界区。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000115.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000115.png';" /></details>

<p>优点:不用交替进入，可连续使用;缺点: $P_i$ 和 $P_j$ ,可能同时进入临界区。按序列①② ${\textstyle\unicode{x2462}}$ ${\textstyle\unicode{x2463}}$  执行时，会同时进入临界区（违背“忙则等待”)。即在检查对方的 flag 后和切换自己的flag前有一段时间，结果都检查通过。这里的问题出在检查和修改操作不能一次进行。</p>
<p>3）算法三:双标志法后检查。算法二先检测对方的进程状态标志，再置自己的标志，由在检测和放置中可插入另一个进程到达时的检测操作，会造成两个进程在分别检测后同时进入临界区。为此，算法三先将自己的标志设置为 TRUE，再检测对方的状态标志，若对方标志为TRUE，则进程等待;否则进入临界区。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000242.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000242.png';" /></details>

<p>两个进程几乎同时都想进入临界区时，它们分别将自己的标志值 flag 设置为 TRUE，并且同时检测对方的状态（执行while语句)，发现对方也要进入临界区时，双方互相谦让，结果谁也进不了临界区，从而导致“饥饿”现象。</p>
<p>4）算法四:Peterson’s Algorithm。为了防止两个进程为进入临界区而无限期等待，又设置变量 turn，每个进程在先设置自己的标志后再设置turn标志。这时，再同时检测另一个进程状态标志和不允许进入标志，以便保证两个进程同时要求进入临界区时，只允许个进程进入临界区。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000331.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000331.png';" /></details>

<p>具体如下:考虑进程P;，一旦设置flag[ $i$ ] = true，就表示它想要进入临界区，同时turn =j,此时若进程P,已在临界区中，符合进程 $P_i$ 中的while循环条件，则 $P_i$ 不能进入临界区。若 $P_j$ 不想要进入临界区，即 flag[ $j$ ] = false，循环条件不符合，则 $P_i$ 可以顺利进入，反之亦然。本算法的基本思想是算法一和算法三的结合。利用flag解决临界资源的互斥访问，而利用turn解决“饥饿”现象。</p>
<p>理解Peterson’s Algorithm的最好方法就是手动模拟。</p>
<h5 id="硬件实现方法"><a href="#硬件实现方法" class="headerlink" title="硬件实现方法"></a>硬件实现方法</h5><p>理解本节介绍的硬件实现，对学习后面的信号量很有帮助。计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或对两个字的内容进行交换等。通过硬件支持实现临界段问题的方法称为低级方法，或称元方法。</p>
<p>(1）中断屏蔽方法</p>
<p>当一个进程正在使用处理机执行它的临界区代码时，防止其他进程进入其临界区进行访问的最简方法是，禁止一切中断发生，或称之为屏蔽中断、关中断。因为CPU只在发生中断时引起进程切换，因此屏蔽中断能够保证当前运行的进程让临界区代码顺利地执行完，进而保证互斥的正确实现，然后执行开中断。其典型模式为</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000605.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000605.png';" /></details>

<p>这种方法限制了处理机交替执行程序的能力，因此执行的效率会明显降低。对内核来说，在它执行更新变量或列表的几条指令期间，关中断是很方便的，但将关中断的权力交给用户则很不明智，若一个进程关中断后不再开中断，则系统可能会因此终止。</p>
<p>(2）硬件指令方法</p>
<p>TestAndSet 指令:这条指令是原子操作，即执行该代码时不允许被中断。其功能是读出指定标志后把该标志设置为真。指令的功能描述如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000736.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000736.png';" /></details>

<p>可以为每个临界资源设置一个共享布尔变量lock，表示资源的两种状态: true表示正被占用，初值为false。在进程访问临界资源之前，利用TestAndSet检查和修改标志lock;若有进程在临界区，则重复检查，直到进程退出。利用该指令实现进程互斥的算法描述如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000758.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000758.png';" /></details>

<p>Swap指令:该指令的功能是交换两个字（字节）的内容。其功能描述如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925000817.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925000817.png';" /></details>

<blockquote>
<p>注意:以上对TestAndSet和Swap指令的描述仅是功能实现，而并非软件实现的定义。事实上，它们是由硬件逻辑直接实现的，不会被中断。</p>
</blockquote>
<p>应为每个临界资源设置一个共享布尔变量lock，初值为false;在每个进程中再设置一个局部布尔变量 key，用于与lock交换信息。在进入临界区前，先利用Swap 指令交换lock 与 key的内容，然后检查key 的状态;有进程在临界区时，重复交换和检查过程，直到进程退出。利用Swap指令实现进程互斥的算法描述如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925001048.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001048.png';" /></details>

<p>硬件方法的优点:适用于任意数目的进程，而不管是单处理机还是多处理机;简单、容易验证其正确性。可以支持进程内有多个临界区，只需为每个临界区设立一个布尔变量。</p>
<p>硬件方法的缺点:进程等待进入临界区时要耗费处理机时间，不能实现让权等待。从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致“饥饿”现象。</p>
<p>无论是软件实现方法还是硬件实现方法，读者只需理解它的执行过程即可，关键是软件实现方法。实际练习和考试中很少让读者写出某种软件和硬件实现方法，因此读者并不需要默写或记忆。以上的代码实现与我们平时在编译器上写的代码意义不同，以上的代码实现是为了表述进程实现同步和互斥的过程，并不是说计算机内部实现同步互斥的就是这些代码。</p>
<h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>信号量机制是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准的原语wait(S)和 signal(S)访问，也可记为“P操作”和“V操作”。</p>
<p>原语是指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件来实现。例如,前述的Test-and-Set和Swap指令就是由硬件实现的原子操作。原语功能的不被中断执行特性在单处理机上可由软件通过屏蔽中断方法实现。</p>
<p>原语之所以不能被中断执行，是因为原语对变量的操作过程若被打断，可能会去运行另一个对同一变量的操作过程，从而出现临界段问题。若能够找到一种解决临界段问题的元方法，就可以实现对共享变量操作的原子性。</p>
<h5 id="整型信号量"><a href="#整型信号量" class="headerlink" title="整型信号量"></a>整型信号量</h5><p>整型信号量被定义为一个用于表示资源数目的整型量S，wait和 signal操作可描述为</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925001244.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001244.png';" /></details>

<p>wait 操作中，只要信号量S≤0，就会不断地测试。因此，该机制并未遵循“让权等待”的准则，而是使进程处于“忙等”的状态。</p>
<h5 id="记录型信号量"><a href="#记录型信号量" class="headerlink" title="记录型信号量"></a>记录型信号量</h5><p>记录型信号量是不存在“忙等”现象的进程同步机制。除需要一个用于代表资源数目的整型变量value 外，再增加一个进程链表L，用于链接所有等待该资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925001447.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001447.png';" /></details>

<p>相应的 wait(S)和 signal(S)的操作如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925001545.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925001545.png';" /></details>

<p>wait操作，S.value–表示进程请求一个该类资源，当S.value &lt;0时，表示该类资源已分配完毕，因此进程应调用block 原语，进行自我阻塞，放弃处理机，并插入该类资源的等待队列S.L，可见该机制遵循了“让权等待”的准则。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925095037.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925095037.png';" /></details>

<p>signal操作,表示进程释放一个资源,使系统中可供分配的该类资源数增1,因此有S.value ++。若加1后仍是S.value≤0，则表示在S.L中仍有等待该资源的进程被阻塞，因此还应调用wakeup原语，将S.L中的第一个等待进程唤醒。</p>
<h5 id="利用信号量实现同步"><a href="#利用信号量实现同步" class="headerlink" title="利用信号量实现同步"></a>利用信号量实现同步</h5><p>信号量机制能用于解决进程间的各种同步问题。设S为实现进程 $P_1$ , $P_2$ 同步的公共信号量，初值为0。进程 $P_2$ 中的语句y要使用进程 $P_1$ 中语句x的运行结果，所以只有当语句x执行完成之后语句y 才可以执行。其实现进程同步的算法如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925095158.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925095158.png';" /></details>

<p>若 $P_2$ 先执行到P(S)时，S为0，执行Р操作会把进程 $P_2$ 阻塞，并放入阻塞队列;当进程 $P_1$ 中的x执行完后，执行V操作，把 $P_2$ 从阻塞队列中放回就绪队列，当 $P_2$ 得到处理机时，就得以继续执行。</p>
<h5 id="利用信号量实现进程互斥"><a href="#利用信号量实现进程互斥" class="headerlink" title="利用信号量实现进程互斥"></a>利用信号量实现进程互斥</h5><p>信号量机制也能很方便地解决进程互斥问题。设S为实现进程 $P_1$ , $P_2$ 互斥的信号量，由于每次只允许一个进程进入临界区﹐所以S的初值应为1(即可用资源数为1)。只需把临界区置于P(S)和V(S)之间，即可实现两个进程对临界资源的互斥访问。其算法如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925095407.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925095407.png';" /></details>

<p>当没有进程在临界区时，任意一个进程要进入临界区，就要执行Р操作，把S的值减为0，然后进入临界区;当有进程存在于临界区时，S的值为0，再有进程要进入临界区，执行Р操作时将会被阻塞，直至在临界区中的进程退出，这样便实现了临界区的互斥。</p>
<p>互斥是不同进程对同一信号量进行P,V操作实现的，一个进程成功对信号量执行了Р操作后进入临界区，并在退出临界区后，由该进程本身对该信号量执行V操作，表示当前没有进程进入临界区，可以让其他进程进入。</p>
<p>下面简单总结一下PV操作在同步互斥中的应用:在同步问题中，若某个行为要用到某种资源，则在这个行为前面Р这种资源一下;若某个行为会提供某种资源，则在这个行为后面V这种资源一下。在互斥问题中，P, V操作要紧夹使用互斥资源的那个行为，中间不能有其他冗余代码。</p>
<h5 id="利用信号量实现前驱关系"><a href="#利用信号量实现前驱关系" class="headerlink" title="利用信号量实现前驱关系"></a>利用信号量实现前驱关系</h5><details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925100154.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925100154.png';" /></details>

<p>信号量也可用来描述程序之间或语句之间的前驱关系。图2.8给出了一个前驱图，其中 $S_1$ , $S_2$ , $S_3$ ,… , $S_6$ 是最简单的程序段(只有一条语句)。为使各程序段能正确执行，应设置若干初始值为“0”的信号量。例如，为保证 $S_1$ → $S_2$ , $S_1$ → $S_3$ 的前驱关系，应分别设置信号量al, a2。同样，为保证 $S_2$ → $S_4$ , $S_2$ → $S_5$ ,  $S_5$ → $S_6$ ,  $S_4$ → $S_6$ ,  $S_5$ → $S_6$ ，应设置信号量b1, b2,c, d,e。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925100516.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925100516.png';" /></details>

<h5 id="分析进程同步和互斥问题的方法步骤"><a href="#分析进程同步和互斥问题的方法步骤" class="headerlink" title="分析进程同步和互斥问题的方法步骤"></a>分析进程同步和互斥问题的方法步骤</h5><p>1）关系分析。找出问题中的进程数，并分析它们之间的同步和互斥关系。同步、互斥、前驱关系直接按照上面例子中的经典范式改写。</p>
<p>2）整理思路。找出解决问题的关键点，并根据做过的题目找出求解的思路。根据进程的操作流程确定Р操作、V操作的大致顺序。</p>
<p>3）设置信号量。根据上面的两步，设置需要的信号量，确定初值，完善整理。</p>
<p>这是一个比较直观的同步问题，以 $S_2$ 为例，它是 $S_1$ 的后继，所以要用到 $S_1$ 的资源，在前面的简单总结中我们说过，在同步问题中，要用到某种资源，就要在行为（题中统一抽象成L)前面Р这种资源一下。 $S_2$ 是 $S_4$ ， $S_5$ 的前驱，给 $S_4$ ， $S_5$ ,提供资源，所以要在L行为后面V由 $S_4$ 和 $S_5$ 代表的资源一下。</p>
<h4 id="管程"><a href="#管程" class="headerlink" title="管程"></a>管程</h4><p>在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作给系统管理带来了麻烦，且容易因同步操作不当而导致系统死锁。于是，便产生了一种新的进程同步工具-管程。管程的特性保证了进程互斥，无须程序员自己实现互斥，从而降低了死锁发生的可能性。同时管程提供了条件变量，可以让程序员灵活地实现进程同步。</p>
<h5 id="管程的定义"><a href="#管程的定义" class="headerlink" title="管程的定义"></a>管程的定义</h5><p>系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。</p>
<p>利用共享数据结构抽象地表示系统中的共享资源，而把对该数据结构实施的操作定义为一组过程。进程对共享资源的申请、释放等操作，都通过这组过程来实现，这组过程还可以根据资源情况，或接受或阻塞进程的访问，确保每次仅有一个进程使用共享资源，这样就可以统一管理对共享资源的所有访问，实现进程互斥。这个代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，称为管程( monitor )。管程定义了一个数据结构和能为并发进程所执行(在该数据结构上)的一组操作，这组操作能同步进程和改变管程中的数据。</p>
<p>由上述定义可知，管程由4部分组成:</p>
<p>①管程的名称;<br>${\textstyle\unicode{x2461}}$  局部于管程内部的共享结构数据说明;</p>
<p>${\textstyle\unicode{x2462}}$对该数据结构进行操作的一组过程(或函数);</p>
<p>${\textstyle\unicode{x2463}}$ 对局部于管程内部的共享数据设置初始值的语句。</p>
<p>管程的定义描述举例如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101003.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101003.png';" /></details>

<p>熟悉面向对象程序设计的读者看到管程的组成后，会立即联想到管程很像一个类(class)。</p>
<p>1)管程把对共享资源的操作封装起来，管程内的共享数据结构只能被管程内的过程所访问。一个进程只有通过调用管程内的过程才能进入管程访问共享资源。对于上例，外部进程只能通过调用take_away()过程来申请一个资源;归还资源也一样。</p>
<p>2）每次仅允许一个进程进入管程，从而实现进程互斥。若多个进程同时调用take_away(),give_back()，则只有某个进程运行完它调用的过程后，下个进程才能开始运行它调用的过程。也就是说，各个进程只能串行执行管程内的过程，这一特性保证了进程“互斥”访问共享数据结构S。</p>
<h5 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h5><p>当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程，那么其他进程无法进入管程。为此，将阻塞原因定义为条件变量condition。通常，一个进程被阻塞的原因可以有多个，因此在管程中设置了多个条件变量。每个条件变量保存了一个等待队列，用于记录因该条件变量而阻塞的所有进程，对条件变量只能进行两种操作，即 wait和 signal。</p>
<p>x.wait:当x对应的条件不满足时，正在调用管程的进程调用x.wait将自己插入x条件的等待队列，并释放管程。此时其他进程可以使用该管程。</p>
<p>x.signal: x对应的条件发生了变化，则调用x.signal，唤醒一个因x条件而阻塞的进程。下面给出条件变量的定义和使用:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101118.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101118.png';" /></details>

<p>条件变量和信号量的比较:</p>
<p>相似点:条件变量的wait/signal操作类似于信号量的P/V操作，可以实现进程的阻塞/唤醒。</p>
<p>不同点:条件变量是“没有值”的，仅实现了“排队等待”功能;而信号量是“有值”的，信号量的值反映了剩余资源数，而在管程中，剩余资源数用共享数据结构记录。</p>
<h4 id="经典同步问题"><a href="#经典同步问题" class="headerlink" title="经典同步问题"></a>经典同步问题</h4><h5 id="生产者-消费者问题"><a href="#生产者-消费者问题" class="headerlink" title="生产者-消费者问题"></a>生产者-消费者问题</h5><p><strong>问题描述</strong>:一组生产者进程和一组消费者进程共享一个初始为空、大小为n的缓冲区，只有缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待;只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或一个消费者从中取出消息。</p>
<p><strong>问题分析</strong>:</p>
<p>1）关系分析。生产者和消费者对缓冲区互斥访问是互斥关系，同时生产者和消费者又是个相互协作的关系，只有生产者生产之后，消费者才能消费，它们也是同步关系。</p>
<p>2）整理思路。这里比较简单，只有生产者和消费者两个进程，正好是这两个进程存在着互斥关系和同步关系。那么需要解决的是互斥和同步PV操作的位置。</p>
<p>3)信号量设置。信号量mutex作为互斥信号量，用于控制互斥访问缓冲池，互斥信号量初值为1;信号量full用于记录当前缓冲池中的“满”缓冲区数，初值为0。信号量empty用于记录当前缓冲池中的“空”缓冲区数，初值为 $n$ 。</p>
<p>我们对同步互斥问题的介绍是一个循序渐进的过程。上面介绍了一个同步问题的例子和一个互斥问题的例子，下面来看生产者-消费者问题的例子是什么样的。</p>
<p>生产者-消费者进程的描述如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101330.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101330.png';" /></details>

<p>该类问题要注意对缓冲区大小为n的处理，当缓冲区中有空时，便可对empty变量执行Р操作，一旦取走一个产品便要执行V操作以释放空闲区。对empty和 full变量的Р操作必须放在对mutex 的P操作之前。若生产者进程先执行P(mutex)，然后执行P(empty)，消费者执行P(mutex),然后执行 P(full)，这样可不可以﹖答案是否定的。设想生产者进程已将缓冲区放满，消费者进程并没有取产品，即 empty =0，当下次仍然是生产者进程运行时，它先执行P(mutex)封锁信号量,再执行P(empty)时将被阻塞，希望消费者取出产品后将其唤醒。轮到消费者进程运行时，它先执行P(mutex)，然而由于生产者进程已经封锁mutex信号量，消费者进程也会被阻塞，这样一来生产者、消费者进程都将阻塞，都指望对方唤醒自己，因此陷入了无休止的等待。同理，若消费者进程已将缓冲区取空，即 full = 0，下次若还是消费者先运行，也会出现类似的死锁。不过生产者释放信号量时，mutex, full 先释放哪一个无所谓，消费者先释放mutex 或empty都可以。</p>
<p>根据对同步互斥问题的简单总结，我们发现，其实生产者-消费者问题只是一个同步互斥问题的综合而已。</p>
<p>下面再看一个较为复杂的生产者-消费者问题。</p>
<p><strong>问题描述</strong>:桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有盘子为空时，爸爸或妈妈才可向盘子中放一个水果;仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出。</p>
<p><strong>问题分析</strong>:</p>
<p>1）关系分析。这里的关系要稍复杂一些。由每次只能向其中放入一只水果可知，爸爸和妈妈是互斥关系。爸爸和女儿、妈妈和儿子是同步关系，而且这两对进程必须连起来，儿子和女儿之间没有互斥和同步关系，因为他们是选择条件执行，不可能并发，如图2.9所示。</p>
<p>2)整理思路。这里有4个进程，实际上可抽象为两个生产者和两个消费者被连接到大小为1的缓冲区上。</p>
<p>3）信号量设置。首先将信号量plate设置互斥信号量，表示是否允许向盘子放入水果，初值为1表示允许放入，且只允许放入一个。信号量apple表示盘子中是否有苹果，初值为0表示盘子为空，不许取，apple = 1表示可以取。信号量orange表示盘子中是否有橘子，初值为0表示盘子为空，不许取，orange =1表示可以取。</p>
<details><summary>图2.9进程之间的关系</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101528.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101528.png';" /></details>

<p>解决该问题的代码如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101624.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101624.png';" /></details>

<p>进程间的关系如图2.9所示。dad()和 daughter()、mom()和 son()必须连续执行，正因为如此，也只能在女儿拿走苹果后或儿子拿走橘子后才能释放盘子，即V(plate)操作。</p>
<h5 id="读者-写者问题"><a href="#读者-写者问题" class="headerlink" title="读者-写者问题"></a>读者-写者问题</h5><p><strong>问题描述</strong>:有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求:①允许多个读者可以同时对文件执行读操作;②只允许一个写者往文件中写信息;③任一写者在完成写操作之前不允许其他读者或写者工作;④写者执行写操作前，应让已有的读者和写者全部退出。</p>
<p><strong>问题分析</strong>:</p>
<p>1）关系分析。由题目分析读者和写者是互斥的，写者和写者也是互斥的，而读者和读者不存在互斥问题。</p>
<p>2）整理思路。两个进程，即读者和写者。写者是比较简单的，它和任何进程互斥，用互斥信号量的Р操作、V操作即可解决。读者的问题比较复杂，它必须在实现与写者互斥的同时，实现与其他读者的同步，因此简单的一对Р操作、V操作是无法解决问题的。这里用到了一个计数器，用它来判断当前是否有读者读文件。当有读者时，写者是无法写文件的，此时读者会一直占用文件，当没有读者时，写者才可以写文件。同时，这里不同读者对计数器的访问也应该是互斥的。</p>
<p>3)信号量设置。首先设置信号量count为计数器，用于记录当前读者的数量，初值为0;设置mutex为互斥信号量，用于保护更新count变量时的互斥;设置互斥信号量rw，用于保证读者和写者的互斥访问。</p>
<p>代码如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101839.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101839.png';" /></details>

<p>在上面的算法中，读进程是优先的，即当存在读进程时，写操作将被延迟，且只要有一个读进程活跃，随后而来的读进程都将被允许访问文件。这样的方式会导致写进程可能长时间等待，且存在写进程“饿死”的情况。</p>
<p>若希望写进程优先，即当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等到已在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。为此，增加一个信号量并在上面程序的 writer()和reader()函数中各增加一对PV操作，就可以得到写进程优先的解决程序。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925101951.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925101951.png';" /></details>

<p>这里的写进程优先是相对而言的，有些书上把这个算法称为读写公平法，即读写进程具有-一样的优先级。当一个写进程访问文件时，若先有一些读进程要求访问文件，后有另一个写进程要求访问文件，则当前访问文件的进程结束对文件的写操作时，会是一个读进程而不是一个写进程占用文件(在信号量w的阻塞队列上，因为读进程先来，因此排在阻塞队列队首，而V操作唤醒进程时唤醒的是队首进程)，所以说这里的写优先是相对的，想要了解如何做到真正写者优先，</p>
<p>可参考其他相关资料。</p>
<p>读者-写者问题有一个关键的特征，即有一个互斥访问的计数器count，因此遇到一个不太好解决的同步互斥问题时，要想一想用互斥访问的计数器count能否解决问题。</p>
<h5 id="哲学家进餐问题"><a href="#哲学家进餐问题" class="headerlink" title="哲学家进餐问题"></a>哲学家进餐问题</h5><details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925102039.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102039.png';" /></details>

<p><strong>问题描述</strong>:一张圆桌边上坐着5名哲学家，每两名哲学家之间的桌上摆一根筷子，两根筷子中间是一碗米饭，如图2.10所示。哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子(一根一根地拿起)。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考。</p>
<p><strong>问题分析</strong>:</p>
<p>1）关系分析。5名哲学家与左右邻居对其中间筷子的访问是互斥关系。</p>
<p>2）整理思路。显然，这里有5个进程。本题的关键是如何让一名哲学家拿到左右两根筷子而不造成死锁或饥饿现象。解决方法有两个:一是让他们同时拿两根筷子;二是对每名哲学家的动作制定规则，避免饥饿或死锁现象的发生。</p>
<p>3)信号量设置。定义互斥信号量数组chopstick[ 5 ]={1,1,1,1,1}，用于对5个筷子的互斥访问。哲学家按顺序编号为0～4，哲学家i左边筷子的编号为i，哲学家右边筷子的编号为(i +1)%5。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925102239.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102239.png';" /></details>

<p>该算法存在以下问题:当5名哲学家都想要进餐并分别拿起左边的筷子时（都恰好执行完wait(chopstick[ i]);）筷子已被拿光,等到他们再想拿右边的筷子时（执行wait(chopstick[(i + 1)%5]);）就全被阻塞，因此出现了死锁。<br>为防止死锁发生，可对哲学家进程施加一些限制条件，比如至多允许4名哲学家同时进餐;仅当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子;对哲学家顺序编号，要求奇数号哲学家先拿左边的筷子，然后拿右边的筷子，而偶数号哲学家刚好相反。</p>
<p>制定的正确规则如下:假设采用第二种方法，当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925102409.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102409.png';" /></details>

<p>此外，还可采用AND型信号量机制来解决哲学家进餐问题，有兴趣的读者可以查阅相关资料，自行思考。</p>
<p>熟悉ACM或有过相关训练的读者都应知道贪心算法，哲学家进餐问题的思想其实与贪心算法的思想截然相反，贪心算法强调争取眼前认为最好的，而不考虑后续会有什么后果。若哲学家进餐问题用贪心算法来解决，即只要眼前有筷子能拿起就拿起的话，就会出现死锁。然而,若不仅考虑眼前的一步，而且考虑下一步，即不因为有筷子能拿起就拿起，而考虑能不能一次拿起两根筷子才做决定的话，就会避免死锁问题，这就是哲学家进餐问题的思维精髓。</p>
<p>大部分练习题和真题用消费者-生产者模型或读者-写者问题就能解决，但对于哲学家进餐问题和吸烟者问题仍然要熟悉。考研复习的关键在于反复多次和全面，“偷工减料”是要吃亏的。</p>
<h5 id="吸烟者问题"><a href="#吸烟者问题" class="headerlink" title="吸烟者问题"></a>吸烟者问题</h5><p><strong>问题描述</strong>:假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者需要有三种材料:烟草、纸和胶水。三个抽烟者中,第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就会将另外两种材料放到桌上，如此重复（让三个抽烟者轮流地抽烟）。</p>
<p><strong>问题分析</strong>:<br>1）关系分析。供应者与三个抽烟者分别是同步关系。由于供应者无法同时满足两个或以上的抽烟者，三个抽烟者对抽烟这个动作互斥（或由三个抽烟者轮流抽烟得知)。</p>
<p>2）整理思路。显然这里有4个进程。供应者作为生产者向三个抽烟者提供材料。</p>
<p>3)信号量设置。信号量offer1, offer2, offer3分别表示烟草和纸组合的资源、烟草和胶水组合的资源、纸和胶水组合的资源。信号量finish用于互斥进行抽烟动作。</p>
<p>代码如下:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925102637.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925102637.png';" /></details>

<h4 id="本节小结-1"><a href="#本节小结-1" class="headerlink" title="本节小结"></a>本节小结</h4><p>本节开头提出的问题的参考答案如下。</p>
<h5 id="为什么要引入进程同步的概念"><a href="#为什么要引入进程同步的概念" class="headerlink" title="为什么要引入进程同步的概念?"></a>为什么要引入进程同步的概念?</h5><p>在多道程序共同执行的条件下，进程与进程是并发执行的，不同进程之间存在不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。</p>
<h5 id="不同的进程之间会存在什么关系"><a href="#不同的进程之间会存在什么关系" class="headerlink" title="不同的进程之间会存在什么关系?"></a>不同的进程之间会存在什么关系?</h5><p>进程之间存在同步与互斥的制约关系。</p>
<p>同步是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。</p>
<p>互斥是指当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。</p>
<h5 id="当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗"><a href="#当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗" class="headerlink" title="当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗?"></a>当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗?</h5><p>当两个或两个以上的进程在执行过程中，因占有一些资源而又需要对方的资源时，会因为争夺资源而造成一种互相等待的现象，若无外力作用，它们都将无法推进下去。这种现象称为死锁，具体介绍和解决方案请参考下一节。</p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>在学习本节时，请读者思考以下问题:</p>
<p>1）为什么会产生死锁?产生死锁有什么条件?</p>
<p>2）有什么办法可以解决死锁问题?</p>
<p>学完本节，读者应了解死锁的由来、产生条件及基本解决方法，区分死锁的避免和死锁的预防。</p>
<h4 id="死锁的概念"><a href="#死锁的概念" class="headerlink" title="死锁的概念"></a>死锁的概念</h4><h5 id="死锁的定义"><a href="#死锁的定义" class="headerlink" title="死锁的定义"></a>死锁的定义</h5><p>在多道程序系统中，由于多个进程的并发执行，改善了系统资源的利用率并提高了系统的处理能力。然而，多个进程的并发执行也带来了新的问题–死锁。所谓死锁，是指多个进程因竞争资源而造成的一种僵局（互相等待)，若无外力作用，这些进程都将无法向前推进。</p>
<p>下面通过一些实例来说明死锁现象。</p>
<p>先看生活中的一个实例。在一条河上有一座桥，桥面很窄，只能容纳一辆汽车通行。若有两辆汽车分别从桥的左右两端驶上该桥，则会出现下述冲突情况:此时，左边的汽车占有桥面左边的一段，要想过桥还需等待右边的汽车让出桥面右边的一段;右边的汽车占有桥面右边的一段，要想过桥还需等待左边的汽车让出桥面左边的一段。此时，若左右两边的汽车都只能向前行驶，则两辆汽车都无法过桥。</p>
<p>在计算机系统中也存在类似的情况。例如，某计算机系统中只有一台打印机和一台输入设备，进程 $P_1$ 正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程 $P_2$ 所占用，而 $P_2$ 在未释放打印机之前，又提出请求使用正被 $P_1$ 占用的输入设备。这样，两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。</p>
<h5 id="死锁产生的原因"><a href="#死锁产生的原因" class="headerlink" title="死锁产生的原因"></a>死锁产生的原因</h5><h6 id="系统资源的竞争"><a href="#系统资源的竞争" class="headerlink" title="系统资源的竞争"></a>系统资源的竞争</h6><p>通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。只有对不可剥夺资源的竞争才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。</p>
<h6 id="进程推进顺序非法"><a href="#进程推进顺序非法" class="headerlink" title="进程推进顺序非法"></a>进程推进顺序非法</h6><p>进程在运行过程中，请求和释放资源的顺序不当，也同样会导致死锁。例如，并发进程 $P_1$ , $P_2$ 分别保持了资源 $R_1$ ,  $R_2$ ，而进程 $P_1$ 申请资源 $R_2$ 、进程 $P_2$ 申请资源 $R_1$ 时，两者都会因为所需资源被占用而阻塞。</p>
<p>信号量使用不当也会造成死锁。进程间彼此相互等待对方发来的消息，也会使得这些进程间无法继续向前推进。例如，进程A等待进程B发的消息，进程B又在等待进程A发的消息，可以看出进程A和B不是因为竞争同一资源，而是在等待对方的资源导致死锁。</p>
<h6 id="死锁产生的必要条件"><a href="#死锁产生的必要条件" class="headerlink" title="死锁产生的必要条件"></a>死锁产生的必要条件</h6><p>产生死锁必须同时满足以下4个条件，只要其中任意一个条件不成立，死锁就不会发生。</p>
<p><strong>互斥条件</strong>:进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。</p>
<p><strong>不剥夺条件</strong>:进程所获得的资源在未使用完之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放)。</p>
<p><strong>请求并保持条件</strong>:进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。</p>
<p><strong>循环等待条件</strong>:存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待态的进程集合{ $P_1$ , $P_2$ ,…, $P_n$ }，其中P,等待的资源被 $P_{i+1}$  ( $i$ =0,1,… ,  $n$ -1）占有， $P_n$ 等待的资源被 $P_0$ 占有，如图2.11所示。</p>
<p>直观上看，循环等待条件似乎和死锁的定义一样，其实不然。按死锁定义构成等待环所要求的条件更严，它要求 $P_i$ 等待的资源必须由 $P_{i+1}$ 来满足，而循环等待条件则无此限制。例如，系统中有两台输出设备， $P_0$ 占有一台， $P_K$ 占有另一台，且K不属于集合{0,1，…, n}。 $P_n$ 等待一台输出设备，它可从 $P_0$ 获得，也可能从 $P_K$ 获得。因此，虽然 $P_n$ , $P_0$ 和其他一些进程形成了循环等待圈,但 $P_K$ 不在圈内，若 $P_K$ 释放了输出设备，则可打破循环等待，如图2.12所示。因此循环等待只是死锁的必要条件。</p>
<details><summary>图2.11和图2.12</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925224155.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925224155.png';" /></details>

<p>资源分配图含圈而系统又不一定有死锁的原因是，同类资源数大于1。但若系统中每类资源都只有一个资源，则资源分配图含圈就变成了系统出现死锁的充分必要条件。</p>
<p>要注意区分不剥夺条件与请求并保持条件。下面用一个简单的例子进行说明:若你手上拿着一个苹果（即便你不打算吃)，别人不能把你手上的苹果拿走，则这就是不剥夺条件;若你左手拿着一个苹果，允许你右手再去拿一个苹果，则这就是请求并保持条件。</p>
<h4 id="死锁的处理策略"><a href="#死锁的处理策略" class="headerlink" title="死锁的处理策略"></a>死锁的处理策略</h4><p>为使系统不发生死锁，必须设法破坏产生死锁的4个必要条件之一，或允许死锁产生，但当死锁发生时能检测出死锁，并有能力实现恢复。</p>
<h5 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h5><p>设置某些限制条件，破坏产生死锁的4个必要条件中的一个或几个，以防止发生死锁。</p>
<h5 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h5><p>在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。</p>
<h5 id="死锁的检测及解除"><a href="#死锁的检测及解除" class="headerlink" title="死锁的检测及解除"></a>死锁的检测及解除</h5><p>无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。</p>
<p>预防死锁和避免死锁都属于事先预防策略，预防死锁的限制条件比较严格，实现起来较为简单，但往往导致系统的效率低，资源利用率低;避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，实现起来较为复杂。</p>
<p>死锁的几种处理策略的比较见表2.4。</p>
<details><summary>表2.4 死锁处理策略的比较</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925225720.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925225720.png';" /></details>

<h4 id="死锁预防-1"><a href="#死锁预防-1" class="headerlink" title="死锁预防"></a>死锁预防</h4><p>防止死锁的发生只需破坏死锁产生的4个必要条件之一即可。</p>
<h5 id="破坏互斥条件"><a href="#破坏互斥条件" class="headerlink" title="破坏互斥条件"></a>破坏互斥条件</h5><p>若允许系统资源都能共享使用，则系统不会进入死锁状态。但有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，破坏互斥条件而预防死锁的方法不太可行，而且在有的场合应该保护这种互斥性。</p>
<h5 id="破坏不剥夺条件"><a href="#破坏不剥夺条件" class="headerlink" title="破坏不剥夺条件"></a>破坏不剥夺条件</h5><p>当一个已保持了某些不可剥夺资源的进程请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺，或从而破坏了不剥夺条件。</p>
<p>该策略实现起来比较复杂，释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销,降低系统吞吐量。这种方法常用于状态易于保存和恢复的资源,如 CPU的寄存器及内存资源，一般不能用于打印机之类的资源。</p>
<h5 id="破坏请求并保持条件"><a href="#破坏请求并保持条件" class="headerlink" title="破坏请求并保持条件"></a>破坏请求并保持条件</h5><p>采用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。一旦投入运行，这些资源就一直归它所有，不再提出其他资源请求，这样就可以保证系统不会发生死锁。</p>
<p>这种方式实现简单，但缺点也显而易见，系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会导致“饥饿”现象，由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。</p>
<h5 id="破坏循环等待条件"><a href="#破坏循环等待条件" class="headerlink" title="破坏循环等待条件"></a>破坏循环等待条件</h5><p>为了破坏循环等待条件，可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。也就是说，只要进程提出申请分配资源 $R_i$ ，则该进程在以后的资源申请中就只能申请编号大于 $R_i$ 的资源。</p>
<p>这种方法存在的问题是，编号必须相对稳定，这就限制了新类型设备的增加;尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费;此外，这种按规定次序申请资源的方法，也必然会给用户的编程带来麻烦。</p>
<h4 id="死锁避免"><a href="#死锁避免" class="headerlink" title="死锁避免"></a>死锁避免</h4><p>避免死锁同样属于事先预防策略，但并不是事先采取某种限制措施破坏死锁的必要条件，而是在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁。这种方法所施加的限制条件较弱，可以获得较好的系统性能。</p>
<h5 id="系统安全状态"><a href="#系统安全状态" class="headerlink" title="系统安全状态"></a>系统安全状态</h5><p>避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配的安全性。若此次分配不会导致系统进入不安全状态，则允许分配;否则让进程等待。</p>
<p>所谓安全状态，是指系统能按某种进程推进顺序( $P_1$ , $P_2$ ,…, $P_n$ )为每个进程 $P_i$ 分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。此时称 $P_i$ ， $P_-2$ .…， $P_n$ 为安全序列。若系统无法找到一个安全序列，则称系统处于不安全状态。</p>
<p>假设系统中有三个进程 $P_1$ , $P_2$ ,和 $P_3$ ，共有12台磁带机。进程 $P_1$ 共需要10台磁带机， $P_2$ 和  $P_3$ 分别需要4台和9台。假设在 $T_0$ 时刻，进程 $P_1$ ， $P_2$ 和 $P_3$ 已分别获得5台、2台和2台，尚有3台未分配，见表2.5。</p>
<details><summary>表2.5 资源分配</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925232929.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925232929.png';" /></details>

<p>在 $T_0$ 时刻是安全的，因为存在一个安全序列 $P_2$ ,  $P_1$ , $P_3$ ，只要系统按此进程序列分配资源，那么每个进程都能顺利完成。也就是说，当前可用磁带机为3台，先把3台磁带机分配给 $Р_2$ 以满足其最大需求， $P_2$ 结束并归还资源后，系统有5台磁带机可用;接下来给 $P_1$ 分配5台磁带机以满足其最大需求， $P_1$ 结束并归还资源后，剩余10台磁带机可用;最后分配7台磁带机给 $P_3$ ，这样$P_3$也能顺利完成。</p>
<p>若在 $T_0$ 时刻后，系统分配1台磁带机给 $P_3$ ，系统剩余可用资源数为2，此时系统进入不安全状态，因为此时已无法再找到一个安全序列。当系统进入不安全状态后，便可能导致死锁。例如，把剩下的2台磁带机分配给 $P_2$ 这样， $P_2$ 完成后只能释放4台磁带机，既不能满足 $P_1$ 又不能满足 $P_3$ ，致使它们都无法推进到完成，彼此都在等待对方释放资源，陷入僵局，即导致死锁。</p>
<p>并非所有的不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态;反之，只要系统处于安全状态，系统便可避免进入死锁状态。</p>
<h5 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a>银行家算法</h5><p>银行家算法是最著名的死锁避免算法，其思想是:把操作系统视为银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源。进程运行之前先声明对各种资源的最大需求量，当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过该进程声明的最大需求量。若超过则拒绝分配资源，若未超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。</p>
<h6 id="数据结构描述"><a href="#数据结构描述" class="headerlink" title="数据结构描述"></a>数据结构描述</h6><p>可利用资源向量Available:含有m个元素的数组，其中每个元素代表一类可用的资源数目。Available[ j ]=K表示系统中现有 $R_j$ 类资源K个。</p>
<p>最大需求矩阵 Max: n×m 矩阵，定义系统中 $n$ 个进程中的每个进程对 $m$ 类资源的最大需求。简单来说，一行代表一个进程，一列代表一类资源。Max[ i,j ]=K表示进程i需要 $R_j$ 类资源的最大数目为K。</p>
<p>分配矩阵Allocation:  $n \times m$ 矩阵，定义系统中每类资源当前已分配给每个进程的资源数。Allocation[ i,j ]=K表示进程 $i$ 当前已分得 $R_j$ 类资源的数目为K。初学者容易混淆Available向量和Allocation矩阵，在此特别提醒。</p>
<p>需求矩阵Need:  $n \times m$ 矩阵，表示每个进程接下来最多还需要多少资源。Need[ i,j ]=K表示进程i还需要 $R_j$类资源的数目为K。</p>
<p>上述三个矩阵间存在下述关系:</p>
<p style='text-align:center'>Need= Max- Allocation</p>

<p>一般情况下，在银行家算法的题目中，Max矩阵和Allocation矩阵是已知条件，而求出 Need矩阵是解题的第一步。</p>
<h6 id="银行家算法描述"><a href="#银行家算法描述" class="headerlink" title="银行家算法描述"></a>银行家算法描述</h6><details><summary>银行家算法描述</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925233723.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925233723.png';" /></details>


<h5 id="安全性算法举例"><a href="#安全性算法举例" class="headerlink" title="安全性算法举例"></a>安全性算法举例</h5><details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925235124.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235124.png';" /></details>

<h5 id="银行家算法举例"><a href="#银行家算法举例" class="headerlink" title="银行家算法举例"></a>银行家算法举例</h5><details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925235226.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235226.png';" /></details>


<h4 id="死锁检测和解除"><a href="#死锁检测和解除" class="headerlink" title="死锁检测和解除"></a>死锁检测和解除</h4><p>前面介绍的死锁预防和避免算法，都是在为进程分配资源时施加限制条件或进行检测，若系统为进程分配资源时不采取任何措施，则应该提供死锁检测和解除的手段。</p>
<h5 id="资源分配图"><a href="#资源分配图" class="headerlink" title="资源分配图"></a>资源分配图</h5><p>系统死锁可利用资源分配图来描述。如图2.13所示，用圆圈代表一个进程，用框代表一类资源。由于一种类型的资源可能有多个，因此用框中的一个圆代表一类资源中的一个资源。从进程到资源的有向边称为请求边，表示该进程申请一个单位的该类资源;从资源到进程的边称为分配边，表示该类资源已有一个资源分配给了该进程。</p>
<p>在图2.13所示的资源分配图中，进程 $P_1$ 已经分得了两个 $R_1$ 资源，并又请求一个 $R_2$ 资源;进程 $P_2$ ,分得了一个 $R_1$ 资源和一个 $R_2$ 资源，并又请求一个 $R_1$ 资源。</p>
<details><summary>图2.13 资源分配示例</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925235430.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235430.png';" /></details>


<h5 id="死锁定理"><a href="#死锁定理" class="headerlink" title="死锁定理"></a>死锁定理</h5><p>简化资源分配图可检测系统状态S是否为死锁状态。简化方法如下:</p>
<p>1)在资源分配图中，找出既不阻塞又不孤点的进程 $P_i$ (即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中己有的空闲资源数量，如在图2.13中， $R_1$ 没有空闲资源， $R_2$ 有一个空闲资源。若所有连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源)。消去它所有的请求边和分配边，使之成为孤立的结点。在图2.14(a)中， $P_1$ 是满足这一条件的进程结点，将P的所有边消去，便得到图2.14(b)所示的情况。</p>
<p>这里要注意一个问题，判断某种资源是否有空间，应用它的资源数量减去它在资源分配图中的出度，例如在图2.13中， $R_1$ 的资源数为3，而出度也为3，所以 $R_1$ 没有空闲资源, $R_2$ 的资源数为2，出度为1，所以 $R_2$ 有一个空闲资源。</p>
<p>2）进程 $P_i$ 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在图2.13中，进程 $P_2$ 就满足这样的条件。根据1)中的方法进行一系列简化后，若能消去图中所有的边，则称该图是可完全简化的，如图2.14(c)所示。</p>
<details><summary>图2.14 资源分配图的化简</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210925235734.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210925235734.png';" /></details>

<p>S为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的，该条件为 $\color{green}{\text{死锁定理}}$ 。</p>
<h5 id="死锁解除"><a href="#死锁解除" class="headerlink" title="死锁解除"></a>死锁解除</h5><p>一旦检测出死锁，就应立即采取相应的措施来解除死锁。死锁解除的主要方法有:</p>
<p>1）资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源而处于资源匮乏的状态。</p>
<p>2）撤销进程法。强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。</p>
<p>3）进程回退法。让一（或多〉个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺。要求系统保持进程的历史信息，设置还原点。</p>
<h4 id="本节小结-2"><a href="#本节小结-2" class="headerlink" title="本节小结"></a>本节小结</h4><p>本节开头提出的问题的参考答案如下。</p>
<p>1）为什么会产生死锁?产生死锁有什么条件?</p>
<p>由于系统中存在一些不可剥夺资源，当两个或两个以上的进程占有自身的资源并请求对方的资源时，会导致每个进程都无法向前推进，这就是死锁。死锁产生的必要条件有4个，分别是互斥条件、不剥夺条件、请求并保持条件和循环等待条件。</p>
<p>互斥条件是指进程要求分配的资源是排他性的，即最多只能同时供一个进程使用。</p>
<p>不剥夺条件是指进程在使用完资源之前，资源不能被强制夺走。</p>
<p>请求并保持条件是指进程占有自身本来拥有的资源并要求其他资源。</p>
<p>循环等待条件是指存在一种进程资源的循环等待链。</p>
<p>2）有什么办法可以解决死锁问题?</p>
<p>死锁的处理策略可以分为预防死锁、避免死锁及死锁的检测与解除。</p>
<p>死锁的预防是指通过设立一些限制条件，破坏死锁的一些必要条件，让死锁无法发生。</p>
<p>死锁的避免是指在动态分配资源的过程中，用一些算法防止系统进入不安全状态，从而避免死锁。</p>
<p>死锁的检测和解除是指在死锁产生前不采取任何措施，只检测当前系统有没有发生死锁，若有，则采取一些措施解除死锁。</p>
<h3 id="本章疑难点-1"><a href="#本章疑难点-1" class="headerlink" title="本章疑难点"></a>本章疑难点</h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h5 id="进程与程序的区别与联系"><a href="#进程与程序的区别与联系" class="headerlink" title="进程与程序的区别与联系"></a>进程与程序的区别与联系</h5><p>1）进程是程序及其数据在计算机上的一次运行活动，是一个动态的概念。进程的运行实体是程序，离开程序的进程没有存在的意义。从静态角度看，进程是由程序、数据和进程控制块（PCB）三部分组成的。而程序是一组有序的指令集合，是一种静态的概念。</p>
<p>2）进程是程序的一次执行过程，它是动态地创建和消亡的，具有一定的生命周期，是暂时存在的;而程序则是一组代码的集合，是永久存在的，可长期保存。</p>
<p>3）一个进程可以执行一个或几个程序，一个程序也可构成多个进程。进程可创建进程，而程序不可能形成新的程序。</p>
<p>4）进程与程序的组成不同。进程的组成包括程序、数据和PCB。</p>
<h5 id="死锁与饥饿"><a href="#死锁与饥饿" class="headerlink" title="死锁与饥饿"></a>死锁与饥饿</h5><p>具有等待队列的信号量的实现可能导致这样的情况:两个或多个进程无限地等待一个事件，而该事件只能由这些等待进程之一来产生。这里的事件是V操作的执行（即释放资源)。出现这样的状态时，这些进程称为死锁(Deadlocked)。</p>
<p>为加以说明，考虑一个由两个进程 $P_0$ 和 $P_1$ 组成的系统，每个进程都访问两个信号量S和Q,这两个信号量的初值均为1。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926000155.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926000155.png';" /></details>

<p>假设进程 $P_0$ 执行P(S)，接着进程 $P_1$ 执行P(Q)。当进程 $P_0$ 执行P(Q)时，它必须等待，直到进程 $P_1$ 执行V(Q)。类似地，当进程 $P_1$ 执行P(S)时，它必须等待，直到进程 $P_0$ 执行V(S)。由于这两个V操作都不能执行，因此进程 $P_0$ 和进程 $P_1$ 就死锁了。</p>
<p>一组进程处于死锁状态是指组内的每个进程都在等待一个事件，而该事件只可能由组内的另一个进程产生。这里所关心的主要是事件是资源的获取和释放。</p>
<p>与死锁相关的另一个问题是无限期阻塞（Indefinite Blocking）或饥饿(Starvation)，即进程在信号量内无穷等待的情况。</p>
<p>产生饥饿的主要原因是:在一个动态系统中，对于每类系统资源，操作系统需要确定一个分配策略，当多个进程同时申请某类资源时，由分配策略确定资源分配给进程的次序。有时资源分配策略可能是不公平的，即不能保证等待时间上界的存在。在这种情况下，即使系统没有发生死锁，某些进程也可能会长时间等待。当等待时间给进程推进和响应带来明显影响时，称发生了进程“饥饿”，当“饥饿”到一定程度的进程所赋予的任务即使完成也不再具有实际意义时，称该进程被“饿死”。</p>
<p>例如，当有多个进程需要打印文件时，若系统分配打印机的策略是最短文件优先，则长文件的打印任务将由于短文件的源源不断到来而被无限期推迟，导致最终“饥饿”甚至“饿死”。</p>
<p>“饥饿”并不表示系统一定会死锁，但至少有一个进程的执行被无限期推迟。“饥饿”与死锁的主要差别如下:</p>
<p>1）进入“饥饿”状态的进程可以只有一个，而因循环等待条件而进入死锁状态的进程却必须大于等于两个。</p>
<p>2）处于“饥饿”状态的进程可以是一个就绪进程，如静态优先权调度算法时的低优先权进程，而处于死锁状态的进程则必定是阻塞进程。</p>
<h5 id="银行家算法的工作原理"><a href="#银行家算法的工作原理" class="headerlink" title="银行家算法的工作原理"></a>银行家算法的工作原理</h5><p>银行家算法的主要思想是避免系统进入不安全状态。在每次进行资源分配时，它首先检查系统是否有足够的资源满足要求，若有则先进行分配，并对分配后的新状态进行安全性检查。若新状态安全，则正式分配上述资源，否则拒绝分配上述资源。这样，它保证系统始终处于安全状态，从而避免了死锁现象的发生。</p>
<h5 id="进程同步、互斥的区别和联系"><a href="#进程同步、互斥的区别和联系" class="headerlink" title="进程同步、互斥的区别和联系"></a>进程同步、互斥的区别和联系</h5><p>并发进程的执行会产生相互制约的关系:一种是进程之间竞争使用临界资源，只能让它们逐个使用，这种现象称为互斥，是一种竞争关系;另一种是进程之间协同完成任务，在关键点上等待另一个进程发来的消息，以便协同一致，是一种协作关系。</p>
<h5 id="作业和进程的关系"><a href="#作业和进程的关系" class="headerlink" title="作业和进程的关系"></a>作业和进程的关系</h5><p>进程是系统资源的使用者，系统的资源大部分都是以进程为单位分配的。而用户使用计算机是为了实现一串相关的任务，通常把用户要求计算机完成的这一串任务称为作业。</p>
<h6 id="批处理系统中作业与进程的关系（进程组织"><a href="#批处理系统中作业与进程的关系（进程组织" class="headerlink" title="批处理系统中作业与进程的关系（进程组织)"></a>批处理系统中作业与进程的关系（进程组织)</h6><p>批处理系统可以通过磁记录设备或卡片机向系统提交批作业，由系统的SPOOLing输入进程将作业放入磁盘的输入井，作为后备作业。作业调度程序（一般也作为独立的进程运行）每当选择一道后备作业运行时，首先为该作业创建一个进程（称为该作业的根进程)。该进程将执行作业控制语言解释程序，解释该作业的作业说明书。父进程在运行过程中可以动态地创建一个或多个子进程，执行说明书中的语句。例如，对一条编译的语句，该进程可以创建一个子进程执行编译程序对用户源程序进行编译。类似地，子进程也可继续创建子进程去完成指定的功能。因此,一个作业就动态地转换成了一组运行实体—进程族。当父进程遇到作业说明书中的“撤出作业”语句时，将该作业从运行态改变为完成态，将作业及相关结果送入磁盘上的输出井。作业终止进程负责将输出井中的作业利用打印机输出，回收作业所占用的资源，删除作业有关的数据结构,删除作业在磁盘输出井中的信息等。作业终止进程撤除一道作业后，可向作业调度进程请求进行新的作业调度。至此，一道进入系统运行的作业全部结束。</p>
<h6 id="分时系统中作业与进程的关系"><a href="#分时系统中作业与进程的关系" class="headerlink" title="分时系统中作业与进程的关系"></a>分时系统中作业与进程的关系</h6><p>在分时系统中，作业的提交方法、组织形式均与批处理作业有很大差异。分时系统的用户通过命令语言逐条与系统应合八把武大系体自动时，系统为每个终端设备建立一个进程（称为终端统内部对应一个(以右T经程序，命令解释程序从终端设备读入俞令，解藉疯令是一茶后台命进程)，该进程执仃类令n可以创建一个子进程去具体执行。若当HPN根据需要创建子孙进程。条命令。对于每条终端命令，可以创建一个子进程去具体执行。若当前的终端命令是一条后台命令，则可以和下一条终端命令并行处理。各子进程在运行过程中完全可以根据需要创建子孙进程。终端命令所对应的进程结束后，命令的功能也相应处理完毕。用户本次上机完毕，用户通过一条登出命令即结束上机过程。</p>
<p>分时系统的作业就是用户的一次上机交互过程，可以认为终端进程的创建是一个交互作业的开始，登出命令运行结束代表用户交互作业的终止。</p>
<p>命令解释程序流程扮演着批处理系统中作业控制语言解释程序的角色，只不过命令解释程序是从用户终端接收命令。</p>
<h6 id="交互地提交批作业"><a href="#交互地提交批作业" class="headerlink" title="交互地提交批作业"></a>交互地提交批作业</h6><p>在同时支持交互和批处理的操作系统中，人们可以用交互的方式准备好批作业的有关程序、数据及作业控制说明书。比如，可用交互式系统提供的全屏幕编辑命令编辑好自编的一个天气预报程序，用编译及装配命令将程序变成可执行文件，用调试命令进行程序调试。调试成功后，用户每天都要做如下工作:准备原始天气数据，运行天气预报执行文件处理原始数据，把结果打印出来等。这时，用交互系统提供的全屏幕编辑命令编辑好将要提交的作业控制说明书文件，如Windows系统的 bat 文件和 Linux系统的sh文件。然后用一条作业提交命令将作业提交到系统作业队列中。系统有专门的作业调度进程负责从作业队列中选择作业，为被选取的作业创建一个父进程运行命令解释程序，解释执行作业控制说明书文件中的命令。</p>
<h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p>【考纲内容】</p>
<p>(一）内存管理基础</p>
<p>内存管理概念;程序装入与链接;逻辑地址与物理地址空间;内存保护</p>
<p>连续分配管理方式</p>
<p>非连续分配管理方式:分页管理方式;分段管理方式;段页式管理方式</p>
<p>(二）虚拟内存管理</p>
<p>虚拟内存的基本概念;请求分页管理方式;页面置换算法</p>
<p>页面分配策略;工作集;抖动</p>
<p>【知识框架】</p>
<ul>
<li>程序执行过程<ul>
<li>编译、连接、装入</li>
<li>逻辑地址和物理地址</li>
</ul>
</li>
<li>扩充内存————覆盖与变换</li>
<li>连续分配<ul>
<li>单一连续分配</li>
<li>固定分区分配————内部碎片</li>
<li>动态分区分配<ul>
<li>外部碎片</li>
<li>分配算法：首次、最佳、最坏、邻近适应</li>
</ul>
</li>
</ul>
</li>
<li>非连续分配<ul>
<li>页式存储管理<ul>
<li>概念:页面、地址结构、页表</li>
<li>地址变化机构及变换过程</li>
<li>快表</li>
</ul>
</li>
<li>段式存储管理————段表、地址变换机构、段的共享与保护</li>
<li>段式存储管理————段表、页表</li>
</ul>
</li>
<li>虚拟内存<ul>
<li>概念<ul>
<li>局部性原理</li>
<li>特征:多次性、对换性、虚拟性</li>
</ul>
</li>
<li>请求分页<ul>
<li>组成：页表机构、缺页中断机构、地址变换机构</li>
<li>页面置换算法<ul>
<li>最佳置换(OPT)</li>
<li>先进先出(FIFO)————Belady异常</li>
<li>最近最久未使用(LRU)</li>
<li>时钟(CLOCK)算法</li>
</ul>
</li>
<li>页面分配策略</li>
<li>抖动、工作集</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>【复习提示】</p>
<p>内存管理和进程管理是操作系统的核心内容，需要重点复习。本章围绕分页机制展开:通过分页管理方式在物理内存大小的基础上提高内存的利用率，再进一步引入请求分页管理方式，实现虚拟内存，使内存脱离物理大小的限制，从而提高处理器的利用率。</p>
<h3 id="内存管理概念"><a href="#内存管理概念" class="headerlink" title="内存管理概念"></a>内存管理概念</h3><p>在学习本节时，请读者思考以下问题:</p>
<p>1）为什么要进行内存管理?</p>
<p>2）页式管理中每个页表项大小的下限如何决定?</p>
<p>3）多级页表解决了什么问题?又会带来什么问题?</p>
<p>在学习经典的管理方法前，同样希望读者先思考，自己给出一些内存管理的想法，并在学习过程中和经典方案进行比较。注意本节给出的内存管理是循序渐进的，后一种方法通常会解决前一种方法的不足。希望读者多多思考，比较每种方法的异同，着重掌握页式管理。</p>
<h4 id="内存管理的基本原理和要求"><a href="#内存管理的基本原理和要求" class="headerlink" title="内存管理的基本原理和要求"></a>内存管理的基本原理和要求</h4><p>内存管理(Memory Management）是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件技术一直在飞速发展，内存容量也在不断增大，但仍然不可能将所有用户进程和系统所需要的全部程序与数据放入主存，因此操作系统必须对内存空间进行合理的划分和有效的动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。</p>
<p>有效的内存管理在多道程序设计中非常重要，它不仅可以方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。</p>
<p>内存管理的功能有:</p>
<ul>
<li>内存空间的分配与回收。由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。</li>
<li>地址转换。在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。</li>
<li>内存空间的扩充。利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。</li>
<li>存储保护。保证各道作业在各自的存储空间内运行，互不干扰。</li>
</ul>
<p>在进行具体的内存管理之前，需要了解进程运行的基本原理和要求。</p>
<h5 id="程序装入和链接"><a href="#程序装入和链接" class="headerlink" title="程序装入和链接"></a>程序装入和链接</h5><p>创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤:</p>
<ul>
<li>编译。由编译程序将用户源代码编译成若干目标模块。</li>
<li>链接。由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起，形成一个完整的装入模块。</li>
<li>装入。由装入程序将装入模块装入内存运行。</li>
</ul>
<p>这三步过程如图3.1所示。</p>
<details><summary>图3.1将用户程序变为可在内存中执行的程序的步骤</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926001932.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926001932.png';" /></details>

<p>程序的链接有以下三种方式。</p>
<ul>
<li>静态链接。在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。</li>
<li>装入时动态链接。将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的方式。</li>
<li>运行时动态链接。对某些目标模块的链接，是在程序执行中需要该目标模块时才进行的。其优点是便于修改和更新，便于实现对目标模块的共享。</li>
</ul>
<p>内存的装入模块在装入内存时，同样有以下三种方式:</p>
<p>1）绝对装入。在编译时，若知道程序将驻留在内存的某个位置，则编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，因此不需对程序和数据的地址进行修改。绝对装入方式只适用于单道程序环境。另外，程序中所用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中采用的是符号地址，编译或汇编时再转换为绝对地址。</p>
<p>2）可重定位装入。在多道程序环境下，多个目标模块的起始地址（简称始址）通常都从О开始，程序中的其他地址都是相对于始址的，此时应采用可重定位装入方式。根据内存的当前情况，将装入模块装入内存的适当位置。装入时对目标程序中指令和数据的修改﹒过程称为重定位,地址变换通常是在装入时一次完成的,所以又称静态重定位,如图3.2(a)所示。</p>
<p>静态重定位的特点是，一个作业装入内存时，必须给它分配要求的全部内存空间，若没有足够的内存，则不能装入该作业。此外，作业一旦进入内存，整个运行期间就不能在内存中移动，也不能再申请内存空间。</p>
<p>3）动态运行时装入，也称动态重定位。程序在内存中若发生移动，则需要采用动态的装入方式。装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持，如图3.2(b)所示。</p>
<p>动态重定位的特点如下:可以将程序分配到不连续的存储区中;在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存;便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。</p>
<details><summary>图3.2 重定位类型</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926002103.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002103.png';" /></details>

<h5 id="逻辑地址空间与物理地址空间"><a href="#逻辑地址空间与物理地址空间" class="headerlink" title="逻辑地址空间与物理地址空间"></a>逻辑地址空间与物理地址空间</h5><p>编译后,每个目标模块都从0号单元开始编址,这称为该目标模块的相对地址(或逻辑地址)。当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的，只有系统编程人员才会涉及内存管理的具体机制。不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。</p>
<p>物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为地址重定位。</p>
<h5 id="内存保护"><a href="#内存保护" class="headerlink" title="内存保护"></a>内存保护</h5><p>内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。内存保护可采取两种方法:</p>
<p>1）在CPU 中设置一对上、下限寄存器，存放用户作业在主存中的下限和上限地址，每当CPU要访问一个地址时，分别和两个寄存器的值相比，判断有无越界。</p>
<p>2）采用重定位寄存器（或基址寄存器）和界地址寄存器（又称限长寄存器）来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值。每个逻辑地址值必须小于界地址寄存器;内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元,如图3.3所示。</p>
<details><summary>图3.3 重定位和界地址寄存器的硬件支持</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926002456.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002456.png';" /></details>

<p>实现内存保护需要重定位寄存器和界地址寄存器，因此要注意两者的区别。重定位寄存器是用来“加”的，逻辑地址加上重定位寄存器中的值就能得到物理地址;界地址寄存器是用来“比”的，通过比较界地址寄存器中的值与逻辑地址的值来判断是否越界。</p>
<h4 id="覆盖与交换"><a href="#覆盖与交换" class="headerlink" title="覆盖与交换"></a>覆盖与交换</h4><p>覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。</p>
<h5 id="覆盖"><a href="#覆盖" class="headerlink" title="覆盖"></a>覆盖</h5><p>早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。</p>
<p>覆盖的基本思想如下:由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序)，因此可把用户空间分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。</p>
<p>覆盖技术的特点是，打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存。</p>
<h5 id="交换"><a href="#交换" class="headerlink" title="交换"></a>交换</h5><p>交换（对换）的基本思想是，把处于等待状态（或在CPU 调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称换出;把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称换入。第2章介绍的中级调度采用的就是交换技术。</p>
<p>例如，有一个CPU采用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚刚执行过的进程换出，将另一进程换入刚刚释放的内存空间。同时，CPU调度器可以将时间片分配给其他已在内存中的进程。每个进程用完时间片都与另一进程交换。在理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。</p>
<p>有关交换，需要注意以下几个问题:</p>
<ul>
<li>交换需要备份存储，通常是快速磁盘。它必须足够大，并提供对这些内存映像的直接访问。</li>
<li>为了有效使用CPU，需要使每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。</li>
<li>若换出进程，则必须确保该进程完全处于空闲状态。</li>
<li>交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用起来可能很快。</li>
<li>交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时就暂停。</li>
<li>普通的交换使用不多，但交换策略的某些变体在许多系统(如UNIX系统)中仍发挥作用。</li>
</ul>
<p>交换技术主要在不同进程（或作业)之间进行，而覆盖则用于同一个程序或进程中。由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史;而交换技术在现代操作系统中仍具有较强的生命力。</p>
<h4 id="连续分配管理方式"><a href="#连续分配管理方式" class="headerlink" title="连续分配管理方式"></a>连续分配管理方式</h4><p>连续分配方式是指为一个用户程序分配一个连续的内存空间，譬如某用户需要1GB的内存空间，连续分配方式就在内存空间中为用户分配一块连续的1GB空间。连续分配方式主要包括单一连续分配、固定分区分配和动态分区分配。</p>
<h5 id="单一连续分配"><a href="#单一连续分配" class="headerlink" title="单一连续分配"></a>单一连续分配</h5><p>内存在此方式下分为系统区和用户区，系统区仅供操作系统使用，通常在低地址部分;用户区是为用户提供的、除系统区之外的内存空间。这种方式无须进行内存保护。因为内存中永远只有一道程序，因此肯定不会因为访问越界而干扰其他程序。</p>
<p>这种方式的优点是简单、无外部碎片，可以采用覆盖技术，不需要额外的技术支持。缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。</p>
<h5 id="固定分区分配"><a href="#固定分区分配" class="headerlink" title="固定分区分配"></a>固定分区分配</h5><p>固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区，如此循环。</p>
<p>固定分区分配在划分分区时有两种不同的方法，如图3.4所示。</p>
<details><summary>图3.4 固定分区分配的两种方法</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926002917.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002917.png';" /></details>

<p>为便于内存分配,通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的始址、大小及状态（是否已分配)，如图3.5(a)所示。当有用户程序要装入时，便检索该表，以找到合适的分区给予分配并将其状态置为“已分配”，未找到合适分区时，则拒绝为该用户程序分配内存。存储空间的分配情况如图3.5(b)所示。</p>
<details><summary>图3.5 固定分区说明表和内存分配情况</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926002959.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926002959.png';" /></details>

<p>这种分区方式存在两个问题:一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间;二是主存利用率低，当程序小于固定分区大小时，也占用一个完整的内存分区空间，这样分区内部就存在空间浪费，这种现象称为内部碎片。</p>
<p>固定分区是可用于多道程序设计的最简单的存储分配，无外部碎片，但不能实现多进程共享一个主存区，所以存储空间利用率低。固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对象的控制系统中仍发挥着一定的作用。</p>
<h5 id="动态分区分配"><a href="#动态分区分配" class="headerlink" title="动态分区分配"></a>动态分区分配</h5><p>动态分区分配又称可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先划分内存，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此，系统中分区的大小和数目是可变的。</p>
<p>如图3.6所示，系统有64MB内存空间，其中低8MB固定分配给操作系统，其余为用户可用内存。开始时装入前三个进程，它们分别分配到所需的空间后，内存只剩下4MB，进程4无法装入。在某个时刻，内存中没有一个就绪进程，CPU出现空闲，操作系统就换出进程2，换入进程4。由于进程4比进程2小，这样在主存中就产生了一个6MB 的内存块。之后CPU又出现空闲，而主存无法容纳进程2，操作系统就换出进程1，换入进程2。</p>
<details><summary>图3.6动态分区</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926003108.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926003108.png';" /></details>

<p>动态分区在开始分配时是很好的，但之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片(（图3.6中最后的4MB和中间的6MB，且随着进程的换入/换出，很可能会出现更多、更小的内存块)，内存的利用率随之下降。这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与固定分区中的内部碎片正好相对。克服外部碎片可以通过紧凑(Compaction）技术来解决，即操作系统不时地对进程进行移动和整理。但这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于Windows系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。</p>
<p>在进程装入或换入主存时，若内存中有多个足够大的空闲块，则操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略。考虑以下几种算法:</p>
<p>1）首次适应(First Fit）算法。空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。</p>
<p>2）最佳适应（Best Fit）算法。空闲分区按容量递增的方式形成分区链，找到第一个能满足要求的空闲分区。</p>
<p>3）最坏适应(Worst Fit）算法。又称最大适应（Largest Fit）算法，空闲分区以容量递减的次序链接，找到第一个能满足要求的空闲分区，即挑选出最大的分区。</p>
<p>4）邻近适应(Next Fit）算法。又称循环首次适应算法，由首次适应算法演变而成。不同之处是，分配内存时从上次查找结束的位置开始继续查找。</p>
<p>在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。在UNIX系统的最初版本中，就是使用首次适应算法为进程分配内存空间的，它使用数组的数据结构（而非链表）来实现。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此增加了查找的开销。</p>
<p>邻近适应算法试图解决这个问题。但实际上，它常常导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配）分裂成小碎片。它通常比首次适应算法的结果要差。</p>
<p>最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，会产生最多的外部碎片。</p>
<p>最坏适应算法与最佳适应算法相反，它选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大内存块，因此性能也非常差。</p>
<p>Knuth 和 Shore分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明:首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。另外要注意，在算法实现时，分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法只需要简单查找;在回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂)，需要将这些块合并。在算法实现时，使用数组或链表进行管理。除了内存的利用率，这里的算法开销也是操作系统设计需要考虑的一个因素。</p>
<p>三种内存分区管理方式的比较见表3.1。</p>
<details><summary>表3.1 三种内存分区管理方式的比较</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926003302.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926003302.png';" /></details>

<p>以上三种内存分区管理方法有一个共同特点，即用户进程（或作业）在主存中都是连续存放的。这里对它们进行比较和总结。</p>
<h4 id="非连续分配管理方式"><a href="#非连续分配管理方式" class="headerlink" title="非连续分配管理方式"></a>非连续分配管理方式</h4><p>非连续分配允许一个程序分散地装入不相邻的内存分区。在连续分配管理方式中，我们发现，即使内存有超过1GB的空闲空间，但若没有连续的1GB空间，则需要1GB空间的作业仍然是无法运行的;但若采用非连续分配管理方式，则作业所要求的1GB内存空间可以分散地分配在内存的各个区域，当然，这也需要额外的空间去存储它们（分散区域）的索引，使得非连续分配方式的存储密度低于连续存储方式的。</p>
<p>非连续分配管理方式根据分区的大小是否固定，分为分页存储管理方式和分段存储管理方式。</p>
<p>在分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行，分为基本分页存储管理方式和请求分页存储管理方式。下面介绍基本分页存储管理方式。</p>
<h5 id="基本分页存储管理方式"><a href="#基本分页存储管理方式" class="headerlink" title="基本分页存储管理方式"></a>基本分页存储管理方式</h5><p>固定分区会产生内部碎片﹐动态分区会产生外部碎片,这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想:把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。</p>
<p>分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点:块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片)。</p>
<h6 id="分页存储的几个基本概念"><a href="#分页存储的几个基本概念" class="headerlink" title="分页存储的几个基本概念"></a>分页存储的几个基本概念</h6><p>①页面和页面大小。进程中的块称为页(Page)，内存中的块称为页框(Page Frame，或页帧)。外存也以同样的单位进行划分，直接称为块（Block)。进程在执行时需要申请主存空间，即要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。为方便地址转换，页面大小应是⒉的整数幂。同时页面大小应该适中，页面太小会使进程的页面数过多，这样页表就会过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率;页面过大又会使页内碎片增多，降低内存的利用率。所以页面的大小应该适中，要在空间效率和时间效率之间权衡。</p>
<p>②地址结构。分页存储管理的逻辑地址结构如图3.7所示。</p>
<details><summary>图3.7 分页存储管理的逻辑地址结构</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926131515.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926131515.png';" /></details>

<p>地址结构包含两部分:前一部分为页号P，后一部分为页内偏移量W。地址长度为32位，其中 0～11位为页内地址，即每页大小为4KB;12~31位为页号，地址空间最多允许 $2^{20}$ 页。</p>
<p>注意，地址结构决定了虚拟内存的寻址空间有多大。在实际问题中，页号、页内偏移、逻辑地址大多都是用十进制数给出的。题目用二进制地址的形式给出时，读者要会转换。</p>
<p>③页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立张页表，它记录页面在内存中对应的物理块号，页表一般存放在内存中。页表是由页表项组成的，初学者容易混淆页表项与地址结构，页表项与地址都由两部构成，而且第一部分都是页号，但页表项的第二部分是物理内存中的块号，而地址的;二部分是页内偏移;页表项的第二部分与地址的第二部分共同组成物理地址。<br>在配置页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见页表的作用是实现从页号到物理块号的地址映射，如图3.8所示。</p>
<details><summary>图3.8 页表的作用</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926131629.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926131629.png';" /></details>

<h6 id="基本地址变换机构"><a href="#基本地址变换机构" class="headerlink" title="基本地址变换机构"></a>基本地址变换机构</h6><p>地址变换机构的任务是将逻辑地址转换为内存中的物理地址。地址变换是借助于页表实现的。图3.9给出了分页存储管理系统中的地址变换机构。</p>
<details><summary>图3.9 分页存储管理系统中的地址变换机构</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926131714.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926131714.png';" /></details>

<p>在系统中通常设置一个页表寄存器（PTR)，存放页表在内存的起始地址F和页表长度M。进程未执行时，页表的始址和长度存放在进程控制块中，当进程执行时，才将页表始址和长度存入页表寄存器。设页面大小为L，逻辑地址A到物理地址E的变换过程如下（逻辑地址、页号、每页的长度都是十进制数):</p>
<p>①计算页号P(P=AIL）和页内偏移量W(W=A%L)。</p>
<p>${\textstyle\unicode{x2461}}$  比较页号Р和页表长度M，若P≥M，则产生越界中断，否则继续执行。</p>
<p>${\textstyle\unicode{x2462}}$  页表中页号Р对应的页表项地址=页表始址F＋页号Px页表项长度，取出该页表项内容b，即为物理块号。要注意区分页表长度和页表项长度。页表长度的值是指一共有多少页，页表项长度是指页地址占多大的存储空间。</p>
<p>④计算E=b×L＋W，用得到的物理地址E去访问内存。</p>
<p>以上整个地址变换过程均是由硬件自动完成的。例如，若页面大小L为1KB，页号2对应的物理块为b=8，计算逻辑地址A=2500的物理地址E的过程如下:P=2500/1K=2，W = 2500%1K=452，查找得到页号2对应的物理块的块号为8，E=8×1024+452=8644。</p>
<p>要再次提醒读者的是，题目中条件用十进制数给出和用二进制数给出的处理过程会稍有不同。同时读者会发现，页式管理只需给出一个整数就能确定对应的物理地址，因为页面大小L是固定的。因此，页式管理中地址空间是 $\color{green}{\text{一维的}}$ 。</p>
<p>页表项的大小不是随意规定的，而是有所约束的。如何确定页表项的大小?</p>
<p>页表项的作用是找到该页在内存中的位置。以32位逻辑地址空间、字节编址单位、一页4KB为例，地址空间内一共有 $2^{32}$ B/4KB= 1M页，因此需要 $log_21M$  = 20位才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小≥ $\lceil 20/81 \rceil$  =3B。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于3B，当然，也可选择更大的页表项让一个页面能够正好容下整数个页表项,进而方便存储(如取成4B，一页正好可以装下1K个页表项)，或增加一些其他信息。</p>
<p>下面讨论分页管理方式存在的两个主要问题:①每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低;②每个进程引入页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。</p>
<h6 id="具有快表的地址变换机构"><a href="#具有快表的地址变换机构" class="headerlink" title="具有快表的地址变换机构"></a>具有快表的地址变换机构</h6><p>由上面介绍的地址变换过程可知，若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存:第一次是访问页表，确定所存取的数据或指令的物理地址;第二次是根据该地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。</p>
<p>为此，在地址变换机构中增设一个具有并行查找能力的高速缓冲存储器—快表，又称相联存储器(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表常称为慢表。具有快表的地址变换机构如图3.10所示。</p>
<details><summary>图3.10 具有快表的地址变换机构</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926132136.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926132136.png';" /></details>

<p>在具有快表的分页机制中，地址的变换过程如下:</p>
<p>${\textstyle\unicode{x2460}}$  CPU给出逻辑地址后，由硬件进行地址转换，将页号送入高速缓存寄存器，并将此页号<br>与快表中的所有页号进行比较。</p>
<p>②若找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框<br>号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。</p>
<p>${\textstyle\unicode{x2462}}$ 若未找到匹配的页号，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。</p>
<blockquote>
<p>注意:有些处理机设计为快表和慢表同时查找，若在快表中查找成功则终止慢表的查找。</p>
</blockquote>
<p>一般快表的命中率可达90%以上，这样分页带来的速度损失就可降低至10%以下。快表的有效性基于著名的局部性原理，后面讲解虚拟内存时将会具体讨论它。</p>
<h6 id="两级页表"><a href="#两级页表" class="headerlink" title="两级页表"></a>两级页表</h6><p>由于引入了分页管理，进程在执行时不需要将所有页调入内存页框，而只需将保存有映射关系的页表调入内存。但是，我们仍然需要考虑页表的大小。以32位逻辑地址空间、页面大小4KB、页表项大小4B为例，若要实现进程对全部逻辑地址空间的映射，则每个进程需要 $2^{20}$ 即约100万个页表项。也就是说，每个进程仅页表这一项就需要4MB 主存空间，这显然是不切实际的。即便不考虑对全部逻辑地址空间进行映射的情况，一个逻辑地址空间稍大的进程，其页表大小也可能是过大的。以一个40MB的进程为例，页表项共40KB (40MB/4KBx4B)，若将所有页表项内容保存在内存中，则需要10个内存页框来保存整个页表。整个进程大小约为1万个页面，而实际执行时只需要几十个页面进入内存页框就可运行，但若要求10个页面大小的页表必须全部进入内存，则相对实际执行时的几十个进程页面的大小来说，肯定降低了内存利用率;从另一方面来说，这10页的页表项也并不需要同时保存在内存中，因为在大多数情况下，映射所需要的页表项都在页表的同一个页面中。</p>
<p>为了压缩页表，我们进一步延伸页表映射的思想，就可得到二级分页，即使用层次结构的页表:将页表的10页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的10个页面进行映射只需要10个页表项，所以上一级页表只需要1页就已足够（可以存储210=1024个页表项)。在进程执行时，只需要将这一页的上一级页表调入内存即可，进程的页表和进程本身的页面可在后面的执行中再调入内存。根据上面提到的条件（32位逻辑地址空间、页面大小4KB、页表项大小4B，以字节为编址单位)，我们来构造一个适合的页表结构。页面大小为4KB，页内偏移地址为 $log_2 4K$ =12位，页号部分为20位，若不采用分级页表，则仅页表就要占用 $2^{20}$ ×4B/4KB = 1024页，这大大超过了许多进程自身需要的页面，对于内存来说是非常浪费资源的，而且查询页表工作也会变得十分不便、试想若把这些页表放在连续的空间内，查询对应页的物理页号时可以通过页表首页地址＋页号×4B的形式得到，而这种方法查询起来虽然相对方便，但连续的1024页对于内存的要求实在太高，并且上面也说到了其中大多数页面都是不会用到的，所以这种方法并不具有可行性。若不把这些页表放在连续的空间里，则需要一张索引表来告诉我们第几张页表该上哪里去找，这能解决页表的查询问题，且不用把所有的页表都调入内存，只在需要它时才调入(下节介绍的虚拟存储器思想)，因此能解决占用内存空间过大的问题。读者也许发现这个方案就和当初引进页表机制的方式一模一样，实际上就是构造一个页表的页表，也就是二级页表。为查询方便，顶级页表最多只能有1个页面(一定要记住这个规定)，因此顶级页表总共可以容纳4KB/4B= 1K个页表项，它占用的地址位数为 $log_2 lK$ = 10位，而之前已经计算出页内偏移地址占用了12位，因此一个32位的逻辑地址空间就剩下了10位，正好使得二级页表的大小在一页之内，这样就得到了逻辑地址空间的格式，如图3.11所示。</p>
<details><summary>图3.11 逻辑地址空间的格式</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926132611.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926132611.png';" /></details>

<p>二级页表实际上是在原有页表结构上再加上一层页表，示意结构如图3.12所示。</p>
<details><summary>图3.12 二级页表结构示意图</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926132635.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926132635.png';" /></details>

<p>建立多级页表的目的在于建立索引，以便不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项。</p>
<h5 id="基本分段存储管理方式"><a href="#基本分段存储管理方式" class="headerlink" title="基本分段存储管理方式"></a>基本分段存储管理方式</h5><p>分页管理方式是从计算机的角度考虑设计的,目的是提高内存的利用率，提升计算机的性能。分页通过硬件机制实现，对用户完全透明。分段管理方式的提出则考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。</p>
<p>1）分段。段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5段，每段从О开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的)，其逻辑地址由段号S与段内偏移量w两部分组成。</p>
<p>在图3.13中，段号为16位，段内偏移量为16位，因此一个作业最多有 $2^{16}$ =65536段,最大段长为64KB。</p>
<details><summary>图3.13 分段系统中的逻辑地址结构</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926144214.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144214.png';" /></details>

<p>在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显式提供，在高级程序设计语言中，这个工作由编译程序完成。</p>
<p>2）段表。每个进程都有一张逻辑空间与内存空间映射的段表，其中每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度。段表的内容如图3.14所示。</p>
<details><summary>图3.14 段表的内容</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926144307.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144307.png';" /></details>

<p>配置段表后，执行中的进程可通过查找段表，找到每段所对应的内存区。可见，段表用于实现从逻辑段到物理内存区的映射，如图3.15所示。</p>
<p>3）地址变换机构。分段系统的地址变换过程如图3.16所示。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址F和段表长度M。从逻辑地址A到物理地址E之间的地址变换过程如下:</p>
<details><summary>图3.15 利用段表实现物理内存区映射</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926144352.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144352.png';" /></details>

<details><summary>图3.16 分段系统的地址变换过程</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926144411.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926144411.png';" /></details>

<p>①从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W，注意在段式存储管理的题目中，逻辑地址一般以二进制数给出，而在页式存储管理中，逻辑地址一般以十进制数给出，读者要具体问题具体分析。</p>
<p>②比较段号S和段表长度M，若S≥M，则产生越界中断，否则继续执行。</p>
<p>③段表中段号S对应的段表项地址=段表始址F＋段号S×段表项长度，取出该段表项的前几位得到段长C。若段内偏移量≥C，则产生越界中断，否则继续执行。从这句话我们可以看出，段表项实际上只有两部分，前几位是段长，后几位是始址。</p>
<p>${\textstyle\unicode{x2463}}$  取出段表项中该段的始址b，计算E=b＋W，用得到的物理地址E去访问内存。</p>
<p>4）段的共享与保护。在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据可以共享，而可修改的代码和数据不能共享。</p>
<p>与分页管理类似，分段管理的保护方法主要有两种:一种是存取控制保护，另一种是地址越界保护。地址越界保护将段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度，则产生越界中断;再将段表项中的段长和逻辑地址中的段内偏移进行比较，若段内偏移大于段长，也会产生越界中断。分页管理中的地址越界保护只需要判断页号是否越界，页内偏移是不可能越界的。</p>
<p>与页式管理不同，段式管理不能通过给出一个整数便确定对应的物理地址，因为每段的长度是不固定的，无法通过整数除法得出段号，无法通过求余得出段内偏移，所以段号和段内偏移一定要显式给出（段号，段内偏移)，因此分段管理的地址空间是二维的。</p>
<h5 id="段页式管理方式"><a href="#段页式管理方式" class="headerlink" title="段页式管理方式"></a>段页式管理方式</h5><p>页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来，便形成了段页式存储管理方式。</p>
<p>在段页式系统中，作业的地址空间首先被分成若干逻辑段，每段都有自己的段号，然后将每段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位，如图3.17所示。</p>
<p>在段页式系统中，作业的逻辑地址分为三部分:段号、页号和页内偏移量，如图3.18所示。</p>
<details><summary>图3.18 段页式系统的逻辑地址结构</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926150756.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926150756.png';" /></details>

<p>为了实现地址变换，系统为每个进程建立一张段表，每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表始址和段表长度（段表寄存器和页表寄存器的作用都有两个，一是在段表或页表中寻址，二是判断是否越界)。</p>
<blockquote>
<p>注意:在一个进程中，段表只有一个，而页表可能有多个。</p>
</blockquote>
<p>在进行地址变换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最后形成物理地址。如图3.19所示，进行一次访问实际需要三次访问主存，这里同样可以使用快表来加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。</p>
<details><summary>图3.19 段页式系统的地址变换机构</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926150852.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926150852.png';" /></details>

<p>结合上面对段式管理和页式管理的地址空间的分析，可以得出结论:段页式管理的地址空间是二维的。</p>
<h4 id="本节小结-3"><a href="#本节小结-3" class="headerlink" title="本节小结"></a>本节小结</h4><p>本节开头提出的问题的参考答案如下。</p>
<h5 id="为什么要进行内存管理"><a href="#为什么要进行内存管理" class="headerlink" title="为什么要进行内存管理?"></a>为什么要进行内存管理?</h5><p>在单道批处理系统阶段，一个系统在一个时间段内只执行一个程序，内存的分配极其简单，即仅分配给当前运行的进程。引入多道程序的并发执行后，进程之间共享的不仅仅是处理机，还有主存储器。然而，共享主存会形成一些特殊的挑战。若不对内存进行管理，则容易导致内存数据的混乱，以至于限制进程的并发执行。因此，为了更好地支持多道程序并发执行，必须进行内存管理。</p>
<h5 id="页式管理中每个页表项大小的下限如何决定"><a href="#页式管理中每个页表项大小的下限如何决定" class="headerlink" title="页式管理中每个页表项大小的下限如何决定?"></a>页式管理中每个页表项大小的下限如何决定?</h5><p>页表项的作用是找到该页在内存中的位置。以32位逻辑地址空间、字节编址单位、一页4KB为例，地址空间内共含有 $2^{32}$ B/4KB= 1M页，需要 $log_2 1M$  = 20位才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小≥  $\lceil 20/8 \rceil$  =3B。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于3B;当然，也可选择更大的页表项大小，让一个页面能够正好容下整数个页表项，以方便存储（例如取成4B，一页正好可以装下1K个页表项)，或增加一些其他信息。</p>
<h5 id="多级页表解决了什么问题-又会带来什么问题"><a href="#多级页表解决了什么问题-又会带来什么问题" class="headerlink" title="多级页表解决了什么问题?又会带来什么问题?"></a>多级页表解决了什么问题?又会带来什么问题?</h5><p>多级页表解决了当逻辑地址空间过大时，页表的长度会大大增加的问题。而采用多级页表时，一次访盘需要多次访问内存甚至磁盘，会大大增加一次访存的时间。</p>
<p>不少读者表示本节的内容难以掌握，实际上本节的内容并不难，只要抓住下列几个关键的线索，本节的所有知识点就能了然于胸。</p>
<p>无论是段式管理、页式管理还是段页式管理，读者都只需要关注三个问题:①逻辑地址结构，②表项结构，③寻址过程。搞清楚这三个问题，就相当于搞清楚了上面几种存储管理方式。再次提醒读者区分逻辑地址结构和表项结构。</p>
<h3 id="虚拟内存管理"><a href="#虚拟内存管理" class="headerlink" title="虚拟内存管理"></a>虚拟内存管理</h3><p>在学习本节时，请读者思考以下问题:</p>
<p>1）为什么要引入虚拟内存?</p>
<p>2）虚拟内存空间的大小由什么因素决定?</p>
<p>3）虚拟内存是怎么解决问题的?会带来什么问题?</p>
<p>读者要掌握虚拟内存解决问题的思想，并了解几种替换算法的优劣，熟练掌握虚实地址的变换方法。</p>
<h4 id="虚拟内存的基本概念"><a href="#虚拟内存的基本概念" class="headerlink" title="虚拟内存的基本概念"></a>虚拟内存的基本概念</h4><h5 id="传统存储管理方式的特征"><a href="#传统存储管理方式的特征" class="headerlink" title="传统存储管理方式的特征"></a>传统存储管理方式的特征</h5><p>3.1节讨论的各种内存管理策略都是为了同时将多个进程保存在内存中，以便允叶进仃多道程序设计。它们都具有以下两个共同的特征:</p>
<p>1）一次性。作业必须一次性全部装入内存后，才能开始运行。这会导致两种情况:①当作业很大而不能全部被装入内存时，将使该作业无法运行;②当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。</p>
<p>2）驻留性。作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程会因等待IO而被阻塞，可能处于长期等待状态。</p>
<p>由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据)占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。</p>
<h5 id="局部性原理"><a href="#局部性原理" class="headerlink" title="局部性原理"></a>局部性原理</h5><p>要真正理解虚拟内存技术的思想，首先须了解著名的局部性原理。Bill Joy (SUN公司CEO)说过:“在研究所时，我经常开玩笑地说高速缓存是计算机科学中唯一重要的思想。事实上，高速缓存技术确实极大地影响了计算机系统的设计。”快表、页高速缓存及虚拟内存技术从广义上讲，都属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，又适用于数据结构（更远地讲，Dijkstra 关于“goto 语句有害”的著名论文也出于对程序局部性原理的深刻认识和理解)。</p>
<p>局部性原理表现在以下两个方面:</p>
<p>1）时间局部性。程序中的某条指令一旦执行，不久后该指令可能再次执行;某数据被访问过，不久后该数据可能再次被访问。产生时间局部性的典型原因是程序中存在着大量的循环操作。</p>
<p>2）空间局部性。一旦程序访问了某个存储单元，在不久后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。</p>
<p>时间局部性通过将近来使用的指令和数据保存到高速缓冲存储器中，并使用高速缓存的层次结构实现。空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上建立了“内存-外存”的两级存储器结构，利用局部性原理实现高速缓存。</p>
<h5 id="虚拟存储器的定义和特征"><a href="#虚拟存储器的定义和特征" class="headerlink" title="虚拟存储器的定义和特征"></a>虚拟存储器的定义和特征</h5><p>基于局部性原理，在程序装入时，将程序的一部分装入内存，而将其余部分留在外存，就可启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。</p>
<p>之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明)，给用户的感觉是好像存在一个比实际物理内存大得多的存储器。虚拟存储器的大小由计算机的地址结构决定，并不是内存和外存的简单相加。虚拟存储器有以下三个主要特征:</p>
<p>1)多次性。多次性是指无须在作业运行时一次性地全部装入内存，而允许被分成多次调入内存运行。</p>
<p>2）对换性。对换性是指无须在作业运行时一直常驻内存，而允许在作业的运行过程中，进行换进和换出。</p>
<p>3）虚拟性。虚拟性是指从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际的内存容量。</p>
<h5 id="虚拟内存技术的实现"><a href="#虚拟内存技术的实现" class="headerlink" title="虚拟内存技术的实现"></a>虚拟内存技术的实现</h5><p>虚拟内存技术允许将一个作业分多次调入内存。采用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。</p>
<p>虚拟内存的实现有以下三种方式:</p>
<ul>
<li>请求分页存储管理。</li>
<li>请求分段存储管理。</li>
<li>请求段页式存储管理。</li>
</ul>
<p>不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面:</p>
<ul>
<li>一定容量的内存和外存。</li>
<li>页表机制（或段表机制)，作为主要的数据结构。</li>
<li>中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断。</li>
<li>地址变换机构，逻辑地址到物理地址的变换。</li>
</ul>
<h4 id="请求分页管理方式"><a href="#请求分页管理方式" class="headerlink" title="请求分页管理方式"></a>请求分页管理方式</h4><p>请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。</p>
<p>在请求分页系统中，只要求将当前需要的一部分贝面装入内仔，使可以后4作F亚r)冲业执行过程中，当所要访问的页面不在内存中时，再逋过调贝功能将具痈八，问r还可地且次功能将暂时不用的页面换出到外存上，以便腾出内存空间。</p>
<p>为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。</p>
<h5 id="页表机制"><a href="#页表机制" class="headerlink" title="页表机制"></a>页表机制</h5><p>请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存中的情况，如何发现和处理这种情况是请求分页系统必须解决的两个基本问题。为此，在请求页表项中增加了4个字段，如图3.20所示。</p>
<details><summary>图3.20 请求分页系统中的页表项</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926151836.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926151836.png';" /></details>

<p>增加的4个字段说明如下:</p>
<ul>
<li>状态位P。用于指示该页是否已调入内存，供程序访问时参考。</li>
<li>访问字段A。用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供置换算法换出页面时参考。</li>
<li>修改位M。标识该页在调入内存后是否被修改过。</li>
<li>外存地址。用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。</li>
</ul>
<h5 id="缺页中断机构"><a href="#缺页中断机构" class="headerlink" title="缺页中断机构"></a>缺页中断机构</h5><p>在请求分页系统中，每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，若内存中有空闲块,则分配一个块，将要调入的页装入该块，并修改页表中的相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。</p>
<p>缺页中断作为中断，同样要经历诸如保护CPU环境、分析中断原因、转入缺页中断处理程序、恢复CPU环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别:</p>
<ul>
<li>在指令执行期间而非一条指令执行完后产生和处理中断信号，属于内部中断。</li>
<li>一条指令在执行期间，可能产生多次缺页中断。</li>
</ul>
<h5 id="地址变换机构"><a href="#地址变换机构" class="headerlink" title="地址变换机构"></a>地址变换机构</h5><p>请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟内存，又增加了某些功能而形成的。</p>
<p>如图3.21所示，在进行地址变换时，先检索快表:</p>
<details><summary>图3.21 请求分页中的地址变换过程</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152033.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152033.png';" /></details>

<ul>
<li>若找到要访问的页，则修改页表项中的访问位（写指令还需要重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。</li>
<li>若未找到该页的页表项，则应到内存中去查找页表，再对比页表项中的状态位P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。</li>
</ul>
<h4 id="页面置换算法（决定应该换入哪页、换出哪页"><a href="#页面置换算法（决定应该换入哪页、换出哪页" class="headerlink" title="页面置换算法（决定应该换入哪页、换出哪页)"></a>页面置换算法（决定应该换入哪页、换出哪页)</h4><p>进程运行时，若其访问的页面不在内存中而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。</p>
<p>选择调出页面的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率也就是说，应将以后不会再访问或以后较长时间内不会再访问的页面先调出。</p>
<p>常见的置换算法有以下4种。</p>
<h5 id="最佳-OPT-置换算法"><a href="#最佳-OPT-置换算法" class="headerlink" title="最佳(OPT)置换算法"></a>最佳(OPT)置换算法</h5><p>最佳(Optimal，OPT)置换算法选择的被淘汰页面是以后永不使用的页面，或是在最长时间内不再被访问的页面，以便保证获得最低的缺页率。然而，由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。</p>
<p>最佳置换算法可用来评价其他算法。假定系统为某进程分配了三个物理块，并考虑有页面号引用串7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1。进程运行时，先将7,0,1三个页面依次装入内存。进程要访问页面2时，产生缺页中断，根据最佳置换算法，选择将第18次访问才需调入的页面7淘汰。然后，访问页面0时，因为它已在内存中，所以不必产生缺页中断。访问页面3时，又会根据最佳置换算法将页面1淘汰……以此类推，如图3.22所示，从图中可以看出采用最佳置换算法时的情况。</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152417.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152417.png';" /></details>

<p>最长时间不被访问和以后被访问次数最小是不同的概念，初学者在理解OPT 算法时千万不要混淆。</p>
<p>可以看到，发生缺页中断的次数为9，页面置换的次数为6。</p>
<h5 id="先进先出-FIFO-页面置换算法"><a href="#先进先出-FIFO-页面置换算法" class="headerlink" title="先进先出(FIFO)页面置换算法"></a>先进先出(FIFO)页面置换算法</h5><p>优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。</p>
<p>这里仍用上面的实例采用FIFO算法进行页面置换。进程访问页面2时，把最早进入内存的页面7换出。然后访问页面3时，把2,0,1中最先进入内存的页面0换出。由图3.23可以看出，利用FIFO算法时进行了12次页面置换，比最佳置换算法正好多一倍。</p>
<p>FIFO算法还会产生所分配的物理块数增大而页故障数不减反增的异常现象，这由Belady于1969年发现，因此称为Belady异常。只有FIFO算法可能出现 Belady异常，LRU和OPT算法永远不会出现Belady 异常。</p>
<details><summary>图3.23 利用FIFO置换算法时的置换图</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152522.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152522.png';" /></details>

<p>如图3.24所示，页面访问顺序为3,2,1,0,3,2,4,3,2,1,0,4。若采用FIFO置换算法，当分配的物理块为3个时，缺页次数为9次;当分配的物理块为4个时，缺页次数为10次。分配给进程的物理块增多，但缺页次数不减反增。</p>
<details><summary>图3.24 Belady异常</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152549.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152549.png';" /></details>

<h5 id="最近最久未使用-LRU-置换算法"><a href="#最近最久未使用-LRU-置换算法" class="headerlink" title="最近最久未使用(LRU)置换算法"></a>最近最久未使用(LRU)置换算法</h5><p>选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。</p>
<p>再对上面的实例采用LRU算法进行页面置换，如图3.25所示。进程第一次对页面2访问时，将最近最久未被访问的页面7置换出去。然后在访问页面3时，将最近最久未使用的页面1换出。</p>
<details><summary>3.25 LRU页面置换算法时的置换图</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152649.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152649.png';" /></details>

<p>在图3.25中，前5次置换的情况与最佳置换算法相同，但两种算法并无必然联系。实际上，LRU算法根据各页以前的情况，是“向前看”的，而最佳置换算法则根据各页以后的使用情况，是“向后看”的。</p>
<p>LRU算法的性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现Belady异常。FIFO算法基于队列实现，不是堆栈类算法。</p>
<h5 id="时钟-CLOCK-置换算法"><a href="#时钟-CLOCK-置换算法" class="headerlink" title="时钟(CLOCK)置换算法"></a>时钟(CLOCK)置换算法</h5><p>LRU算法的性能接近于OPT算法，但实现起来比较困难，且开销大;FIFO算法实现简单，但性能差。因此，操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU算法的性能，这类算法都是CLOCK算法的变体。因为算法要循环扫描缓冲区，像时钟的指针一样转动，所以称为CLOCK算法。</p>
<p>简单的CLOCK算法给每帧关联一个附加位，称为使用位。当某页首次装入主存时，将该帧的使用位设置为1;当该页随后再被访问到时，其使用位也被置为1。对于页替换算法，用于替换的候选帧集合可视为一个循环缓冲区，并有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的啊时，操作系统就付以拉旒里刷，所右帧的使用位均为1，始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换;若所有帧的使用位均为1，<br>则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并停留在最初的位置上，替换该帧中的页。由于该算法循环检查各页面的情况，因此称CLOCK算法，又称最近未用(Not RecentlyUsed，NRU）算法。</p>
<p>CLOCK算法的性能比较接近LRU算法，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型CLOCK置换算法。这样，每帧都处于以下4种情况之一:</p>
<ul>
<li>最近未被访问，也未被修改（u = 0,m = 0)</li>
<li>最近被访问，但未被修改(u = 1,m = 0)</li>
<li>最近未被访问，但被修改（u = 0, m = 1)</li>
<li>最近被访问，被修改(u = 1, m= 1)</li>
</ul>
<p>算法执行如下操作步骤:</p>
<p>1)从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧（u =0, m = 0）用于替换。</p>
<p>2）若第1)步失败，则重新扫描，查找(u=0,m= 1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0。</p>
<p>3）若第2）步失败，则指针将回到它的最初位置，且集合中所有帧的使用位均为0。重复第1）步，并且若有必要，重复第2）步，以便可以找到供替换的帧。</p>
<p>改进型CLOCK算法优于简单CLOCK算法的地方在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。</p>
<p>有些读者会认为CLOCK算法和改进型CLOCK算法记忆起来不易。为方便记忆，我们将其总结如下。</p>
<p>操作系统中任何经过优化而有效的页面置换算法都有一个原则，即尽可能保留曾经使用过的页面，而淘汰未使用的页面，认为这样可以在总体上减少换页次数。CLOCK 算法只考虑到是否被访问过，因此被访问过的当然尽可能留下，未使用过的就淘汰;而改进型CLOCK算法对使用过的页面又做了细分，分为使用过但未修改过和使用过且修改过。因此，若有未使用过的页面，则当然首先把它换出，若全部页面都使用过，则当然优先把未修改过的页面换出。</p>
<p>为帮助读者理解，这里举一个例子。假设系统给某进程分配了5个页框，刚开始，进程依次访问1,3,4,2,5号页面，系统会将这些页面连成一个循环队列，刚开始扫描指针指向第一个被访问的页面(即1号页)，如图3.26所示。</p>
<details><summary>图3.26 刚开始扫描时指针指向的页面</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152915.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152915.png';" /></details>

<p>图3.26中，小括号内的数字就是使用位。接下来，若进程请求访问6号页面，则由于此时分配给进程的5个页框都被使用，因此必须选择一个页面置换出去。按照CLOCK置换算法的规则，在第一轮扫描中，指针扫过的页面的使用位应置为0。第一轮扫描的过程如图3.27所示。</p>
<details><summary>图3.27 第一轮扫描的过程</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926152935.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926152935.png';" /></details> 

<p>第一轮扫描中，未找到使用位为0的页面，因此需要进行第二轮扫描。第二轮扫描中，1号页面的使用位为0，因此将1号页面换出，将6号页面换入，将6号页的访问位设置为1，并将扫描指针后移（若下次需要换出页面，则从3号页面开始扫描)，如图3.28所示。</p>
<p>注意一个小细节:假设1号页面原先占有的是 $x$ 号物理块(页框)，则6号页面换入内存后也放在 $x$ 号物理块中。</p>
<details><summary>图3.28 第二轮扫描后指针指向的页面</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926153014.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926153014.png';" /></details>


<h4 id="页面分配策略"><a href="#页面分配策略" class="headerlink" title="页面分配策略"></a>页面分配策略</h4><h5 id="驻留集大小"><a href="#驻留集大小" class="headerlink" title="驻留集大小"></a>驻留集大小</h5><p>对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页都读入主存。因此，操作系统必须决定读取多少页，即决定给特定的进程分配几个页框。给一个进程分配的物理页框的集合就是这个进程的驻留集。需要考虑以下几点:</p>
<p>1）分配给一个进程的存储量越小，任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。</p>
<p>2）若一个进程在主存中的页数过少，则尽管有局部性原理，页错误率仍然会相对较高。</p>
<p>3）若页数过多，则由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。</p>
<p>基于这些因素，现代操作系统通常采用三种策略:</p>
<p>1）固定分配局部置换。它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后调入需要的页面。实现这种策略时，难以确定应为每个进程分配的物理块数目:太少会频繁出现缺页中断，太多又会使CPU和其他资源利用率下降。</p>
<p>2）可变分配全局置换。这是最易于实现的物理块分配和置换策略，它为系统中的每个进程分配一定数目的物理块，操作系统自身也保持一个空闲物理块队列。当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中。这种方法比固定分配局部置换更加灵活，可以动态增加进程的物理块，但也存在弊端如它会盲目地给进程增加物理块，从而导致系统多道程序的并发能力下降。</p>
<p>3）可变分配局部置换。它为每个进程分配一定数目的物理块，当某个进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，因此不会影响其他进程的运行。若进程在运行中频繁地缺页，则系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度;反之，若进程运行中的缺页率特别低，则可适当减少分配给该进程的物理块。比起可变分配全局置换，这种方法不仅可以动态增加进程物理块的数量，还能动态减少进程物理块的数量，在保证进程不会过多地调页的同时，也保持了系统的多道程序并发能力。当然它需要更复杂的实现，也需要更大的开销，但对比频繁地换入/换出所浪费的计算机资源，这种牺牲是值得的。</p>
<p>页面分配策略在2015年的统考选择题中出现过，考查的是这三种策略的名称。往年很多读者看到这里时，由于认为不是重点，复习时便一带而过，最后在考试中失分。在这种基础题上失分是十分可惜的。再次提醒读者，考研成功的秘诀在于“反复多次”和“全面”。</p>
<h5 id="调入页面的时机"><a href="#调入页面的时机" class="headerlink" title="调入页面的时机"></a>调入页面的时机</h5><p>为确定系统将进程运行时所缺的页面调入内存的时机，可采取以下两种调页策略:</p>
<p>1）预调页策略。根据局部性原理，一次调入若干相邻的页可能会比一次调入一页更高效。但若调入的一批页面中大多数都未被访问，则又是低效的。因此，需要采用以预测为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约50%。因此这种策略主要用于进程的首次调入，由程序员指出应先调入哪些页。</p>
<p>2）请求调页策略。进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。由这种策略调入的页一定会被访问，且这种策略比较易于实现，因此在目前的虚拟存储器中大多采用此策略。它的缺点是每次只调入一页，调入/调出页面数多时会花费过多的IO开销。</p>
<p>预调入实际上就是运行前的调入，请求调页实际上就是运行期间调入。一般情况下，两种调页策略会同时使用。</p>
<h5 id="从何处调入页面"><a href="#从何处调入页面" class="headerlink" title="从何处调入页面"></a>从何处调入页面</h5><p>请求分页系统中的外存分为两部分:用于存放文件的文件区和用于存放对换页面的对换区。对换区通常采用连续分配方式，而文件区采用离散分配方式，因此对换区的磁盘IO速度比文件区的更快。这样，从何处调入页面就存在三种情况:</p>
<p>1）系统拥有足够的对换区空间。可以全部从对换区调入所需页面，以提高调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。</p>
<p>2）系统缺少足够的对换区空间。凡不会被修改的文件都直接从文件区调入;而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入（因为读的速度比写的速度快)</p>
<p>3）UNIX方式。与进程有关的文件都放在文件区，因此未运行过的页面都应从文件区调入曾经运行过但又被换出的页面，由于放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无须再从对换区调入。</p>
<h4 id="抖动"><a href="#抖动" class="headerlink" title="抖动"></a>抖动</h4><p>在页面置换过程中，一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种频繁的页面调度行为称为抖动或颠簸。若一个进程在换页上用的时间多于执行时间，则这个进程就在颠簸。</p>
<p>频繁发生缺页中断（抖动）的主要原囚定，术个H在么你放离在稳定状态，几乎主存的所帧数目。虚拟内存技术可在内仔中保留史多的心在坟方问列尽可能多的进程。然而，如果管理不有空间都被进程块占据，处理机和操作系统可以且按w四到可的操3作而不是执行讲程的指令，当，那么处理机的大部分时间都将用于交换块，即请求调入贝面的操作，如个定执1进在了，因此会大大降低系统效率。</p>
<h4 id="工作集"><a href="#工作集" class="headerlink" title="工作集"></a>工作集</h4><p>工作集是指在某段时间间隔内，进程要访问的页面集合。基于局部性原理，可以用最近访问过的页面来确定工作集。一般来说，工作集W可由时间t和工作集窗口大小△来确定。例如，某进程对页面的访问次序如下:</p>
<div style='text-align:center'><details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926153350.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926153350.png';" /></details></div>



<h4 id="地址翻译"><a href="#地址翻译" class="headerlink" title="地址翻译"></a>地址翻译</h4><p>本小节引入一个实例来说明虚实地址的变换过程，考虑到统考试题近来出现了学科综合的趋势，这里结合“计算机组成原理”中的Cache部分进行讲解。对于不参加统考的读者，可以看到翻译出实地址为止，对于参加统考却还没有复习计算机组成原理的读者，可在复习完“计算机组成原理”后，再回来看本章的内容。</p>
<p>设某系统满足以下条件:</p>
<details><summary>图片详情</summary><img src="https://raw.githubusercontent.com/ednow/cloudimg/main/githubio/20210926153519.png" alt="找不到图片(Image not found)" onerror="this.onerror=null;this.src='https://gitee.com/ednow/cloudimg/raw/main/githubio/20210926153519.png';" /></details>

<h4 id="本章小结-1"><a href="#本章小结-1" class="headerlink" title="本章小结"></a>本章小结</h4><h5 id="为什么要引入虚拟内存"><a href="#为什么要引入虚拟内存" class="headerlink" title="为什么要引入虚拟内存?"></a>为什么要引入虚拟内存?</h5><p>上一节提到过，多道程序并发执行不仅使进程之间共享了处理器，而且同时共享了主存。然而，随着对处理器需求的增长，进程的执行速度会以某种合理平滑的方式慢下来。但是，若同时运行的进程太多，则需要很多的内存，当一个程序没有内存空间可用时，那么它甚至无法运行。所以，在物理上扩展内存相对有限的条件下，应尝试以一些其他可行的方式在逻辑上扩充内存。</p>
<h5 id="虚拟内存（虚存）空间的大小由什么因素决定"><a href="#虚拟内存（虚存）空间的大小由什么因素决定" class="headerlink" title="虚拟内存（虚存）空间的大小由什么因素决定?"></a>虚拟内存（虚存）空间的大小由什么因素决定?</h5><p>虚存的容量要满足以下两个条件:</p>
<p>①虚存的实际容量≤内存容量和外存容量之和，这是硬件的硬性条件规定的，若虚存的实际容量超过了这个容量，则没有相应的空间来供虚存使用。</p>
<p>${\textstyle\unicode{x2461}}$  虚存的最大容量≤计算机的地址位数能容纳的最大容量。假设地址是32位的，按字节编址，一个地址代表1B存储空间，则虚存的最大容量≤4GB( $2^{32}$ B)。这是因为若虚存的最大容量超过4GB，则32位的地址将无法访问全部虚存，也就是说4GB 以后的空间被浪费了，相当于没有一样，没有任何意义。</p>
<p>实际虚存的容量是取条件①和②的交集，即两个条件都要满足，仅满足一个条件是不行的。</p>
<h5 id="虚拟内存是怎么解决问题的-会带来什么问题"><a href="#虚拟内存是怎么解决问题的-会带来什么问题" class="headerlink" title="虚拟内存是怎么解决问题的?会带来什么问题?"></a>虚拟内存是怎么解决问题的?会带来什么问题?</h5><p>虚拟内存使用外存上的空间来扩充内存空间，通过一定的换入/换出，使得整个系统在逻辑上能够使用一个远远超出其物理内存大小的内存容量。因为虚拟内存技术调换页面时需要访问外存，会导致平均访存时间增加，若使用了不合适的替换算法，则会大大降低系统性能。</p>
<p>本节学习了4种页面置换算法，要把它们与处理机调度算法区分开。当然，这些调度算法之间也是有联系的，它们都有一个共同点，即通过一定的准则决定资源的分配对象。在处理机调度算法中这些准则比较多，有优先级、响应比、时间片等，而在页面调度算法中就比较简单，即是否被用到过或近段时间内是否经常使用。在操作系统中，几乎每类资源都会有相关的调度算法，读者通过将这些调度算法作为线索，可把整个操作系统的课程连成一个整体。</p>
<h2 id="文件管理-1"><a href="#文件管理-1" class="headerlink" title="文件管理"></a>文件管理</h2><h3 id="文件系统基础"><a href="#文件系统基础" class="headerlink" title="文件系统基础"></a>文件系统基础</h3><h4 id="文件的概念"><a href="#文件的概念" class="headerlink" title="文件的概念"></a>文件的概念</h4><h4 id="文件的逻辑结构"><a href="#文件的逻辑结构" class="headerlink" title="文件的逻辑结构"></a>文件的逻辑结构</h4><h4 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h4><h4 id="文件共享"><a href="#文件共享" class="headerlink" title="文件共享"></a>文件共享</h4><h4 id="文件保护"><a href="#文件保护" class="headerlink" title="文件保护"></a>文件保护</h4><h3 id="文件系统实现"><a href="#文件系统实现" class="headerlink" title="文件系统实现"></a>文件系统实现</h3><h4 id="文件系统层次结构"><a href="#文件系统层次结构" class="headerlink" title="文件系统层次结构"></a>文件系统层次结构</h4><h4 id="目录实现"><a href="#目录实现" class="headerlink" title="目录实现"></a>目录实现</h4><h4 id="文件实现—文件分配方式"><a href="#文件实现—文件分配方式" class="headerlink" title="文件实现—文件分配方式"></a>文件实现—文件分配方式</h4><h4 id="文件实现——文件存储空间管理"><a href="#文件实现——文件存储空间管理" class="headerlink" title="文件实现——文件存储空间管理"></a>文件实现——文件存储空间管理</h4><h3 id="磁盘组织与管理"><a href="#磁盘组织与管理" class="headerlink" title="磁盘组织与管理"></a>磁盘组织与管理</h3><h4 id="磁盘的结构"><a href="#磁盘的结构" class="headerlink" title="磁盘的结构"></a>磁盘的结构</h4><h4 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h4><h4 id="磁盘的管理"><a href="#磁盘的管理" class="headerlink" title="磁盘的管理"></a>磁盘的管理</h4><h2 id="输入-输出-I-O-管理"><a href="#输入-输出-I-O-管理" class="headerlink" title="输入/输出(I/O)管理"></a>输入/输出(I/O)管理</h2><h3 id="I-O管理概述"><a href="#I-O管理概述" class="headerlink" title="I/O管理概述"></a>I/O管理概述</h3><h4 id="I-O设备"><a href="#I-O设备" class="headerlink" title="I/O设备"></a>I/O设备</h4><h4 id="I-O控制方式"><a href="#I-O控制方式" class="headerlink" title="I/O控制方式"></a>I/O控制方式</h4><h4 id="1-O子系统的层次结构"><a href="#1-O子系统的层次结构" class="headerlink" title="1/O子系统的层次结构"></a>1/O子系统的层次结构</h4><h3 id="1-O核心子系统"><a href="#1-O核心子系统" class="headerlink" title="1/O核心子系统"></a>1/O核心子系统</h3><h4 id="I-O子系统概述"><a href="#I-O子系统概述" class="headerlink" title="I/O子系统概述"></a>I/O子系统概述</h4><h4 id="IO调度概念"><a href="#IO调度概念" class="headerlink" title="IO调度概念"></a>IO调度概念</h4><h4 id="高速缓存与缓冲区"><a href="#高速缓存与缓冲区" class="headerlink" title="高速缓存与缓冲区"></a>高速缓存与缓冲区</h4><h4 id="设备分配与回收"><a href="#设备分配与回收" class="headerlink" title="设备分配与回收"></a>设备分配与回收</h4><h4 id="SPOOLing技术（假脱机技术）"><a href="#SPOOLing技术（假脱机技术）" class="headerlink" title="SPOOLing技术（假脱机技术）"></a>SPOOLing技术（假脱机技术）</h4>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag"># 操作系统</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/07/19/%E6%80%BB%E7%BB%93-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="prev" title="总结-计算机网络">
      <i class="fa fa-chevron-left"></i> 总结-计算机网络
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/07/19/%E6%80%BB%E7%BB%93-%E4%B9%A0%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="next" title="习题-计算机网络">
      习题-计算机网络 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      



      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-text">操作系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA"><span class="nav-text">计算机系统概论</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-text">操作系统的基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">操作系统的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%89%B9%E5%BE%81"><span class="nav-text">操作系统的特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%9B%AE%E6%A0%87%E5%92%8C%E5%8A%9F%E8%83%BD"><span class="nav-text">操作系统的目标和功能</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%91%E5%B1%95%E4%B8%8E%E5%88%86%E7%B1%BB"><span class="nav-text">操作系统的发展与分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%B7%A5%E6%93%8D%E4%BD%9C%E9%98%B6%E6%AE%B5%EF%BC%88%E6%AD%A4%E9%98%B6%E6%AE%B5%E6%97%A0%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-text">手工操作阶段（此阶段无操作系统)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%B9%E5%A4%84%E7%90%86%E9%98%B6%E6%AE%B5-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%A7%8B%E5%87%BA%E7%8E%B0%EF%BC%89"><span class="nav-text">批处理阶段(操作系统开始出现）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-text">分时操作系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-text">实时操作系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F"><span class="nav-text">网络操作系统和分布式计算机系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%AA%E4%BA%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-text">个人计算机操作系统</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="nav-text">操作系统的运行环境</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6"><span class="nav-text">操作系统的运行机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">中断和异常的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8"><span class="nav-text">系统调用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="nav-text">操作系统的体系结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%A7%E5%86%85%E6%A0%B8%E5%92%8C%E5%BE%AE%E5%86%85%E6%A0%B8"><span class="nav-text">大内核和微内核</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E7%AB%A0%E7%96%91%E9%9A%BE%E7%82%B9"><span class="nav-text">本章疑难点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E6%80%A7%E4%B8%8E%E5%B9%B6%E5%8F%91%E6%80%A7%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB"><span class="nav-text">并行性与并发性的区别和联系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%B9%E6%9D%83%E6%8C%87%E4%BB%A4%E4%B8%8E%E9%9D%9E%E7%89%B9%E6%9D%83%E6%8C%87%E4%BB%A4"><span class="nav-text">特权指令与非特权指令</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BF%E7%AE%A1%E6%8C%87%E4%BB%A4%E4%B8%8E%E8%AE%BF%E7%AE%A1%E4%B8%AD%E6%96%AD"><span class="nav-text">访管指令与访管中断</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86"><span class="nav-text">进程管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B"><span class="nav-text">进程与线程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E5%BE%81"><span class="nav-text">进程的概念和特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81%E4%B8%8E%E8%BD%AC%E6%8D%A2"><span class="nav-text">进程的状态与转换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6"><span class="nav-text">进程控制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%BB%84%E7%BB%87"><span class="nav-text">进程的组织</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%80%9A%E4%BF%A1"><span class="nav-text">进程的通信</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%A6%82%E5%BF%B5%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">线程概念和多线程模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AC%E8%8A%82%E5%B0%8F%E7%BB%93"><span class="nav-text">本节小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6"><span class="nav-text">处理机调度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">调度的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E7%9A%84%E6%97%B6%E6%9C%BA%E3%80%81%E5%88%87%E6%8D%A2%E4%B8%8E%E8%BF%87%E7%A8%8B"><span class="nav-text">调度的时机、切换与过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E6%96%B9%E5%BC%8F"><span class="nav-text">进程调度方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%87%86%E5%88%99"><span class="nav-text">调度的基本准则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B8%E5%9E%8B%E7%9A%84%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="nav-text">典型的调度算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AC%E7%AB%A0%E5%B0%8F%E7%BB%93"><span class="nav-text">本章小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5"><span class="nav-text">进程同步</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-text">进程同步的基本概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%B8%B4%E7%95%8C%E5%8C%BA%E4%BA%92%E6%96%A5%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95"><span class="nav-text">实现临界区互斥的基本方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F"><span class="nav-text">信号量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%A1%E7%A8%8B"><span class="nav-text">管程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98"><span class="nav-text">经典同步问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AC%E8%8A%82%E5%B0%8F%E7%BB%93-1"><span class="nav-text">本节小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%BB%E9%94%81"><span class="nav-text">死锁</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%BB%E9%94%81%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">死锁的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%BB%E9%94%81%E7%9A%84%E5%A4%84%E7%90%86%E7%AD%96%E7%95%A5"><span class="nav-text">死锁的处理策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2-1"><span class="nav-text">死锁预防</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%BB%E9%94%81%E9%81%BF%E5%85%8D"><span class="nav-text">死锁避免</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B%E5%92%8C%E8%A7%A3%E9%99%A4"><span class="nav-text">死锁检测和解除</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AC%E8%8A%82%E5%B0%8F%E7%BB%93-2"><span class="nav-text">本节小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E7%AB%A0%E7%96%91%E9%9A%BE%E7%82%B9-1"><span class="nav-text">本章疑难点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-text"></span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-text">内存管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%A6%82%E5%BF%B5"><span class="nav-text">内存管理概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%92%8C%E8%A6%81%E6%B1%82"><span class="nav-text">内存管理的基本原理和要求</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A6%86%E7%9B%96%E4%B8%8E%E4%BA%A4%E6%8D%A2"><span class="nav-text">覆盖与交换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD%E5%88%86%E9%85%8D%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F"><span class="nav-text">连续分配管理方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%88%86%E9%85%8D%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F"><span class="nav-text">非连续分配管理方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AC%E8%8A%82%E5%B0%8F%E7%BB%93-3"><span class="nav-text">本节小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-text">虚拟内存管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-text">虚拟内存的基本概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%B7%E6%B1%82%E5%88%86%E9%A1%B5%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F"><span class="nav-text">请求分页管理方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%EF%BC%88%E5%86%B3%E5%AE%9A%E5%BA%94%E8%AF%A5%E6%8D%A2%E5%85%A5%E5%93%AA%E9%A1%B5%E3%80%81%E6%8D%A2%E5%87%BA%E5%93%AA%E9%A1%B5"><span class="nav-text">页面置换算法（决定应该换入哪页、换出哪页)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A1%B5%E9%9D%A2%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-text">页面分配策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8A%96%E5%8A%A8"><span class="nav-text">抖动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B7%A5%E4%BD%9C%E9%9B%86"><span class="nav-text">工作集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91"><span class="nav-text">地址翻译</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AC%E7%AB%A0%E5%B0%8F%E7%BB%93-1"><span class="nav-text">本章小结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86-1"><span class="nav-text">文件管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80"><span class="nav-text">文件系统基础</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">文件的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%9A%84%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84"><span class="nav-text">文件的逻辑结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="nav-text">目录结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB"><span class="nav-text">文件共享</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E4%BF%9D%E6%8A%A4"><span class="nav-text">文件保护</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0"><span class="nav-text">文件系统实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="nav-text">文件系统层次结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95%E5%AE%9E%E7%8E%B0"><span class="nav-text">目录实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%AE%9E%E7%8E%B0%E2%80%94%E6%96%87%E4%BB%B6%E5%88%86%E9%85%8D%E6%96%B9%E5%BC%8F"><span class="nav-text">文件实现—文件分配方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86"><span class="nav-text">文件实现——文件存储空间管理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A3%81%E7%9B%98%E7%BB%84%E7%BB%87%E4%B8%8E%E7%AE%A1%E7%90%86"><span class="nav-text">磁盘组织与管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A3%81%E7%9B%98%E7%9A%84%E7%BB%93%E6%9E%84"><span class="nav-text">磁盘的结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="nav-text">磁盘调度算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A3%81%E7%9B%98%E7%9A%84%E7%AE%A1%E7%90%86"><span class="nav-text">磁盘的管理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BE%93%E5%85%A5-%E8%BE%93%E5%87%BA-I-O-%E7%AE%A1%E7%90%86"><span class="nav-text">输入&#x2F;输出(I&#x2F;O)管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#I-O%E7%AE%A1%E7%90%86%E6%A6%82%E8%BF%B0"><span class="nav-text">I&#x2F;O管理概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#I-O%E8%AE%BE%E5%A4%87"><span class="nav-text">I&#x2F;O设备</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#I-O%E6%8E%A7%E5%88%B6%E6%96%B9%E5%BC%8F"><span class="nav-text">I&#x2F;O控制方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-O%E5%AD%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="nav-text">1&#x2F;O子系统的层次结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-O%E6%A0%B8%E5%BF%83%E5%AD%90%E7%B3%BB%E7%BB%9F"><span class="nav-text">1&#x2F;O核心子系统</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#I-O%E5%AD%90%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0"><span class="nav-text">I&#x2F;O子系统概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#IO%E8%B0%83%E5%BA%A6%E6%A6%82%E5%BF%B5"><span class="nav-text">IO调度概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%B8%8E%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="nav-text">高速缓存与缓冲区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BE%E5%A4%87%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6"><span class="nav-text">设备分配与回收</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SPOOLing%E6%8A%80%E6%9C%AF%EF%BC%88%E5%81%87%E8%84%B1%E6%9C%BA%E6%8A%80%E6%9C%AF%EF%BC%89"><span class="nav-text">SPOOLing技术（假脱机技术）</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ednow</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">294</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">54</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ednow</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '04b9fe1c5636beb4acc4',
      clientSecret: '8ccb8829887eac219a8fdb018878fd0cf088a7ac',
      repo        : 'gittalk-comment',
      owner       : 'ednow',
      admin       : ['ednow'],
      id          : '9ab634ee53ff0f9148821de81290e2d1',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
